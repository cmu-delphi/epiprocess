% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/growth_rate.R
\name{growth_rate}
\alias{growth_rate}
\title{Estimate growth rate}
\usage{
growth_rate(
  x = seq_along(y),
  y,
  x0 = x,
  method = c("rel_change", "linear_reg", "smooth_spline", "trend_filter"),
  h = 7,
  log_scale = FALSE,
  dup_rm = FALSE,
  na_rm = FALSE,
  ...
)
}
\arguments{
\item{x}{Design points corresponding to the signal values \code{y}. Default is
\code{seq_along(y)} (that is, equally-spaced points from 1 to the length of
\code{y}).}

\item{y}{Signal values.}

\item{x0}{Points at which we should estimate the growth rate. Must be a
subset of \code{x} (no extrapolation allowed). Default is \code{x}.}

\item{method}{Either "rel_change", "linear_reg", "smooth_spline", or
"trend_filter", indicating the method to use for the growth rate
calculation. The first two are local methods: they are run in a sliding
fashion over the sequence (in order to estimate derivatives and hence
growth rates); the latter two are global methods: they are run once over
the entire sequence. See details for more explanation.}

\item{h}{Bandwidth for the sliding window, when \code{method} is "rel_change" or
"linear_reg". See details for more explanation.}

\item{log_scale}{Should growth rates be estimated using the parametrization
on the log scale? See details for an explanation. Default is \code{FALSE}.}

\item{dup_rm}{Should we check and remove duplicates in \code{x} (and corresponding
elements of \code{y}) before the computation? Some methods might handle
duplicate \code{x} values gracefully, whereas others might fail (either quietly
or loudly). Default is \code{FALSE}.}

\item{na_rm}{Should missing values be removed before the computation? Default
is \code{FALSE}.}

\item{...}{Additional arguments to pass to the method used to estimate the
derivative.}
}
\value{
Vector of growth rate estimates at the specified points \code{x0}.
}
\description{
Estimates the growth rate of a signal at given points along the underlying
sequence. Several methodologies are available; see the \href{https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html}{growth rate vignette}
for examples.
}
\details{
The growth rate of a function f defined over a continuously-valued
parameter t is defined as f'(t) / f(t), where f'(t) is the derivative of f
at t. To estimate the growth rate of a signal in discrete-time (which can
be thought of as evaluations or discretizations of an underlying function
in continuous-time), we can therefore estimate the derivative and divide by
the signal value itself (or possibly a smoothed version of the signal
value).

The following methods are available for estimating the growth rate:
\itemize{
\item "rel_change": uses (B/A - 1) / h, where B is the average of \code{y} over the
second half of a sliding window of bandwidth h centered at the reference
point \code{x0}, and A the average over the first half. This can be seen as
using a first-difference approximation to the derivative.
\item "linear_reg": uses the slope from a linear regression of \code{y} on \code{x} over a
sliding window centered at the reference point \code{x0}, divided by the fitted
value from this linear regression at \code{x0}.
\item "smooth_spline": uses the estimated derivative at \code{x0} from a smoothing
spline fit to \code{x} and \code{y}, via \code{stats::smooth.spline()}, divided by the
fitted value of the spline at \code{x0}.
\item "trend_filter": uses the estimated derivative at \code{x0} from polynomial trend
filtering (a discrete spline) fit to \code{x} and \code{y}, via
\code{genlasso::trendfilter()}, divided by the fitted value of the discrete
spline at \code{x0}.
}
\subsection{Log Scale}{

An alternative view for the growth rate of a function f in general is given
by defining g(t) = log(f(t)), and then observing that g'(t) = f'(t) /
f(t). Therefore, any method that estimates the derivative can be simply
applied to the log of the signal of interest, and in this light, each
method above ("rel_change", "linear_reg", "smooth_spline", and
"trend_filter") has a log scale analog, which can be used by setting
\code{log_scale = TRUE}.
}

\subsection{Sliding Windows}{

For the local methods, "rel_change" and "linear_reg", we use a sliding window
centered at the reference point of bandiwidth \code{h}. In other words, the
sliding window consists of all points in \code{x} whose distance to the
reference point is at most \code{h}. Note that the unit for this distance is
implicitly defined by the \code{x} variable; for example, if \code{x} is a vector of
\code{Date} objects, \code{h = 7}, and the reference point is January 7, then the
sliding window contains all data in between January 1 and 14 (matching the
behavior of \code{epi_slide()} with \code{before = h - 1} and \code{after = h}).
}

\subsection{Additional Arguments}{

For the global methods, "smooth_spline" and "trend_filter", additional
arguments can be specified via \code{...} for the underlying estimation
function. For the smoothing spline case, these additional arguments are
passed directly to \code{stats::smooth.spline()} (and the defaults are exactly
as in this function). The trend filtering case works a bit differently:
here, a custom set of arguments is allowed (which are distributed
internally to \code{genlasso::trendfilter()} and \code{genlasso::cv.trendfilter()}):
\itemize{
\item \code{ord}: order of piecewise polynomial for the trend filtering fit. Default
is 3.
\item \code{maxsteps}: maximum number of steps to take in the solution path before
terminating. Default is 1000.
\item \code{cv}: should cross-validation be used to choose an effective degrees of
freedom for the fit? Default is \code{TRUE}.
\item \code{k}: number of folds if cross-validation is to be used. Default is 3.
\item \code{df}: desired effective degrees of freedom for the trend filtering fit. If
\code{cv = FALSE}, then \code{df} must be a positive integer; if \code{cv = TRUE}, then
\code{df} must be one of "min" or "1se" indicating the selection rule to use
based on the cross-validation error curve: minimum or 1-standard-error
rule, respectively. Default is "min" (going along with the default \code{cv = TRUE}). Note that if \code{cv = FALSE}, then we require \code{df} to be set by the
user.
}
}
}
\examples{
# COVID cases growth rate by state using default method relative change
cases_deaths_subset \%>\%
  group_by(geo_value) \%>\%
  mutate(cases_gr = growth_rate(x = time_value, y = cases))

# Log scale, degree 4 polynomial and 6-fold cross validation
cases_deaths_subset \%>\%
  group_by(geo_value) \%>\%
  mutate(gr_poly = growth_rate(x = time_value, y = cases, log_scale = TRUE, ord = 4, k = 6))
}
