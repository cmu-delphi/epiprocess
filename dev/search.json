[{"path":"https://cmu-delphi.github.io/epiprocess/dev/DEVELOPMENT.html","id":"setting-up-the-development-environment","dir":"","previous_headings":"","what":"Setting up the development environment","title":"NA","text":"","code":"install.packages(c('devtools', 'pkgdown', 'styler', 'lintr', 'pak')) # install dev dependencies pak::pkg_install(\".\") # install package and dependencies"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/DEVELOPMENT.html","id":"validating-the-package","dir":"","previous_headings":"","what":"Validating the package","title":"NA","text":"","code":"styler::style_pkg() # format code lintr::lint_package() # lint code  devtools::check() # run R CMD check, which runs everything below devtools::document() # generate package meta data and man files devtools::test() # test package devtools::build_vignettes() # build vignettes only devtools::run_examples() # run doc examples devtools::check(vignettes = FALSE) # check package without vignettes"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/DEVELOPMENT.html","id":"developing-the-documentation-site","dir":"","previous_headings":"","what":"Developing the documentation site","title":"NA","text":"CI builds two version documentation: https://cmu-delphi.github.io/epiprocess/ main branch https://cmu-delphi.github.io/epiprocess/dev dev branch. Commands developing documentation site:","code":"# Basic build and preview R -e 'pkgdown::clean_site()' R -e 'devtools::document()' R -e 'pkgdown::build_site()'  # A smart rebuild workflow for non-RStudio users. # You may need to first build the site. R -e 'pkgdown::build_site(\".\", examples = FALSE, devel = TRUE, preview = FALSE)' R -e 'renv::install(\"servr\")' # Will start a local docs server and monitor for changes. Rscript inst/pkgdown-watch.R"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/DEVELOPMENT.html","id":"versioning","dir":"","previous_headings":"","what":"Versioning","title":"NA","text":"Please follow guidelines PR template document.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/DEVELOPMENT.html","id":"planned-cran-release-process","dir":"","previous_headings":"","what":"Planned CRAN release process","title":"NA","text":"Open release issue copy follow checklist issue (modified checklist generated usethis::use_release_issue(version = \"1.0.2\")): git pull dev branch. Make sure changes committed pushed. Check current CRAN check results. Aim 10/10, notes. check works well enough, merge main. Otherwise open PR fix . guidelines. git checkout main git pull may choke MIT license url, ‚Äôs ok. devtools::build_readme() devtools::check_win_devel() maintainer (‚Äúcre‚Äù description) check email problems. may choke, sensitive binary versions packages given system. Either bypass ask someone else run ‚Äôre concerned. Update cran-comments.md PR changes (go list ) dev run list . Submit CRAN: devtools::submit_cran(). Maintainer approves email. Wait CRAN‚Ä¶ accepted üéâ, move next steps. rejected, fix resubmit. Open merge PR containing updates made main back dev. usethis::use_github_release(publish = FALSE) (publish , otherwise won‚Äôt push) create draft release based commit hash CRAN-SUBMISSION push tag GitHub repo. Go repo, verify release notes, publish ready.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 epiprocess authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/compactify.html","id":"removing-redundant-update-data-to-save-space","dir":"Articles","previous_headings":"","what":"Removing redundant update data to save space","title":"Compactify to remove redundant archive data","text":"need store version update rows look like last version corresponding observations carried forward (LOCF) use epiprocess‚Äòs‚Äô epi_archive-related functions, apply LOCF fill data explicit updates. default, even detect remove LOCF-redundant rows save space; impact results long directly work archive‚Äôs DT field way expects rows remain. three different values can assigned compactify: argument: LOCF-redundant rows, removes issues warning information rows removed TRUE: removes LOCF-redundant rows without warning feedback FALSE: keeps LOCF-redundant rows without warning feedback example, one chart using LOCF values, another doesn‚Äôt use illustrate LOCF. Notice head first dataset differs second third value included. LOCF-redundant values can mar performance dataset operations. column case_rate_7d_av many LOCF-redundant values percent_cli, omit percent_cli column comparing performance. example, huge proportion original version update data LOCF-redundant, compactifying saves large amount space. proportion data LOCF-redundant can vary widely data sets, won‚Äôt always lucky. expect, performing 1000 iterations dplyr::filter faster LOCF values omitted. also like measure speed epi_archive methods. detailed performance comparison:","code":"library(epiprocess) library(dplyr)  dt <- archive_cases_dv_subset$DT  locf_omitted <- as_epi_archive(dt) #> Warning: Found rows that appear redundant based on last (version of each) observation carried forward; these rows have been removed to 'compactify' and save space: #> Key: <geo_value, time_value, version> #>       geo_value time_value    version percent_cli case_rate_7d_av #>          <char>     <Date>     <Date>       <num>           <num> #>    1:        ca 2020-06-01 2020-06-07    2.140116        6.628329 #>    2:        ca 2020-06-01 2020-06-23    2.498918        6.628329 #>    3:        ca 2020-06-01 2020-07-23    2.698157        6.603020 #>   ---                                                             #> 4949:        tx 2021-10-18 2021-10-22          NA       23.819450 #> 4950:        tx 2021-10-19 2021-10-22          NA       24.705959 #> 4951:        tx 2021-10-20 2021-10-22          NA       16.464639 #> Built-in `epi_archive` functionality should be unaffected, but results may change if you work directly with its fields (such as `DT`). See `?as_epi_archive` for details. To silence this warning but keep compactification, you can pass `compactify=TRUE` when constructing the archive. locf_included <- as_epi_archive(dt, compactify = FALSE)  head(locf_omitted$DT) #> Key: <geo_value, time_value, version> #>    geo_value time_value    version percent_cli case_rate_7d_av #>       <char>     <Date>     <Date>       <num>           <num> #> 1:        ca 2020-06-01 2020-06-02          NA        6.628329 #> 2:        ca 2020-06-01 2020-06-06    2.140116        6.628329 #> 3:        ca 2020-06-01 2020-06-08    2.140379        6.628329 #> 4:        ca 2020-06-01 2020-06-09    2.114430        6.628329 #> 5:        ca 2020-06-01 2020-06-10    2.133677        6.628329 #> 6:        ca 2020-06-01 2020-06-11    2.197207        6.628329 head(locf_included$DT) #> Key: <geo_value, time_value, version> #>    geo_value time_value    version percent_cli case_rate_7d_av #>       <char>     <Date>     <Date>       <num>           <num> #> 1:        ca 2020-06-01 2020-06-02          NA        6.628329 #> 2:        ca 2020-06-01 2020-06-06    2.140116        6.628329 #> 3:        ca 2020-06-01 2020-06-07    2.140116        6.628329 #> 4:        ca 2020-06-01 2020-06-08    2.140379        6.628329 #> 5:        ca 2020-06-01 2020-06-09    2.114430        6.628329 #> 6:        ca 2020-06-01 2020-06-10    2.133677        6.628329 dt2 <- select(dt, -percent_cli)  locf_included_2 <- as_epi_archive(dt2, compactify = FALSE) locf_omitted_2 <- as_epi_archive(dt2, compactify = TRUE) nrow(locf_included_2$DT) #> [1] 129638 nrow(locf_omitted_2$DT) #> [1] 9055 # Performance of filtering iterate_filter <- function(my_ea) {   for (i in 1:1000) {     filter(my_ea$DT, version >= as.Date(\"2020-01-01\") + i)   } }  elapsed_time <- function(fx) c(system.time(fx))[[3]]  speed_test <- function(f, name) {   data.frame(     operation = name,     locf = elapsed_time(f(locf_included_2)),     no_locf = elapsed_time(f(locf_omitted_2))   ) }  speeds <- speed_test(iterate_filter, \"filter_1000x\") # Performance of as_of iterated 200 times iterate_as_of <- function(my_ea) {   for (i in 1:1000) {     my_ea %>% epix_as_of(min(my_ea$DT$time_value) + i - 1000)   } }  speeds <- rbind(speeds, speed_test(iterate_as_of, \"as_of_1000x\"))  # Performance of slide slide_median <- function(my_ea) {   my_ea %>% epix_slide(median = median(.data$case_rate_7d_av), .before = 7) }  speeds <- rbind(speeds, speed_test(slide_median, \"slide_median\")) speeds_tidy <- tidyr::gather(speeds, key = \"is_locf\", value = \"time_in_s\", locf, no_locf)  library(ggplot2)  ggplot(speeds_tidy) +   geom_bar(aes(x = is_locf, y = time_in_s, fill = operation), stat = \"identity\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/correlation.html","id":"correlations-grouped-by-time","dir":"Articles","previous_headings":"","what":"Correlations grouped by time","title":"Correlate signals across locations and time","text":"epi_cor() function operates epi_df object, requires specification variables correlate, next two arguments (var1 var2). general, can specify grouping variable (combination variables) correlation computations call epi_cor(), via cor_by argument. potentially leads many ways compute correlations. always least two ways compute correlations epi_df: grouping time value, geo value. former obtained via cor_by = time_value.  plot addresses question: ‚Äúgiven day, case death rates linearly associated, across U.S. states?‚Äù. might interested broadening question, instead asking: ‚Äúgiven day, higher case rates tend associate higher death rates?‚Äù, removing dependence linear relationship. latter can addressed using Spearman correlation, accomplished setting method = \"spearman\" call epi_cor(). Spearman correlation highly robust invariant monotone transformations.","code":"library(ggplot2)  z1 <- epi_cor(x, case_rate, death_rate, cor_by = \"time_value\")  ggplot(z1, aes(x = time_value, y = cor)) +   geom_line() +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Correlation\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/correlation.html","id":"lagged-correlations","dir":"Articles","previous_headings":"","what":"Lagged correlations","title":"Correlate signals across locations and time","text":"might also interested case rates associate death rates future. Using dt1 parameter epi_cor(), can lag case rates back number days want, calculating correlations. , set dt1 = -10. means var1 = case_rate lagged 10 days, case rates June 1st correlated death rates June 11th. (might also help think way: death rates certain day correlated case rates offset -10 days.)  Note epi_cor() takes argument shift_by determines grouping use time shifts. default geo_value, makes sense problem hand (another setting, may want group geo value another variable‚Äîsay, age‚Äîtime shifting). can see , generally, lagging case rates back 10 days improves correlations, confirming case rates better correlated death rates 10 days now.","code":"z2 <- epi_cor(x, case_rate, death_rate, cor_by = time_value, dt1 = -10)  z <- rbind(   z1 %>% mutate(lag = 0),   z2 %>% mutate(lag = 10) ) %>%   mutate(lag = as.factor(lag))  ggplot(z, aes(x = time_value, y = cor)) +   geom_line(aes(color = lag)) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Correlation\", col = \"Lag\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/correlation.html","id":"correlations-grouped-by-state","dir":"Articles","previous_headings":"","what":"Correlations grouped by state","title":"Correlate signals across locations and time","text":"second option group geo value, obtained setting cor_by = geo_value. ‚Äôll look correlations 0- 10-day lagged case rates.  can see , generally speaking, lagging case rates back 10 days improves correlations.","code":"z1 <- epi_cor(x, case_rate, death_rate, cor_by = geo_value) z2 <- epi_cor(x, case_rate, death_rate, cor_by = geo_value, dt1 = -10)  z <- rbind(   z1 %>% mutate(lag = 0),   z2 %>% mutate(lag = 10) ) %>%   mutate(lag = as.factor(lag))  ggplot(z, aes(cor)) +   geom_density(aes(fill = lag, col = lag), alpha = 0.5) +   labs(x = \"Correlation\", y = \"Density\", fill = \"Lag\", col = \"Lag\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/correlation.html","id":"more-systematic-lag-analysis","dir":"Articles","previous_headings":"","what":"More systematic lag analysis","title":"Correlate signals across locations and time","text":"Next perform systematic investigation correlations broad range lag values.  can see pretty clear curvature mean correlation case death rates (correlations come grouping geo value) function lag. maximum occurs lag somewhere around 17 days.","code":"library(purrr) lags <- 0:35  z <- map_dfr(lags, function(lag) {   epi_cor(x, case_rate, death_rate, cor_by = geo_value, dt1 = -lag) %>%     mutate(lag = .env$lag) })  z %>%   group_by(lag) %>%   summarize(mean = mean(cor, na.rm = TRUE)) %>%   ggplot(aes(x = lag, y = mean)) +   geom_line() +   geom_point() +   labs(x = \"Lag\", y = \"Mean correlation\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/correlation.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Correlate signals across locations and time","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_archive.html","id":"getting-data-into-epi_archive-format","dir":"Articles","previous_headings":"","what":"Getting data into epi_archive format","title":"Working with epi_archive objects and data revisions","text":"work signal percentage doctor‚Äôs visits CLI (COVID-like illness) computed medical insurance claims, available COVIDcast API. signal subject heavy regular revision; can read API documentation page. data included package (via epidatasets package) can loaded : data can also fetched Delphi Epidata API following query: epi_archive() object can constructed data frame, data table, tibble, provided (least) following columns: geo_value: geographic value associated row measurements. time_value: time value associated row measurements. version: time value specifying version row measurements. example, given row version January 15, 2022 time_value January 14, 2022, row contains measurements data January 14, 2022 available one day later. can see , data frame returned epidatr::pub_covidcast() columns required epi_archive format, issue playing role version. can now use as_epi_archive() bring epi_archive format. See epi_archive() documentation information internal structure.","code":"library(epiprocess) library(data.table) library(dplyr) library(purrr) library(ggplot2)  # This fetches the raw data backing the archive_cases_dv_subset object. dv <- archive_cases_dv_subset$DT %>%   as_tibble() library(epidatr)  dv <- pub_covidcast(   source = \"doctor-visits\",   signals = \"smoothed_adj_cli\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx\",   time_values = epirange(20200601, 20211201),   issues = epirange(20200601, 20211201) ) %>%   rename(version = issue, percent_cli = value) dv_archive <- dv %>%   select(geo_value, time_value, version, percent_cli) %>%   as_epi_archive(compactify = TRUE) dv_archive #> ‚Üí An `epi_archive` object, with metadata: #> ‚Ñπ Min/max time values: 2020-06-01 / 2021-11-30 #> ‚Ñπ First/last version with update: 2020-06-02 / 2021-12-01 #> ‚Ñπ Versions end: 2021-12-01 #> ‚Ñπ A preview of the table (119316 rows x 4 columns): #> Key: <geo_value, time_value, version> #>         geo_value time_value    version percent_cli #>            <char>     <Date>     <Date>       <num> #>      1:        ca 2020-06-01 2020-06-02          NA #>      2:        ca 2020-06-01 2020-06-06    2.140116 #>      3:        ca 2020-06-01 2020-06-08    2.140379 #>      4:        ca 2020-06-01 2020-06-09    2.114430 #>      5:        ca 2020-06-01 2020-06-10    2.133677 #>     ---                                             #> 119312:        tx 2021-11-26 2021-11-29    1.858596 #> 119313:        tx 2021-11-27 2021-11-28          NA #> 119314:        tx 2021-11-28 2021-11-29          NA #> 119315:        tx 2021-11-29 2021-11-30          NA #> 119316:        tx 2021-11-30 2021-12-01          NA"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_archive.html","id":"producing-snapshots-in-epi_df-form","dir":"Articles","previous_headings":"","what":"Producing snapshots in epi_df form","title":"Working with epi_archive objects and data revisions","text":"key method epi_archive class epix_as_of(), generates snapshot archive epi_df format. represents --date values signal variables given version. Note max time value epi_df object May 29, 2021, even though specified version date June 1, 2021 (note as_of field printed helps us see date snapshot). can infer doctor‚Äôs visits signal 2 days latent June 1. Now, let‚Äôs investigate much data revised. plot --date version time series black (edf_latest ) overlay several revisions archive, spaced one month apart, colored lines (snapshots ). also mark version dates dotted vertical lines.  can see interesting highly nontrivial revision behavior: points time provisional data snapshots grossly underestimate latest curve (look particular Florida close end 2021), others overestimate (states towards beginning 2021), though quite dramatically. Modeling revision process, often called backfill modeling, important statistical problem .","code":"edf <- epix_as_of(dv_archive, as.Date(\"2021-06-01\")) print(edf) #> An `epi_df` object, 1,460 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-06-01 #>  #> # A tibble: 1,460 √ó 3 #>   geo_value time_value percent_cli #> * <chr>     <date>           <dbl> #> 1 ca        2020-06-01        2.75 #> 2 ca        2020-06-02        2.57 #> 3 ca        2020-06-03        2.48 #> 4 ca        2020-06-04        2.41 #> 5 ca        2020-06-05        2.57 #> 6 ca        2020-06-06        2.63 #> # ‚Ñπ 1,454 more rows print(max(edf$time_value)) #> [1] \"2021-05-31\" edf_latest <- epix_as_of(dv_archive, dv_archive$versions_end) max_version <- max(dv_archive$DT$version) versions <- seq(as.Date(\"2020-06-01\"), max_version - 1, by = \"1 month\") monthly_snapshots <- map(versions, function(v) {   epix_as_of(dv_archive, v) %>% mutate(version = v) }) %>%   bind_rows(     edf_latest %>% mutate(version = max_version)   ) %>%   mutate(latest = version == max_version)  ggplot(   monthly_snapshots %>% filter(!latest),   aes(x = time_value, y = percent_cli) ) +   geom_line(aes(color = factor(version)), na.rm = TRUE) +   geom_vline(aes(color = factor(version), xintercept = version), lty = 2) +   facet_wrap(~geo_value, scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"% of doctor's visits with CLI\") +   theme(legend.position = \"none\") +   geom_line(     data = monthly_snapshots %>% filter(latest),     aes(x = time_value, y = percent_cli),     inherit.aes = FALSE, color = \"black\", na.rm = TRUE   )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_archive.html","id":"summarizing-revision-behavior","dir":"Articles","previous_headings":"","what":"Summarizing revision behavior","title":"Working with epi_archive objects and data revisions","text":"many ways examine signals change across revisions. provide convenient analysis wrapper revision_summary(), computes simple summary statistics key (default, (geo_value,time_value) pairs). addition per key summary, also returns overall summary. sample output: can see output , mentioned , data set lot revisions: keys revision 34% keys change 10% revised. detailed analysis possible printing, can inspect returned revision_details tibble. collect number statistics state: states similar stats features, except time_near_latest stat, amount time takes revisions converge within 20% final value stay . highest CA lowest TX.","code":"revision_details <- revision_summary(dv_archive, print_inform = TRUE) #> Min lag (time to first version): #>      min median     mean     max #>   3 days 3 days 3.5 days 12 days #> Fraction of epi_key+time_values with #> No revisions: #> ‚Ä¢ 0 out of 1,956 (0%) #>  #> Quick revisions (last revision within 3 days of the `time_value`): #> ‚Ä¢ 0 out of 1,956 (0%) #>  #> Few revisions (At most 3 revisions for that `time_value`): #> ‚Ä¢ 0 out of 1,956 (0%) #>  #>  #> Fraction of revised epi_key+time_values which have: #> Less than 0.1 spread in relative value: #> ‚Ä¢ 91 out of 1,956 (4.65%) #>  #> Spread of more than 2.22056495 in actual value (when revised): #> ‚Ä¢ 671 out of 1,956 (34.3%) #>  #> days until within 20% of the latest value: #>      min median     mean     max #>   3 days 5 days 9.1 days 67 days revision_details %>%   group_by(geo_value) %>%   summarise(     n_rev = mean(n_revisions),     min_lag = min(min_lag),     max_lag = max(max_lag),     spread = mean(spread),     rel_spread = mean(rel_spread),     time_near_latest = mean(time_near_latest)   ) #> # A tibble: 4 √ó 7 #>   geo_value n_rev min_lag max_lag spread rel_spread time_near_latest #>   <chr>     <dbl> <drtn>  <drtn>   <dbl>      <dbl> <drtn>           #> 1 ca         56.4 3 days  74 days   2.53      0.304 11.278119 days   #> 2 fl         56.4 3 days  74 days   2.29      0.280 10.830266 days   #> 3 ny         56.4 3 days  74 days   1.98      0.206  6.977505 days   #> 4 tx         56.4 3 days  74 days   1.63      0.218  7.398773 days"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_archive.html","id":"merging-epi_archive-objects","dir":"Articles","previous_headings":"","what":"Merging epi_archive objects","title":"Working with epi_archive objects and data revisions","text":"common operation datasets merging (joining) together, grab data multiple sources joint analysis modeling. Merging two epi_archive objects together bit tricky however, since need handle datasets might get revised different times. function epix_merge() made smooth . merge working epi_archive versioned percentage CLI outpatient visits another one versioned COVID-19 case reporting data, fetch COVIDcast API, rate scale (counts per 100,000 people population). Note used sync = \"locf\" argument specify want synchronize two datasets disjoint revisions using last observation carried forward (LOCF). information, see epix_merge().","code":"library(epidatr)  y <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_7dav_incidence_prop\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx\",   time_values = epirange(20200601, 20211201),   issues = epirange(20200601, 20211201) ) %>%   select(geo_value, time_value, version = issue, case_rate_7d_av = value) %>%   as_epi_archive(compactify = TRUE)  dv_cases_archive <- epix_merge(dv_archive, y, sync = \"locf\", compactify = TRUE) print(dv_cases_archive) #> ‚Üí An `epi_archive` object, with metadata: #> ‚Ñπ Min/max time values: 2020-06-01 / 2021-11-30 #> ‚Ñπ First/last version with update: 2020-06-02 / 2021-12-01 #> ‚Ñπ Versions end: 2021-12-01 #> ‚Ñπ A preview of the table (129638 rows x 5 columns): #> Key: <geo_value, time_value, version> #>         geo_value time_value    version percent_cli case_rate_7d_av #>            <char>     <Date>     <Date>       <num>           <num> #>      1:        ca 2020-06-01 2020-06-02          NA        6.628329 #>      2:        ca 2020-06-01 2020-06-06    2.140116        6.628329 #>      3:        ca 2020-06-01 2020-06-07    2.140116        6.628329 #>      4:        ca 2020-06-01 2020-06-08    2.140379        6.628329 #>      5:        ca 2020-06-01 2020-06-09    2.114430        6.628329 #>     ---                                                             #> 129634:        tx 2021-11-26 2021-11-29    1.858596        7.957657 #> 129635:        tx 2021-11-27 2021-11-28          NA        7.174299 #> 129636:        tx 2021-11-28 2021-11-29          NA        6.834681 #> 129637:        tx 2021-11-29 2021-11-30          NA        8.841247 #> 129638:        tx 2021-11-30 2021-12-01          NA        9.566218"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_archive.html","id":"backtesting-forecasting-models","dir":"Articles","previous_headings":"","what":"Backtesting forecasting models","title":"Working with epi_archive objects and data revisions","text":"One common use cases epiprocess::epi_archive() object accurate model backtesting. See vignette(\"backtesting\", package=\"epipredict\") -depth demo, using pre-built forecaster package.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_archive.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Working with epi_archive objects and data revisions","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. percent_cli data modified part COVIDcast Epidata API Doctor Visits data. dataset licensed terms Creative Commons Attribution 4.0 International license. Copyright Delphi Research Group Carnegie Mellon University 2020.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"getting-data-into-epi_df-format","dir":"Articles","previous_headings":"","what":"Getting data into epi_df format","title":"Working with epi_df objects and time series data","text":"vignette(\"epiprocess\"), fetch daily reported COVID-19 cases CA, FL, NY, TX (note: ‚Äôre using new, cumulative cases) using epidatr package, convert epi_df format. data included package (via epidatasets package) can loaded : data can also fetched Delphi Epidata API following query: data 2,684 rows 3 columns.","code":"library(epiprocess) library(dplyr) edf <- cases_deaths_subset %>%   select(geo_value, time_value, cases) %>%   arrange(geo_value, time_value) library(epidatr)  d <- as.Date(\"2024-03-20\")  edf <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_incidence_num\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx,ga,pa\",   time_values = epirange(20200301, 20211231),   as_of = d ) %>%   select(geo_value, time_value, cases = value) %>%   arrange(geo_value, time_value) %>%   as_epi_df(as_of = d)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"rolling-computations-using-epi_slide","dir":"Articles","previous_headings":"","what":"Rolling computations using epi_slide","title":"Working with epi_df objects and time series data","text":"common operation time series processing aggregating values time series applying function rolling time window data points. key tool allows epi_slide(). function always first makes sure group data grouping variables epi_df object, includes geo_value possibly other_keys columns. applies rolling slide computation inside group. epi_slide() function three ways specify computation performed: using tidy evaluation approach passing formula passing function","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"slide-the-tidy-way","dir":"Articles","previous_headings":"Rolling computations using epi_slide","what":"Slide the tidy way","title":"Working with epi_df objects and time series data","text":"Usually, convenient way setup computation epi_slide() pass expression tidy evaluation. case, can simply define name new column directly part expression, setting equal computation can access columns .x name, just call , say, dplyr::mutate(). example: simple sanity check, visualize 7-day trailing averages computed top original counts:  can see Texas plot, state moved weekly reporting COVID-19 cases summer 2021. Note without epi_slide(), computation much less convenient. instance, rough equivalent computation following, easy get wrong: Furthermore epi_slide() allows selecting .ref_time_value, latter recipe support.","code":"slide_output <- edf %>%   epi_slide(cases_7sd = sd(cases, na.rm = TRUE), .window_size = 7) library(ggplot2)  ggplot(slide_output, aes(x = time_value)) +   geom_col(aes(y = cases, fill = geo_value), alpha = 0.5, show.legend = FALSE) +   geom_line(aes(y = cases_7sd, col = geo_value), show.legend = FALSE) +   facet_wrap(~geo_value, scales = \"free_y\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 cases\") edf %>%   complete(geo_value, time_value = seq.Date(min(time_value), max(time_value), by = \"day\")) %>%   arrange_canonical() %>%   group_by(geo_value) %>%   mutate(cases_7sd = slider::slide_dbl(cases, .f = sd, na.rm = TRUE, .before = 7, .after = 0)) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #> # Groups:   geo_value [6] #>   geo_value time_value cases cases_7sd #> * <chr>     <date>     <dbl>     <dbl> #> 1 ca        2020-03-01     6     NA    #> 2 ca        2020-03-02     4      1.41 #> 3 ca        2020-03-03     6      1.15 #> 4 ca        2020-03-04    11      2.99 #> 5 ca        2020-03-05    10      2.97 #> 6 ca        2020-03-06    18      5.08 #> # ‚Ñπ 4,020 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"slide-with-a-function","dir":"Articles","previous_headings":"Rolling computations using epi_slide","what":"Slide with a function","title":"Working with epi_df objects and time series data","text":"can also pass function second argument epi_slide(). case, passed function .f must form function(x, g, t, ...), x epi_df column names input epi_df g one-row tibble containing values grouping variables associated group, instance g$geo_value t ref_time_value current window ... additional arguments computation can done function:","code":"edf %>%   epi_slide(.f = function(x, g, t) sd(x$cases, na.rm = TRUE), .window_size = 7) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>   geo_value time_value cases slide_value #> * <chr>     <date>     <dbl>       <dbl> #> 1 ca        2020-03-01     6       NA    #> 2 ca        2020-03-02     4        1.41 #> 3 ca        2020-03-03     6        1.15 #> 4 ca        2020-03-04    11        2.99 #> 5 ca        2020-03-05    10        2.97 #> 6 ca        2020-03-06    18        5.08 #> # ‚Ñπ 4,020 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"epi_slide-with-a-formula","dir":"Articles","previous_headings":"Rolling computations using epi_slide","what":"epi_slide() with a formula","title":"Working with epi_df objects and time series data","text":"computation can done formula, references columns must made prefix .x$..., instance: Note name column defaults slide_value unnamed formula function case. can adjusted .new_col_name.","code":"edf %>%   epi_slide(~ sd(.x$cases, na.rm = TRUE), .window_size = 7) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>   geo_value time_value cases slide_value #> * <chr>     <date>     <dbl>       <dbl> #> 1 ca        2020-03-01     6       NA    #> 2 ca        2020-03-02     4        1.41 #> 3 ca        2020-03-03     6        1.15 #> 4 ca        2020-03-04    11        2.99 #> 5 ca        2020-03-05    10        2.97 #> 6 ca        2020-03-06    18        5.08 #> # ‚Ñπ 4,020 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"rolling-computations-with-multiple-column-outputs","dir":"Articles","previous_headings":"Rolling computations using epi_slide","what":"Rolling computations with multiple column outputs","title":"Working with epi_df objects and time series data","text":"formula (function) returns data.frame, columns data.frame unpacked resulting epi_df (sense tidyr::unpack()). example, following computes 7-day trailing average daily cases well 7-day trailing standard deviation daily cases:","code":"edf %>%   epi_slide(     ~ data.frame(cases_mean = mean(.x$cases, na.rm = TRUE), cases_sd = sd(.x$cases, na.rm = TRUE)),     .window_size = 7   ) #> An `epi_df` object, 4,026 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 5 #>   geo_value time_value cases cases_mean cases_sd #> * <chr>     <date>     <dbl>      <dbl>    <dbl> #> 1 ca        2020-03-01     6       6       NA    #> 2 ca        2020-03-02     4       5        1.41 #> 3 ca        2020-03-03     6       5.33     1.15 #> 4 ca        2020-03-04    11       6.75     2.99 #> 5 ca        2020-03-05    10       7.4      2.97 #> 6 ca        2020-03-06    18       9.17     5.08 #> # ‚Ñπ 4,020 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"optimized-rolling-mean-and-sums","dir":"Articles","previous_headings":"Rolling computations using epi_slide","what":"Optimized rolling mean and sums","title":"Working with epi_df objects and time series data","text":"two common sliding operations, offer two optimized versions: epi_slide_mean() epi_slide_sum(). much faster epi_slide(), recommend using interested mean sum column. following computes 7-day trailing mean daily cases:","code":"edf %>%   group_by(geo_value) %>%   epi_slide_mean(\"cases\", .window_size = 7, na.rm = TRUE) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #> # Groups:   geo_value [6] #>   geo_value time_value cases cases_7dav #> * <chr>     <date>     <dbl>      <dbl> #> 1 ca        2020-03-01     6       6    #> 2 ca        2020-03-02     4       5    #> 3 ca        2020-03-03     6       5.33 #> 4 ca        2020-03-04    11       6.75 #> 5 ca        2020-03-05    10       7.4  #> 6 ca        2020-03-06    18       9.17 #> # ‚Ñπ 4,020 more rows edf %>%   group_by(geo_value) %>%   epi_slide_sum(\"cases\", .window_size = 7, na.rm = TRUE) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #> # Groups:   geo_value [6] #>   geo_value time_value cases cases_7dsum #> * <chr>     <date>     <dbl>       <dbl> #> 1 ca        2020-03-01     6           6 #> 2 ca        2020-03-02     4          10 #> 3 ca        2020-03-03     6          16 #> 4 ca        2020-03-04    11          27 #> 5 ca        2020-03-05    10          37 #> 6 ca        2020-03-06    18          55 #> # ‚Ñπ 4,020 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"running-a-forecaster-on-a-sliding-window-of-data","dir":"Articles","previous_headings":"Rolling computations using epi_slide","what":"Running a forecaster on a sliding window of data","title":"Working with epi_df objects and time series data","text":"natural next step use sliding window forecast future values. However correctly, make sure data historically accurate. data structure use epi_archive analogous slide function epix_slide(). read along train thought, see vignette(\"epi_archive\").","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"adding-more-keys-to-an-epi_df-and-aggregating-groups-with-sum_groups_epi_df","dir":"Articles","previous_headings":"","what":"Adding more keys to an epi_df and aggregating groups with sum_groups_epi_df","title":"Working with epi_df objects and time series data","text":"epi_df object can key columns just geo_value time_value. example, demographic attributes like age group, can add key column. can aggregate data key columns using sum_groups_epi_df(). Let‚Äôs use influenza hospitalization rate data CDC system FluSurv example. can get Delphi Epidata API can now convert data epi_df object set age_group column additional group key: Note epi_df object now additional key column age_group. means one row combination geo_value, time_value, age_group dataset (enforced construction time). Now can aggregate data age_group, want compute total:","code":"library(epidatr) flu_data <- pub_flusurv(   locations = \"ca\",   epiweeks = epirange(201801, 202001), ) %>%   select(location, epiweek, issue, rate_age_0, rate_age_1, rate_age_2, rate_age_3, rate_age_4) %>%   tidyr::pivot_longer(cols = starts_with(\"rate_age_\"), names_to = \"age_group\", values_to = \"rate\") flu_data #> # A tibble: 305 √ó 5 #>   location epiweek    issue      age_group   rate #>   <chr>    <date>     <date>     <chr>      <dbl> #> 1 CA       2017-12-31 2018-12-30 rate_age_0   4.4 #> 2 CA       2017-12-31 2018-12-30 rate_age_1   1.7 #> 3 CA       2017-12-31 2018-12-30 rate_age_2   2.7 #> 4 CA       2017-12-31 2018-12-30 rate_age_3  18.7 #> 5 CA       2017-12-31 2018-12-30 rate_age_4  99.7 #> 6 CA       2018-01-07 2019-01-06 rate_age_0   4.4 #> # ‚Ñπ 299 more rows flu_data <- flu_data %>% as_epi_df(other_keys = \"age_group\", as_of = as.Date(\"2024-03-20\")) #> inferring time_value column. #> inferring geo_value column. flu_data #> An `epi_df` object, 305 x 5 with metadata: #> * geo_type  = state #> * time_type = week #> * other_keys = age_group #> * as_of     = 2024-03-20 #>  #> # A tibble: 305 √ó 5 #>   geo_value age_group  time_value issue       rate #> * <chr>     <chr>      <date>     <date>     <dbl> #> 1 CA        rate_age_0 2017-12-31 2018-12-30   4.4 #> 2 CA        rate_age_1 2017-12-31 2018-12-30   1.7 #> 3 CA        rate_age_2 2017-12-31 2018-12-30   2.7 #> 4 CA        rate_age_3 2017-12-31 2018-12-30  18.7 #> 5 CA        rate_age_4 2017-12-31 2018-12-30  99.7 #> 6 CA        rate_age_0 2018-01-07 2019-01-06   4.4 #> # ‚Ñπ 299 more rows group_cols <- key_colnames(exclude = \"age_group\") flu_data %>%   sum_groups_epi_df(\"rate\", group_cols = group_cols) #> An `epi_df` object, 61 x 3 with metadata: #> * geo_type  = custom #> * time_type = week #> * as_of     = 2024-03-20 #>  #> # A tibble: 61 √ó 3 #>   geo_value time_value  rate #> * <chr>     <date>     <dbl> #> 1 total     2017-12-31 127.  #> 2 total     2018-01-07  76.7 #> 3 total     2018-01-14  57.8 #> 4 total     2018-01-21  37.9 #> 5 total     2018-01-28  30   #> 6 total     2018-02-04  22.8 #> # ‚Ñπ 55 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"detecting-and-filling-time-gaps-with-complete-epi_df","dir":"Articles","previous_headings":"","what":"Detecting and filling time gaps with complete.epi_df","title":"Working with epi_df objects and time series data","text":"Sometimes may missing data time series. can due actual missing data, can due fact data reported certain days. latter case, often useful fill missing data explicit zeros. can done complete.epi_df() function. First, let‚Äôs create data set missing data. reuse dataset edf , modify slightly. Now let‚Äôs fill missing data explicit zeros:","code":"edf_missing <- edf %>%   filter(geo_value %in% c(\"ca\", \"tx\")) %>%   group_by(geo_value) %>%   slice(1:3, 5:6)  edf_missing %>%   print(n = 10) #> An `epi_df` object, 10 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 10 √ó 3 #> # Groups:   geo_value [2] #>    geo_value time_value cases #>  * <chr>     <date>     <dbl> #>  1 ca        2020-03-01     6 #>  2 ca        2020-03-02     4 #>  3 ca        2020-03-03     6 #>  4 ca        2020-03-05    10 #>  5 ca        2020-03-06    18 #>  6 tx        2020-03-01     0 #>  7 tx        2020-03-02     0 #>  8 tx        2020-03-03     0 #>  9 tx        2020-03-05     3 #> 10 tx        2020-03-06     1 edf_missing %>%   complete(     time_value = seq.Date(min(time_value), max(time_value), by = \"day\"),     fill = list(cases = 0)   ) %>%   print(n = 12) #> An `epi_df` object, 12 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 12 √ó 3 #> # Groups:   geo_value [2] #>    geo_value time_value cases #>  * <chr>     <date>     <dbl> #>  1 ca        2020-03-01     6 #>  2 ca        2020-03-02     4 #>  3 ca        2020-03-03     6 #>  4 ca        2020-03-04     0 #>  5 ca        2020-03-05    10 #>  6 ca        2020-03-06    18 #>  7 tx        2020-03-01     0 #>  8 tx        2020-03-02     0 #>  9 tx        2020-03-03     0 #> 10 tx        2020-03-04     0 #> 11 tx        2020-03-05     3 #> 12 tx        2020-03-06     1"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"detecting-and-filling-time-gaps-with-tsibble","dir":"Articles","previous_headings":"Detecting and filling time gaps with complete.epi_df","what":"Detecting and filling time gaps with tsibble","title":"Working with epi_df objects and time series data","text":"can also use tsibble package detect fill time gaps. ‚Äôll work county-level reported COVID-19 cases MA VT. data included package (via epidatasets package) can loaded : data can also fetched Delphi Epidata API following query: data contains 16,212 rows 5 columns.","code":"library(epiprocess) library(dplyr) library(readr)  x <- covid_incidence_county_subset library(epidatr)  d <- as.Date(\"2024-03-20\")  # Get mapping between FIPS codes and county&state names: y <- read_csv(\"https://github.com/cmu-delphi/covidcast/raw/c89e4d295550ba1540d64d2cc991badf63ad04e5/Python-packages/covidcast-py/covidcast/geo_mappings/county_census.csv\", # nolint: line_length_linter   col_types = c(     FIPS = col_character(),     CTYNAME = col_character(),     STNAME = col_character()   ) ) %>%   filter(STNAME %in% c(\"Massachusetts\", \"Vermont\"), STNAME != CTYNAME) %>%   select(geo_value = FIPS, county_name = CTYNAME, state_name = STNAME)  # Fetch only counties from Massachusetts and Vermont, then append names columns as well x <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_incidence_num\",   geo_type = \"county\",   time_type = \"day\",   geo_values = paste(y$geo_value, collapse = \",\"),   time_values = epirange(20200601, 20211231),   as_of = d ) %>%   select(geo_value, time_value, cases = value) %>%   inner_join(y, by = \"geo_value\", relationship = \"many-to-one\", unmatched = c(\"error\", \"drop\")) %>%   as_epi_df(as_of = d)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"converting-to-tsibble-format","dir":"Articles","previous_headings":"","what":"Converting to tsibble format","title":"Working with epi_df objects and time series data","text":"manipulating wrangling time series data, tsibble already provides host useful tools. tsibble object (formerly, class tbl_ts) basically tibble (data frame) two specially-marked columns: index column representing time variable (defining order past present), key column identifying unique observational unit time point. fact, key can made number columns, just single one. epi_df object, index variable time_value, key variable typically geo_value (though need always case: example, age group variable another column, serve second key variable). epiprocess package thus provides implementation as_tsibble() epi_df objects, sets variables according defaults. can also set key variable(s) directly call as_tsibble(). Similar SQL keys, key uniquely identify time point (, key index together uniquely identify row), as_tsibble() throws error: can see, duplicate county names Massachusetts Vermont, caused error. Keying county name state name, however, work: One major advantages tsibble package ability handle implicit gaps time series data. words, can infer time scale ‚Äôre interested (say, daily data), detect apparent gaps (say, values reported January 1 3 January 2). can subsequently use functionality make missing entries explicit, generally help avoid bugs downstream data processing tasks. Let‚Äôs first remove certain dates data set create gaps: functions has_gaps(), scan_gaps(), count_gaps() tsibble package provide useful summaries, slightly different formats. can also visualize patterns missingness:  Using fill_gaps() function tsibble, can replace gaps explicit value. default NA, current case, missingness random rather represents small value censored (hypothetical COVID-19 reports, certainly real phenomenon occurs signals), better replace zero, . (approaches, LOCF: last observation carried forward time, accomplished first filling NA values following second call tidyr::fill().) Note time series Addison, VT starts August 27, 2020, even though original (uncensored) data set drawn period went back June 6, 2020. setting .full = TRUE, can zero-fill entire span observed (censored) data. Explicit imputation missingness (zero-filling case) can important protecting bugs sorts downstream tasks. example, even something simple 7-day trailing average complicated missingness. function epi_slide() looks rows within window 7 days anchored right reference time point (.window_size = 7). days given week missing censored small case counts, taking average observed case counts can misleading unintentionally biased upwards. Meanwhile, running epi_slide() zero-filled data brings trailing averages (appropriately) downwards, can see inspecting Plymouth, MA around July 1, 2021.","code":"library(tsibble)  xt <- as_tsibble(x) head(xt) #> # A tsibble: 6 x 5 [1D] #> # Key:       geo_value [1] #>   geo_value time_value cases county_name       state_name    #>   <chr>     <date>     <dbl> <chr>             <chr>         #> 1 25001     2020-06-01     4 Barnstable County Massachusetts #> 2 25001     2020-06-02     2 Barnstable County Massachusetts #> 3 25001     2020-06-03     6 Barnstable County Massachusetts #> 4 25001     2020-06-04     4 Barnstable County Massachusetts #> 5 25001     2020-06-05     2 Barnstable County Massachusetts #> 6 25001     2020-06-06     2 Barnstable County Massachusetts key(xt) #> [[1]] #> geo_value index(xt) #> time_value interval(xt) #> <interval[1]> #> [1] 1D head(as_tsibble(x, key = \"county_name\")) #> Error in `validate_tsibble()`: #> ! A valid tsibble must have distinct rows identified by key and index. #> ‚Ñπ Please use `duplicates()` to check the duplicated rows. head(duplicates(x, key = \"county_name\")) #> # A tibble: 6 √ó 5 #>   geo_value time_value cases county_name     state_name    #>   <chr>     <date>     <dbl> <chr>           <chr>         #> 1 25009     2020-06-01    92 Essex County    Massachusetts #> 2 25011     2020-06-01     0 Franklin County Massachusetts #> 3 50009     2020-06-01     0 Essex County    Vermont       #> 4 50011     2020-06-01     0 Franklin County Vermont       #> 5 25009     2020-06-02    90 Essex County    Massachusetts #> 6 25011     2020-06-02     0 Franklin County Massachusetts head(as_tsibble(x, key = c(\"county_name\", \"state_name\"))) #> # A tsibble: 6 x 5 [1D] #> # Key:       county_name, state_name [1] #>   geo_value time_value cases county_name    state_name #>   <chr>     <date>     <dbl> <chr>          <chr>      #> 1 50001     2020-06-01     0 Addison County Vermont    #> 2 50001     2020-06-02     0 Addison County Vermont    #> 3 50001     2020-06-03     0 Addison County Vermont    #> 4 50001     2020-06-04     0 Addison County Vermont    #> 5 50001     2020-06-05     0 Addison County Vermont    #> 6 50001     2020-06-06     1 Addison County Vermont state_naming <- read_csv(\"https://github.com/cmu-delphi/covidcast/raw/c89e4d295550ba1540d64d2cc991badf63ad04e5/Python-packages/covidcast-py/covidcast/geo_mappings/state_census.csv\", # nolint: line_length_linter   col_types = c(NAME = col_character(), ABBR = col_character()) ) %>%   transmute(state_name = NAME, abbr = tolower(ABBR)) %>%   as_tibble()  # First make geo value more readable for tables, plots, etc. x <- x %>%   inner_join(state_naming, by = \"state_name\", relationship = \"many-to-one\", unmatched = c(\"error\", \"drop\")) %>%   mutate(geo_value = paste(substr(county_name, 1, nchar(county_name) - 7), state_name, sep = \", \")) %>%   select(geo_value, time_value, cases)  xt <- as_tsibble(x) %>% filter(cases >= 3) head(has_gaps(xt)) #> # A tibble: 6 √ó 2 #>   geo_value                 .gaps #>   <chr>                     <lgl> #> 1 Addison, Vermont          TRUE  #> 2 Barnstable, Massachusetts TRUE  #> 3 Bennington, Vermont       TRUE  #> 4 Berkshire, Massachusetts  TRUE  #> 5 Bristol, Massachusetts    TRUE  #> 6 Caledonia, Vermont        TRUE head(scan_gaps(xt)) #> # A tsibble: 6 x 2 [1D] #> # Key:       geo_value [1] #>   geo_value        time_value #>   <chr>            <date>     #> 1 Addison, Vermont 2020-08-28 #> 2 Addison, Vermont 2020-08-29 #> 3 Addison, Vermont 2020-08-30 #> 4 Addison, Vermont 2020-08-31 #> 5 Addison, Vermont 2020-09-01 #> 6 Addison, Vermont 2020-09-02 head(count_gaps(xt)) #> # A tibble: 6 √ó 4 #>   geo_value        .from      .to           .n #>   <chr>            <date>     <date>     <int> #> 1 Addison, Vermont 2020-08-28 2020-10-04    38 #> 2 Addison, Vermont 2020-10-06 2020-10-23    18 #> 3 Addison, Vermont 2020-10-25 2020-11-04    11 #> 4 Addison, Vermont 2020-11-06 2020-11-10     5 #> 5 Addison, Vermont 2020-11-14 2020-11-18     5 #> 6 Addison, Vermont 2020-11-20 2020-11-20     1 library(ggplot2)  ggplot(   count_gaps(xt),   aes(     x = reorder(geo_value, desc(geo_value)),     color = geo_value   ) ) +   geom_linerange(aes(ymin = .from, ymax = .to)) +   geom_point(aes(y = .from)) +   geom_point(aes(y = .to)) +   coord_flip() +   labs(x = \"County\", y = \"Date\") +   theme(legend.position = \"none\") fill_gaps(xt, cases = 0) %>%   head() #> # A tsibble: 6 x 3 [1D] #> # Key:       geo_value [1] #>   geo_value        time_value cases #>   <chr>            <date>     <dbl> #> 1 Addison, Vermont 2020-08-27     3 #> 2 Addison, Vermont 2020-08-28     0 #> 3 Addison, Vermont 2020-08-29     0 #> 4 Addison, Vermont 2020-08-30     0 #> 5 Addison, Vermont 2020-08-31     0 #> 6 Addison, Vermont 2020-09-01     0 xt_filled <- fill_gaps(xt, cases = 0, .full = TRUE)  head(xt_filled) #> # A tsibble: 6 x 3 [1D] #> # Key:       geo_value [1] #>   geo_value        time_value cases #>   <chr>            <date>     <dbl> #> 1 Addison, Vermont 2020-06-01     0 #> 2 Addison, Vermont 2020-06-02     0 #> 3 Addison, Vermont 2020-06-03     0 #> 4 Addison, Vermont 2020-06-04     0 #> 5 Addison, Vermont 2020-06-05     0 #> 6 Addison, Vermont 2020-06-06     0 xt %>%   as_epi_df(as_of = as.Date(\"2024-03-20\")) %>%   group_by(geo_value) %>%   epi_slide(cases_7dav = mean(cases), .window_size = 7) %>%   ungroup() %>%   filter(     geo_value == \"Plymouth, MA\",     abs(time_value - as.Date(\"2021-07-01\")) <= 3   ) %>%   print(n = 7) #> An `epi_df` object, 0 x 4 with metadata: #> * geo_type  = custom #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 0 √ó 4 #> # ‚Ñπ 4 variables: geo_value <chr>, time_value <date>, cases <dbl>, #> #   cases_7dav <dbl>  xt_filled %>%   as_epi_df(as_of = as.Date(\"2024-03-20\")) %>%   group_by(geo_value) %>%   epi_slide(cases_7dav = mean(cases), .window_size = 7) %>%   ungroup() %>%   filter(     geo_value == \"Plymouth, MA\",     abs(time_value - as.Date(\"2021-07-01\")) <= 3   ) %>%   print(n = 7) #> An `epi_df` object, 0 x 4 with metadata: #> * geo_type  = custom #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 0 √ó 4 #> # ‚Ñπ 4 variables: geo_value <chr>, time_value <date>, cases <dbl>, #> #   cases_7dav <dbl>"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"geographic-aggregation","dir":"Articles","previous_headings":"","what":"Geographic aggregation","title":"Working with epi_df objects and time series data","text":"yet provide tools geographic aggregation epiprocess. However, Python geocoding utilities available. Reach us functionality like see us add epiprocess.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epi_df.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Working with epi_df objects and time series data","text":"percent_cli data modified part COVIDcast Epidata API Doctor Visits data. dataset licensed terms Creative Commons Attribution 4.0 International license. Copyright Delphi Research Group Carnegie Mellon University 2020. document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epiprocess.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Get started with epiprocess","text":"vignette provides brief introduction epiprocess package. following: Get data epi_df() format plot data Perform basic signal processing tasks (lagged differences, rolling average, cumulative sum, etc.) Detect outliers data apply corrections Calculate growth rate data Get data epi_archive() format perform similar signal processing tasks","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epiprocess.html","id":"getting-data-into-epi_df-format","dir":"Articles","previous_headings":"","what":"Getting data into epi_df format","title":"Get started with epiprocess","text":"‚Äôll start getting data epi_df() format, just tibble bit special structure. example, get COVID-19 confirmed cumulative case data JHU CSSE California, Florida, New York, Texas, March 1, 2020 January 31, 2022. included example data epidatasets::covid_confirmed_cumulative_num object, prepared downloading data using epidatr::pub_covidcast(). data can downloaded epidatr follows: tibble returned columns required epi_df object, geo_value time_value, can convert directly epi_df object using as_epi_df(). brief, can think epi_df object snapshot epidemiological data set particular point time (recorded as_of attribute). can easily plot data using autoplot() method (convenience wrapper ggplot2).  can compute 7 day moving average confirmed daily cases geo_value using epi_slide_mean() function. -depth guide sliding, see vignette(\"epi_df\"). can compute growth rate confirmed cumulative cases geo_value. -depth guide growth rates, see vignette(\"growth_rate\"). Detect outliers daily reported cases geo_value. -depth guide outlier detection, see vignette(\"outliers\"). Add column epi_df object daily deaths geo_value compute correlations cases deaths geo_value. -depth guide correlations, see vignette(\"correlation\"). Note epi_df object loses geo_value time_value columns, decay regular tibble.","code":"library(epidatasets) library(epidatr) library(epiprocess) library(dplyr) library(tidyr) library(withr)  covid_confirmed_cumulative_num class(covid_confirmed_cumulative_num) colnames(covid_confirmed_cumulative_num) covid_confirmed_cumulative_num <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_cumulative_num\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx\",   time_values = epirange(20200301, 20220131), ) edf <- covid_confirmed_cumulative_num %>%   select(geo_value, time_value, cases_cumulative = value) %>%   as_epi_df() %>%   group_by(geo_value) %>%   mutate(cases_daily = cases_cumulative - lag(cases_cumulative, default = 0)) edf #> An `epi_df` object, 2,808 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-12-09 23:53:20.569538 #>  #> # A tibble: 2,808 √ó 4 #> # Groups:   geo_value [4] #>   geo_value time_value cases_cumulative cases_daily #> * <chr>     <date>                <dbl>       <dbl> #> 1 ca        2020-03-01               19          19 #> 2 fl        2020-03-01                0           0 #> 3 ny        2020-03-01                0           0 #> 4 tx        2020-03-01                0           0 #> 5 ca        2020-03-02               23           4 #> 6 fl        2020-03-02                1           1 #> # ‚Ñπ 2,802 more rows edf %>%   autoplot(cases_cumulative) edf %>%   group_by(geo_value) %>%   epi_slide_mean(cases_daily, .window_size = 7, na.rm = TRUE) #> An `epi_df` object, 2,808 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-12-09 23:53:20.569538 #>  #> # A tibble: 2,808 √ó 5 #> # Groups:   geo_value [4] #>   geo_value time_value cases_cumulative cases_daily cases_daily_7dav #> * <chr>     <date>                <dbl>       <dbl>            <dbl> #> 1 ca        2020-03-01               19          19            19    #> 2 ca        2020-03-02               23           4            11.5  #> 3 ca        2020-03-03               29           6             9.67 #> 4 ca        2020-03-04               40          11            10    #> 5 ca        2020-03-05               50          10            10    #> 6 ca        2020-03-06               68          18            11.3  #> # ‚Ñπ 2,802 more rows edf %>%   group_by(geo_value) %>%   mutate(cases_growth = growth_rate(x = time_value, y = cases_cumulative, method = \"rel_change\", h = 7)) #> An `epi_df` object, 2,808 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-12-09 23:53:20.569538 #>  #> # A tibble: 2,808 √ó 5 #> # Groups:   geo_value [4] #>   geo_value time_value cases_cumulative cases_daily cases_growth #> * <chr>     <date>                <dbl>       <dbl>        <dbl> #> 1 ca        2020-03-01               19          19        0.534 #> 2 fl        2020-03-01                0           0      Inf     #> 3 ny        2020-03-01                0           0      Inf     #> 4 tx        2020-03-01                0           0      Inf     #> 5 ca        2020-03-02               23           4        0.579 #> 6 fl        2020-03-02                1           1        2.32  #> # ‚Ñπ 2,802 more rows edf %>%   group_by(geo_value) %>%   mutate(outlier_info = detect_outlr(x = time_value, y = cases_daily)) %>%   ungroup() #> An `epi_df` object, 2,808 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-12-09 23:53:20.569538 #>  #> # A tibble: 2,808 √ó 5 #>   geo_value time_value cases_cumulative cases_daily outlier_info$rm_lower #> * <chr>     <date>                <dbl>       <dbl>                 <dbl> #> 1 ca        2020-03-01               19          19                  0.5  #> 2 fl        2020-03-01                0           0                 -2.5  #> 3 ny        2020-03-01                0           0                 -2.5  #> 4 tx        2020-03-01                0           0                 -2    #> 5 ca        2020-03-02               23           4                  0.25 #> 6 fl        2020-03-02                1           1                 -1.75 #> # ‚Ñπ 2,802 more rows #> # ‚Ñπ 5 more variables: outlier_info$rm_upper <dbl>, $rm_replacement <dbl>, ‚Ä¶ df <- pub_covidcast(   source = \"jhu-csse\",   signals = \"deaths_incidence_num\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx\",   time_values = epirange(20200301, 20220131), ) %>%   select(geo_value, time_value, deaths_daily = value) %>%   as_epi_df() %>%   arrange_canonical() edf <- inner_join(edf, df, by = c(\"geo_value\", \"time_value\")) edf %>%   group_by(geo_value) %>%   epi_slide_mean(deaths_daily, .window_size = 7, na.rm = TRUE) %>%   epi_cor(cases_daily, deaths_daily) #> # A tibble: 4 √ó 2 #>   geo_value   cor #>   <chr>     <dbl> #> 1 ca        0.202 #> 2 fl        0.245 #> 3 ny        0.183 #> 4 tx        0.359 edf %>% select(-time_value) #> # A tibble: 2,808 √ó 4 #> # Groups:   geo_value [4] #>   geo_value cases_cumulative cases_daily deaths_daily #>   <chr>                <dbl>       <dbl>        <dbl> #> 1 ca                      19          19            0 #> 2 fl                       0           0            0 #> 3 ny                       0           0            0 #> 4 tx                       0           0            0 #> 5 ca                      23           4            0 #> 6 fl                       1           1            0 #> # ‚Ñπ 2,802 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epiprocess.html","id":"getting-data-into-epi_archive-format","dir":"Articles","previous_headings":"","what":"Getting data into epi_archive format","title":"Get started with epiprocess","text":"can also get data epi_archive() format, can thought aggregation many epi_df snapshots. can perform similar signal processing tasks epi_archive objects epi_df objects, though interface bit different. See vignette(\"epi_archive\") -depth guide epi_archive objects.","code":"library(epidatr) library(epiprocess) library(data.table) library(dplyr) library(purrr) library(ggplot2)  dv <- pub_covidcast(   source = \"doctor-visits\",   signals = \"smoothed_adj_cli\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx\",   time_values = epirange(20200601, 20211201),   issues = epirange(20200601, 20211201) ) %>%   select(geo_value, time_value, issue, percent_cli = value) %>%   as_epi_archive(compactify = TRUE) dv #> ‚Üí An `epi_archive` object, with metadata: #> ‚Ñπ Min/max time values: 2020-06-01 / 2021-11-26 #> ‚Ñπ First/last version with update: 2020-06-06 / 2021-11-29 #> ‚Ñπ Versions end: 2021-11-29 #> ‚Ñπ A preview of the table (117124 rows x 4 columns): #> Key: <geo_value, time_value, version> #>         geo_value time_value    version percent_cli #>            <char>     <Date>     <Date>       <num> #>      1:        ca 2020-06-01 2020-06-06    2.140116 #>      2:        ca 2020-06-01 2020-06-08    2.140379 #>      3:        ca 2020-06-01 2020-06-09    2.114430 #>      4:        ca 2020-06-01 2020-06-10    2.133677 #>      5:        ca 2020-06-01 2020-06-11    2.197207 #>     ---                                             #> 117120:        tx 2021-11-23 2021-11-29    2.159704 #> 117121:        tx 2021-11-24 2021-11-27    2.024028 #> 117122:        tx 2021-11-24 2021-11-29    1.937911 #> 117123:        tx 2021-11-25 2021-11-29    1.866631 #> 117124:        tx 2021-11-26 2021-11-29    1.858596"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/epiprocess.html","id":"data-attribution","dir":"Articles","previous_headings":"","what":"Data attribution","title":"Get started with epiprocess","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/growth_rate.html","id":"growth-rate-basics","dir":"Articles","previous_headings":"","what":"Growth rate basics","title":"Estimate growth rates in signals","text":"growth rate function ff defined continuously-valued parameter tt defined f‚Ä≤(t)/f(t)f'(t)/f(t), f‚Ä≤(t)f'(t) derivative ff tt. estimate growth rate signal discrete-time (can thought evaluations discretizations underlying function continuous-time), can estimate derivative divide signal value (possibly smoothed version signal value). growth_rate() function takes sequence underlying design points x corresponding sequence y signal values, allows us choose following methods estimating growth rate given reference point x0, setting method argument: ‚Äúrel_change‚Äù: uses (B‚Äæ/‚Äæ‚àí1)/h(\\bar B/\\bar - 1) / h, B‚Äæ\\bar B average y second half sliding window bandwidth h centered reference point x0, ‚Äæ\\bar average first half. can seen using first-difference approximation derivative. ‚Äúlinear_reg‚Äù: uses slope linear regression y x sliding window centered reference point x0, divided fitted value linear regression x0. ‚Äúsmooth_spline‚Äù: uses estimated derivative x0 smoothing spline fit x y, via stats::smooth.spline(), divided fitted value spline x0. ‚Äútrend_filter‚Äù: uses estimated derivative x0 polynomial trend filtering (discrete spline) fit x y, via genlasso::trendfilter(), divided fitted value discrete spline x0. default growth_rate() x0 = x, returns estimate growth rate underlying design point.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/growth_rate.html","id":"relative-change","dir":"Articles","previous_headings":"","what":"Relative change","title":"Estimate growth rates in signals","text":"default method ‚Äúrel_change‚Äù, simplest way estimate growth rates. default bandwidth h = 7, daily data, considers relative change signal adjacent weeks. can wrap growth_rate() call dplyr::mutate() append new column epi_df object computed growth rates. can visualize growth rate estimates plotting signal values highlighting periods time relative change 1% (red) -1% (blue), faceting geo value.  direct visualization, plot estimated growth rates , overlaying curves two states one plot.  can see estimated growth rates relative change method somewhat volatile, appears bias towards towards right boundary time span‚Äîlook estimated growth rate Georgia late December 2021, takes potentially suspicious dip. general, estimation derivatives difficult near boundary, relative changes can suffer particularly noticeable boundary bias based difference averages two halves local window, simplistic approach, one halves truncated near boundary.","code":"x <- x %>%   group_by(geo_value) %>%   mutate(cases_gr1 = growth_rate(time_value, cases))  head(x, 10) #> An `epi_df` object, 10 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 10 √ó 4 #> # Groups:   geo_value [1] #>   geo_value time_value cases cases_gr1 #> * <chr>     <date>     <dbl>     <dbl> #> 1 ga        2020-06-01  643.   0.00601 #> 2 ga        2020-06-02  603.   0.0185  #> 3 ga        2020-06-03  608    0.0240  #> 4 ga        2020-06-04  656.   0.0218  #> 5 ga        2020-06-05  677.   0.0193  #> 6 ga        2020-06-06  718.   0.0163  #> # ‚Ñπ 4 more rows library(ggplot2)  upper <- 0.01 lower <- -0.01  ggplot(x, aes(x = time_value, y = cases)) +   geom_tile(     data = x %>% filter(cases_gr1 >= upper),     aes(x = time_value, y = 0, width = 7, height = Inf),     fill = 2, alpha = 0.08   ) +   geom_tile(     data = x %>% filter(cases_gr1 <= lower),     aes(x = time_value, y = 0, width = 7, height = Inf),     fill = 4, alpha = 0.08   ) +   geom_line() +   facet_wrap(vars(geo_value), scales = \"free_y\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 cases\") ggplot(x, aes(x = time_value, y = cases_gr1)) +   geom_line(aes(col = geo_value)) +   geom_hline(yintercept = upper, linetype = 2, col = 2) +   geom_hline(yintercept = lower, linetype = 2, col = 4) +   scale_color_manual(values = c(3, 6)) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"State\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/growth_rate.html","id":"linear-regression","dir":"Articles","previous_headings":"","what":"Linear regression","title":"Estimate growth rates in signals","text":"second simplest method available ‚Äúlinear_reg‚Äù, whose default bandwidth h = 7. Compared ‚Äúrel_change‚Äù, appears behave similarly overall, thankfully avoids troublesome spikes:","code":"x <- x %>%   group_by(geo_value) %>%   mutate(cases_gr2 = growth_rate(time_value, cases, method = \"linear_reg\"))  x %>%   pivot_longer(     cols = starts_with(\"cases_gr\"),     names_to = \"method\",     values_to = \"gr\"   ) %>%   mutate(method = recode(method,     cases_gr1 = \"rel_change\",     cases_gr2 = \"linear_reg\"   )) %>%   ggplot(aes(x = time_value, y = gr)) +   geom_line(aes(col = method)) +   scale_color_manual(values = c(2, 4)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/growth_rate.html","id":"nonparametric-estimation","dir":"Articles","previous_headings":"","what":"Nonparametric estimation","title":"Estimate growth rates in signals","text":"can also use nonparametric method estimate derivative, ‚Äúsmooth_spline‚Äù ‚Äútrend_filter‚Äù. latter going generally computationally expensive, also able adapt better local level smoothness. (apparent efficiency actually compounded particular implementations default settings methods: ‚Äútrend_filter‚Äù based full solution path algorithm provided genlasso package, performs cross-validation default order pick level regularization; read documentation growth_rate() details.)  particular example, trend filtering estimates growth rate appear much stable smoothing spline, also much stable estimates local relative changes linear regressions. smoothing spline growth rate estimates based default settings stats::smooth.spline(), appear severely -regularized . arguments stats::smooth.spline() can customized passing additional arguments ... call growth_rate(); similarly, can also use additional arguments customize settings underlying trend filtering functions genlasso::trendfilter(), genlasso::cv.trendfilter(), documentation growth_rate() gives full details.","code":"x <- x %>%   group_by(geo_value) %>%   mutate(     cases_gr3 = growth_rate(time_value, cases, method = \"smooth_spline\"),     cases_gr4 = growth_rate(time_value, cases, method = \"trend_filter\")   )  x %>%   select(geo_value, time_value, cases_gr3, cases_gr4) %>%   pivot_longer(     cols = starts_with(\"cases_gr\"),     names_to = \"method\",     values_to = \"gr\"   ) %>%   mutate(method = recode(method,     cases_gr3 = \"smooth_spline\",     cases_gr4 = \"trend_filter\"   )) %>%   ggplot(aes(x = time_value, y = gr)) +   geom_line(aes(col = method)) +   scale_color_manual(values = c(3, 6)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/growth_rate.html","id":"log-scale-estimation","dir":"Articles","previous_headings":"","what":"Log scale estimation","title":"Estimate growth rates in signals","text":"general, alternative view growth rate function ff given defining g(t)=log(f(t))g(t) = \\log(f(t)), observing g‚Ä≤(t)=f‚Ä≤(t)/f(t)g'(t) = f'(t)/f(t). Therefore, method estimates derivative can simply applied log signal interest, light, method (‚Äúrel_change‚Äù, ‚Äúlinear_reg‚Äù, ‚Äúsmooth_spline‚Äù, ‚Äútrend_filter‚Äù) log scale analog, can used setting argument log_scale = TRUE call growth_rate().   Comparing rel_change_log curves rel_change counterparts (shown earlier figures), see former curves appear less volatile match linear regression estimates much closely. particular, rel_change upward spikes, rel_change_log less pronounced spikes. occur? estimate g‚Ä≤(t)g'(t) can expressed ùîº[log(B)‚àílog()]/h=ùîº[log(1+hR)]/h\\mathbb E[\\log(B)-\\log()]/h = \\mathbb E[\\log(1+hR)]/h, R=((B‚àí)/h)/AR = ((B-)/h) / , expectation refers averaging hh observations window. Consider following two relevant inequalities, due concavity logarithm function: ùîº[log(1+hR)]/h‚â§log(1+hùîº[R])/h‚â§ùîº[R]. \\mathbb E[\\log(1+hR)]/h \\leq \\log(1+h\\mathbb E[R])/h \\leq \\mathbb E[R]. first inequality Jensen‚Äôs; second inequality tangent line concave function lies . Finally, observe ùîº[R]‚âà((B‚Äæ‚àí‚Äæ)/h)/‚Äæ\\mathbb E[R] \\approx ((\\bar B-\\bar )/h) / \\bar , rel_change estimate. explains rel_change_log curve often lies rel_change curve.","code":"x <- x %>%   group_by(geo_value) %>%   mutate(     cases_gr5 = growth_rate(time_value, cases,       method = \"rel_change\",       log_scale = TRUE     ),     cases_gr6 = growth_rate(time_value, cases,       method = \"linear_reg\",       log_scale = TRUE     ),     cases_gr7 = growth_rate(time_value, cases,       method = \"smooth_spline\",       log_scale = TRUE     ),     cases_gr8 = growth_rate(time_value, cases,       method = \"trend_filter\",       log_scale = TRUE     )   )  x %>%   select(geo_value, time_value, cases_gr5, cases_gr6) %>%   pivot_longer(     cols = starts_with(\"cases_gr\"),     names_to = \"method\",     values_to = \"gr\"   ) %>%   mutate(method = recode(method,     cases_gr5 = \"rel_change_log\",     cases_gr6 = \"linear_reg_log\"   )) %>%   ggplot(aes(x = time_value, y = gr)) +   geom_line(aes(col = method)) +   scale_color_manual(values = c(2, 4)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\") x %>%   select(geo_value, time_value, cases_gr7, cases_gr8) %>%   pivot_longer(     cols = starts_with(\"cases_gr\"),     names_to = \"method\",     values_to = \"gr\"   ) %>%   mutate(method = recode(method,     cases_gr7 = \"smooth_spline_log\",     cases_gr8 = \"trend_filter_log\"   )) %>%   ggplot(aes(x = time_value, y = gr)) +   geom_line(aes(col = method)) +   scale_color_manual(values = c(3, 6)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/growth_rate.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Estimate growth rates in signals","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/outliers.html","id":"outlier-detection","dir":"Articles","previous_headings":"","what":"Outlier detection","title":"Detect and correct outliers in signals","text":"detect_outlr() function allows us run multiple outlier detection methods given signal, (optionally) combine results methods. , ‚Äôll investigate outlier detection results following methods. Detection based rolling median, using detect_outlr_rm(), computes rolling median default window size n time points centered time point consideration, computes thresholds based multiplier times rolling IQR computed residuals. Detection based seasonal-trend decomposition using LOESS (STL), using detect_outlr_stl(), similar rolling median method replaces rolling median fitted values STL. Detection based STL decomposition, subtracting seasonality term predictions, may result extrema large seasonal variations considered outliers. outlier detection methods specified using tibble passed detect_outlr(), one row per method, whose columms specify outlier detection function, input arguments (nondefault values need supplied), abbreviated name method used tracking results. Abbreviations ‚Äúrm‚Äù ‚Äústl‚Äù can used built-detection functions detect_outlr_rm() detect_outlr_stl(), respectively. Additionally, ‚Äôll form combined lower upper thresholds, calculated median lower upper thresholds methods time point. Note using combined median threshold equivalent using majority vote across base methods determine whether value outlier. visualize results, first define convenience function plotting. Now produce plots state time, faceting detection method.","code":"detection_methods <- bind_rows(   tibble(     method = \"rm\",     args = list(list(       detect_negatives = TRUE,       detection_multiplier = 2.5     )),     abbr = \"rm\"   ),   tibble(     method = \"stl\",     args = list(list(       detect_negatives = TRUE,       detection_multiplier = 2.5,       seasonal_period = 7     )),     abbr = \"stl_seasonal\"   ),   tibble(     method = \"stl\",     args = list(list(       detect_negatives = TRUE,       detection_multiplier = 2.5,       seasonal_period = 7,       seasonal_as_residual = TRUE     )),     abbr = \"stl_reseasonal\"   ) )  detection_methods #> # A tibble: 3 √ó 3 #>   method args             abbr           #>   <chr>  <list>           <chr>          #> 1 rm     <named list [2]> rm             #> 2 stl    <named list [3]> stl_seasonal   #> 3 stl    <named list [4]> stl_reseasonal x <- x %>%   group_by(geo_value) %>%   mutate(     outlier_info = detect_outlr(       x = time_value,       y = cases,       methods = detection_methods,       combiner = \"median\"     )   ) %>%   ungroup() %>%   unnest(outlier_info)  head(x) #> An `epi_df` object, 6 x 15 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-10-28 #>  #> # A tibble: 6 √ó 15 #>   geo_value time_value cases rm_lower rm_upper rm_replacement #> * <chr>     <date>     <dbl>    <dbl>    <dbl>          <dbl> #> 1 fl        2020-06-01   667    345      2195             667 #> 2 nj        2020-06-01   486     64.4     926.            486 #> 3 fl        2020-06-02   617    406.     2169.            617 #> 4 nj        2020-06-02   658    140.      841.            658 #> 5 fl        2020-06-03  1317    468.     2142.           1317 #> 6 nj        2020-06-03   541    216       756             541 #> # ‚Ñπ 9 more variables: stl_seasonal_lower <dbl>, stl_seasonal_upper <dbl>, #> #   stl_seasonal_replacement <dbl>, stl_reseasonal_lower <dbl>, ‚Ä¶ # Plot outlier detection bands and/or points identified as outliers plot_outlr <- function(x, signal, method_abbr, bands = TRUE, points = TRUE,                        facet_vars = vars(.data$geo_value), nrow = NULL, ncol = NULL,                        scales = \"fixed\") {   # Convert outlier detection results to long format   signal <- rlang::enquo(signal)   x_long <- x %>%     pivot_longer(       cols = starts_with(method_abbr),       names_to = c(\"method\", \".value\"),       names_pattern = \"(.+)_(.+)\"     )    # Start of plot with observed data   p <- ggplot() +     geom_line(data = x, mapping = aes(x = .data$time_value, y = !!signal))    # If requested, add bands   if (bands) {     p <- p + geom_ribbon(       data = x_long,       aes(         x = .data$time_value, ymin = .data$lower, ymax = .data$upper,         color = .data$method       ), fill = NA     )   }    # If requested, add points   if (points) {     x_detected <- x_long %>% filter((!!signal < .data$lower) | (!!signal > .data$upper))     p <- p + geom_point(       data = x_detected,       aes(         x = .data$time_value, y = !!signal, color = .data$method,         shape = .data$method       )     )   }    # If requested, add faceting   if (!is.null(facet_vars)) {     p <- p + facet_wrap(facet_vars, nrow = nrow, ncol = ncol, scales = scales)   }    return(p) } method_abbr <- c(detection_methods$abbr, \"combined\")  plot_outlr(x %>% filter(geo_value == \"fl\"), cases, method_abbr,   facet_vars = vars(method), scales = \"free_y\", ncol = 1 ) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(     x = \"Date\", y = \"Reported COVID-19 counts\", color = \"Method\",     shape = \"Method\"   ) plot_outlr(x %>% filter(geo_value == \"nj\"), cases, method_abbr,   facet_vars = vars(method), scales = \"free_y\", ncol = 1 ) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(     x = \"Date\", y = \"Reported COVID-19 counts\", color = \"Method\",     shape = \"Method\"   )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/outliers.html","id":"outlier-correction","dir":"Articles","previous_headings":"","what":"Outlier correction","title":"Detect and correct outliers in signals","text":"Finally, order correct outliers, can use posited replacement values returned outlier detection method. use replacement value combined method, defined median replacement values base methods time point.  advanced correction functionality coming point future.","code":"y <- x %>%   mutate(cases_corrected = combined_replacement) %>%   select(geo_value, time_value, cases, cases_corrected)  y %>% filter(cases != cases_corrected) #> An `epi_df` object, 22 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-10-28 #>  #> # A tibble: 22 √ó 4 #>   geo_value time_value cases cases_corrected #> * <chr>     <date>     <dbl>           <dbl> #> 1 fl        2020-07-12 15300          10181  #> 2 nj        2020-07-19    -8            320. #> 3 nj        2020-08-13   694            404. #> 4 nj        2020-08-14   619            397. #> 5 nj        2020-08-16    40            366  #> 6 nj        2020-08-22   555            360  #> # ‚Ñπ 16 more rows  ggplot(y, aes(x = time_value)) +   geom_line(aes(y = cases), linetype = 2) +   geom_line(aes(y = cases_corrected), col = 2) +   geom_hline(yintercept = 0, linetype = 3) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 counts\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/articles/outliers.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Detect and correct outliers in signals","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jacob Bien. Contributor. Logan Brooks. Author, maintainer. Rafael Catoia. Contributor. Nat DeFries. Contributor. Daniel McDonald. Author. Rachel Lobay. Contributor. Ken Mawer. Contributor. Chloe . Contributor. Quang Nguyen. Contributor. Evan Ray. Author. Dmitry Shemetov. Author. Ryan Tibshirani. Author. David Weber. Contributor. Lionel Henry. Contributor.           Author included rlang fragments Hadley Wickham. Contributor.           Author included rlang fragments Posit. Copyright holder.           Copyright holder included rlang fragments Johns Hopkins University Center Systems Science Engineering. Data contributor.           Owner COVID-19 cases deaths data COVID-19 Data Repository Johns Hopkins University. Copyright holder.           Copyright holder COVID-19 cases deaths data COVID-19 Data Repository Carnegie Mellon University Delphi Group. Data contributor.           Owner claims-based CLI data Delphi Epidata API","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Brooks L, McDonald D, Ray E, Shemetov D, Tibshirani R (2024). epiprocess: Tools basic signal processing epidemiology. R package version 0.10.0, https://cmu-delphi.github.io/epiprocess/.","code":"@Manual{,   title = {epiprocess: Tools for basic signal processing in epidemiology},   author = {Logan Brooks and Daniel McDonald and Evan Ray and Dmitry Shemetov and Ryan Tibshirani},   year = {2024},   note = {R package version 0.10.0},   url = {https://cmu-delphi.github.io/epiprocess/}, }"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/index.html","id":"epiprocess","dir":"","previous_headings":"","what":"Tools for basic signal processing in epidemiology","title":"Tools for basic signal processing in epidemiology","text":"epiprocess package works epidemiological time series data provides tools manage, analyze, process data preparation modeling. designed work tandem epipredict, provides pre-built epiforecasting models well tools build custom models. packages designed lower barrier entry implementation cost epidemiological time series analysis forecasting. epiprocess contains: epi_df working snapshot data single point time epi_archive working histories data changes time one common uses epi_archive accurate backtesting forecasting models, see vignette(\"backtesting\",     package=\"epipredict\") epi_slide() sliding window operations (aids feature creation) epix_slide() sliding window operations archives (aids backtesting) growth_rate() computing growth rates detect_outlr() outlier detection epi_cor() computing correlations new set tools, may interested learning book format: Introduction Epidemiological Forecasting. may also interested : epidatr, accessing wide range epidemiological data sets, including COVID-19 data, flu data, . rtestim, package estimating time-varying reproduction number epidemic. package provided Delphi group Carnegie Mellon University.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for basic signal processing in epidemiology","text":"install: package yet CRAN.","code":"# Stable version pak::pkg_install(\"cmu-delphi/epiprocess@main\")  # Dev version pak::pkg_install(\"cmu-delphi/epiprocess@dev\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Tools for basic signal processing in epidemiology","text":"epiprocess epidatr installed, can use following code get started: Get COVID-19 confirmed cumulative case data JHU CSSE California, Florida, New York, Texas, March 1, 2020 January 31, 2022 Convert data epi_df object sort geo_value time_value. can work epi_df like can tibble using dplyr verbs Compute 7 day moving average confirmed daily cases geo_value Autoplot confirmed daily cases geo_value","code":"library(epiprocess) library(epidatr) library(dplyr) library(magrittr) df <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_cumulative_num\",   geo_type = \"state\",   time_type = \"day\",   geo_values = \"ca,fl,ny,tx\",   time_values = epirange(20200301, 20220131),   as_of = as.Date(\"2024-01-01\") ) %>%   select(geo_value, time_value, cases_cumulative = value) df #> # A tibble: 2,808 √ó 3 #>   geo_value time_value cases_cumulative #>   <chr>     <date>                <dbl> #> 1 ca        2020-03-01               19 #> 2 fl        2020-03-01                0 #> 3 ny        2020-03-01                0 #> 4 tx        2020-03-01                0 #> 5 ca        2020-03-02               23 #> 6 fl        2020-03-02                1 #> # ‚Ñπ 2,802 more rows edf <- df %>%   as_epi_df(as_of = as.Date(\"2024-01-01\")) %>%   arrange_canonical() %>%   group_by(geo_value) %>%   mutate(cases_daily = cases_cumulative - lag(cases_cumulative, default = 0)) edf #> An `epi_df` object, 2,808 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-01-01 #>  #> # A tibble: 2,808 √ó 4 #> # Groups:   geo_value [4] #>   geo_value time_value cases_cumulative cases_daily #> * <chr>     <date>                <dbl>       <dbl> #> 1 ca        2020-03-01               19          19 #> 2 ca        2020-03-02               23           4 #> 3 ca        2020-03-03               29           6 #> 4 ca        2020-03-04               40          11 #> 5 ca        2020-03-05               50          10 #> 6 ca        2020-03-06               68          18 #> # ‚Ñπ 2,802 more rows edf <- edf %>%   group_by(geo_value) %>%   epi_slide_mean(cases_daily, .window_size = 7, na.rm = TRUE, .prefix = \"smoothed_\") edf #> An `epi_df` object, 2,808 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-01-01 #>  #> # A tibble: 2,808 √ó 5 #> # Groups:   geo_value [4] #>   geo_value time_value cases_cumulative cases_daily smoothed_cases_daily #> * <chr>     <date>                <dbl>       <dbl>                <dbl> #> 1 ca        2020-03-01               19          19                19    #> 2 ca        2020-03-02               23           4                11.5  #> 3 ca        2020-03-03               29           6                 9.67 #> 4 ca        2020-03-04               40          11                10    #> 5 ca        2020-03-05               50          10                10    #> 6 ca        2020-03-06               68          18                11.3  #> # ‚Ñπ 2,802 more rows edf %>%   autoplot(smoothed_cases_daily)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/apply_compactify.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a tibble as would be found in an epi_archive, remove duplicate entries. ‚Äî apply_compactify","title":"Given a tibble as would be found in an epi_archive, remove duplicate entries. ‚Äî apply_compactify","text":"Works shifting rows except version, comparing values see changed. need arrange descending order, note need group, since least one column version changed, kept.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/apply_compactify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a tibble as would be found in an epi_archive, remove duplicate entries. ‚Äî apply_compactify","text":"","code":"apply_compactify(df, keys, tolerance = .Machine$double.eps^0.5)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/arrange_canonical.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrange an epi_df into a standard order ‚Äî arrange_canonical","title":"Arrange an epi_df into a standard order ‚Äî arrange_canonical","text":"Moves key_colnames() left, arranges rows based ordering. function mainly use tests function output predictable order, necessary.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/arrange_canonical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrange an epi_df into a standard order ‚Äî arrange_canonical","text":"","code":"arrange_canonical(x, ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/arrange_canonical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrange an epi_df into a standard order ‚Äî arrange_canonical","text":"x epi_df. objects produce warning return . ... used","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_slide_computation.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a epi[x]_slide computation function from a function, formula, or quosure ‚Äî as_slide_computation","title":"Generate a epi[x]_slide computation function from a function, formula, or quosure ‚Äî as_slide_computation","text":"as_slide_computation() transforms one-sided formula quosure function; functions returned -light modifications calculate ref_time_value. code extends rlang::as_function create functions take three arguments. arguments can accessed via idiomatic ., .x, .y, extended include .z; positional references ..1 ..2, extended include ..3; also epi[x]_slide-specific names .group_key .ref_time_value.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_slide_computation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a epi[x]_slide computation function from a function, formula, or quosure ‚Äî as_slide_computation","text":"","code":"as_slide_computation(   .f,   ...,   .f_arg = caller_arg(.f),   .call = caller_env(),   .ref_time_value_long_varnames,   .ref_time_value_label )  as_time_slide_computation(   .f,   ...,   .f_arg = caller_arg(.f),   .call = caller_env() )  as_diagonal_slide_computation(   .f,   ...,   .f_arg = caller_arg(.f),   .call = caller_env() )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_slide_computation.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Generate a epi[x]_slide computation function from a function, formula, or quosure ‚Äî as_slide_computation","text":"code documentation based as_function Hadley Wickham's rlang package. original license rlang package. MIT License Copyright (c) 2020 rlang authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (\"Software\"), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED \"\", WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE. Portions original code used adaptation: Much documentation examples general flow function, including branching conditions Error conditions wording chunk converting formula function, see https://github.com/r-lib/rlang/blob/c55f6027928d3104ed449e591e8a225fcaf55e13/R/fn.R#L411-L418 Changes made include: Updates documentation due new functionality removal function--string processing logic helper arg env addition output function wrapper defines data mask evaluating quosures Calling argument-checking function Replacing rlang error functions internal error functions","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_slide_computation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a epi[x]_slide computation function from a function, formula, or quosure ‚Äî as_slide_computation","text":"... Additional arguments pass function formula specified via x. x quosure, arguments passed via ... ignored. .ref_time_value_long_varnames Character vector. variable names allow formulas data-masking tidy evaluation use refer ref_time_value computation (addition .z formulas)? E.g., \".ref_time_value\" c(\".ref_time_value\", \".version\"). .ref_time_value_label String; describe/label ref_time_value error messages; e.g., \"reference time value\" \"version\". f function, one-sided formula, quosure. function, function returned -, modifications. formula, e.g. ~ mean(.x$cases), converted function three arguments: .x (single argument), .x .y (two arguments), .x, .y, .z (three arguments). . placeholder can used instead .x, .group_key can used place .y, .ref_time_value can used place .z. allows create compact anonymous functions (lambdas) three inputs. Functions created formulas special class. Use inherits(fn, \"epiprocess_slide_computation\") test . quosure, case f provided parent epi[x]_slide call ... interpreted expression tidy evaluation, evaluated within wrapper function. wrapper sets object access via data mask.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tibble.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to tibble ‚Äî as_tibble.epi_df","title":"Convert to tibble ‚Äî as_tibble.epi_df","text":"Converts epi_df object tibble, dropping metadata grouping.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tibble.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to tibble ‚Äî as_tibble.epi_df","text":"","code":"# S3 method for class 'epi_df' as_tibble(x, ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tibble.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to tibble ‚Äî as_tibble.epi_df","text":"x epi_df ... Unused, extensibility.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tibble.epi_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert to tibble ‚Äî as_tibble.epi_df","text":"Advanced: working third-party package uses as_tibble() epi_dfs actually want remain epi_dfs, use attr(your_epi_df, \"decay_to_tibble\") <- FALSE beforehand.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tsibble.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to tsibble format ‚Äî as_tsibble.epi_df","title":"Convert to tsibble format ‚Äî as_tsibble.epi_df","text":"Converts epi_df object tsibble, index taken time_value, key variables taken geo_value along others other_keys field metadata, else explicitly set.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tsibble.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to tsibble format ‚Äî as_tsibble.epi_df","text":"","code":"# S3 method for class 'epi_df' as_tsibble(x, key, ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/as_tsibble.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to tsibble format ‚Äî as_tsibble.epi_df","text":"x epi_df key Optional. additional keys (geo_value) add tsibble. ... additional arguments passed tsibble::as_tsibble()","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/assert_sufficient_f_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert that a sliding computation function takes enough args ‚Äî assert_sufficient_f_args","title":"Assert that a sliding computation function takes enough args ‚Äî assert_sufficient_f_args","text":"Assert sliding computation function takes enough args","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/assert_sufficient_f_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert that a sliding computation function takes enough args ‚Äî assert_sufficient_f_args","text":"","code":"assert_sufficient_f_args(.f, ..., .ref_time_value_label)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/assert_sufficient_f_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert that a sliding computation function takes enough args ‚Äî assert_sufficient_f_args","text":"... Dots forwarded f dots epi_slide epix_slide. .ref_time_value_label String; describe/label ref_time_value error messages; e.g., \"reference time value\" \"version\". f Function; specifies computation slide epi_df epi_archive epi_slide epix_slide.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/autoplot.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically plot an epi_df ‚Äî autoplot.epi_df","title":"Automatically plot an epi_df ‚Äî autoplot.epi_df","text":"Automatically plot epi_df","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/autoplot.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically plot an epi_df ‚Äî autoplot.epi_df","text":"","code":"# S3 method for class 'epi_df' autoplot(   object,   ...,   .color_by = c(\"all_keys\", \"geo_value\", \"other_keys\", \".response\", \"all\", \"none\"),   .facet_by = c(\".response\", \"other_keys\", \"all_keys\", \"geo_value\", \"all\", \"none\"),   .base_color = \"#3A448F\",   .max_facets = Inf )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/autoplot.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically plot an epi_df ‚Äî autoplot.epi_df","text":"object epi_df ... <tidy-select> One unquoted expressions separated commas. Variable names can used positions data frame, expressions like x:y can used select range variables. .color_by variables determine color(s) used plot lines. Options include: all_keys - default uses interaction key variables including geo_value geo_value - geo_value other_keys - available keys geo_value .response - numeric variables (y-axis) - uses interaction keys numeric variables none - coloring aesthetic applied .facet_by Similar .color_by except default display numeric variable separate facet .base_color Lines shown color. example, single numeric variable faceting geo_value, locations share color line. .max_facets Cut number facets displayed. Especially useful testing many geo_value's keys.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/autoplot.epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatically plot an epi_df ‚Äî autoplot.epi_df","text":"ggplot object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/autoplot.epi_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatically plot an epi_df ‚Äî autoplot.epi_df","text":"","code":"autoplot(cases_deaths_subset, cases, death_rate_7d_av)  autoplot(cases_deaths_subset, case_rate_7d_av, .facet_by = \"geo_value\")  autoplot(cases_deaths_subset, case_rate_7d_av,   .color_by = \"none\",   .facet_by = \"geo_value\" )  autoplot(cases_deaths_subset, case_rate_7d_av,   .color_by = \"none\",   .base_color = \"red\", .facet_by = \"geo_value\" )   # .base_color specification won't have any effect due .color_by default autoplot(cases_deaths_subset, case_rate_7d_av,   .base_color = \"red\", .facet_by = \"geo_value\" )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/check_ukey_unique.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that a unique key is indeed unique in a tibble (TRUE/str) ‚Äî check_ukey_unique","title":"Check that a unique key is indeed unique in a tibble (TRUE/str) ‚Äî check_ukey_unique","text":"checkmate-style check function.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/check_ukey_unique.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that a unique key is indeed unique in a tibble (TRUE/str) ‚Äî check_ukey_unique","text":"","code":"check_ukey_unique(x, ukey_names, end_cli_message = character())"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/check_ukey_unique.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that a unique key is indeed unique in a tibble (TRUE/str) ‚Äî check_ukey_unique","text":"x tibble, particular row column order (guaranteed row order based ukey can probably something efficient) ukey_names character vector; subset column names x denoting unique key. end_cli_message optional character vector, cli message format string/vector; information/advice tack onto error messages.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/check_ukey_unique.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that a unique key is indeed unique in a tibble (TRUE/str) ‚Äî check_ukey_unique","text":"TRUE ukey duplicated (.e., x[ukey_names] duplicated rows); string error message errors.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/clone.html","id":null,"dir":"Reference","previous_headings":"","what":"Clone an epi_archive object. ‚Äî clone","title":"Clone an epi_archive object. ‚Äî clone","text":"Clone epi_archive object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/clone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clone an epi_archive object. ‚Äî clone","text":"","code":"clone(x)  # S3 method for class 'epi_archive' clone(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/clone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clone an epi_archive object. ‚Äî clone","text":"x epi_archive object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/complete.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"","title":"","text":"tidyr::complete() analogue epi_df objects. function can used, example, add rows missing combinations geo_value time_value, filling columns NAs. See examples usage details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/complete.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"","text":"","code":"# S3 method for class 'epi_df' complete(data, ..., fill = list(), explicit = TRUE)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/complete.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"","text":"data epi_df ... see tidyr::complete fill see tidyr::complete explicit see tidyr::complete","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/complete.epi_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"","text":"","code":"start_date <- as.Date(\"2020-01-01\") daily_edf <- tibble::tribble(   ~geo_value, ~time_value, ~value,   1, start_date + 1, 1,   1, start_date + 3, 3,   2, start_date + 2, 2,   2, start_date + 3, 3, ) %>%   as_epi_df(as_of = start_date + 3) # Complete without grouping puts all the geo_values on the same min and max # time_value index daily_edf %>%   complete(geo_value, time_value = full_seq(time_value, period = 1)) #> An `epi_df` object, 6 x 3 with metadata: #> * geo_type  = hhs #> * time_type = day #> * as_of     = 2020-01-04 #>  #> # A tibble: 6 √ó 3 #>   geo_value time_value value #> *     <dbl> <date>     <dbl> #> 1         1 2020-01-02     1 #> 2         1 2020-01-03    NA #> 3         1 2020-01-04     3 #> 4         2 2020-01-02    NA #> 5         2 2020-01-03     2 #> 6         2 2020-01-04     3 # Complete with grouping puts all the geo_values on individual min and max # time_value indices daily_edf %>%   group_by(geo_value) %>%   complete(time_value = full_seq(time_value, period = 1)) #> An `epi_df` object, 5 x 3 with metadata: #> * geo_type  = hhs #> * time_type = day #> * as_of     = 2020-01-04 #>  #> # A tibble: 5 √ó 3 #> # Groups:   geo_value [2] #>   geo_value time_value value #> *     <dbl> <date>     <dbl> #> 1         1 2020-01-02     1 #> 2         1 2020-01-03    NA #> 3         1 2020-01-04     3 #> 4         2 2020-01-03     2 #> 5         2 2020-01-04     3 # Complete has explicit=TRUE by default, but if it's FALSE, then complete # only fills the implicit gaps, not those that are explicitly NA daily_edf <- tibble::tribble(   ~geo_value, ~time_value, ~value,   1, start_date + 1, 1,   1, start_date + 2, NA,   1, start_date + 3, 3,   2, start_date + 2, 2,   2, start_date + 3, 3, ) %>%   as_epi_df(as_of = start_date + 3) daily_edf %>%   complete(     geo_value,     time_value = full_seq(time_value, period = 1),     fill = list(value = 0),     explicit = FALSE   ) #> An `epi_df` object, 6 x 3 with metadata: #> * geo_type  = hhs #> * time_type = day #> * as_of     = 2020-01-04 #>  #> # A tibble: 6 √ó 3 #>   geo_value time_value value #> *     <dbl> <date>     <dbl> #> 1         1 2020-01-02     1 #> 2         1 2020-01-03    NA #> 3         1 2020-01-04     3 #> 4         2 2020-01-02     0 #> 5         2 2020-01-03     2 #> 6         2 2020-01-04     3 # Complete works for weekly data and can take a fill value # No grouping weekly_edf <- tibble::tribble(   ~geo_value, ~time_value, ~value,   1, start_date + 1, 1,   1, start_date + 15, 3,   2, start_date + 8, 2,   2, start_date + 15, 3, ) %>%   as_epi_df(as_of = start_date + 3) weekly_edf %>%   complete(     geo_value,     time_value = full_seq(time_value, period = 7),     fill = list(value = 0)   ) #> An `epi_df` object, 6 x 3 with metadata: #> * geo_type  = hhs #> * time_type = week #> * as_of     = 2020-01-04 #>  #> # A tibble: 6 √ó 3 #>   geo_value time_value value #> *     <dbl> <date>     <dbl> #> 1         1 2020-01-02     1 #> 2         1 2020-01-09     0 #> 3         1 2020-01-16     3 #> 4         2 2020-01-02     0 #> 5         2 2020-01-09     2 #> 6         2 2020-01-16     3 # With grouping weekly_edf %>%   group_by(geo_value) %>%   complete(     time_value = full_seq(time_value, period = 7),     fill = list(value = 0)   ) #> An `epi_df` object, 5 x 3 with metadata: #> * geo_type  = hhs #> * time_type = week #> * as_of     = 2020-01-04 #>  #> # A tibble: 5 √ó 3 #> # Groups:   geo_value [2] #>   geo_value time_value value #> *     <dbl> <date>     <dbl> #> 1         1 2020-01-02     1 #> 2         1 2020-01-09     0 #> 3         1 2020-01-16     3 #> 4         2 2020-01-09     2 #> 5         2 2020-01-16     3"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/decay_epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop any epi_df metadata and class on a data frame ‚Äî decay_epi_df","title":"Drop any epi_df metadata and class on a data frame ‚Äî decay_epi_df","text":"Useful implementing ?dplyr_extending manipulations cause invariants epi_dfs violated need return class. Note maintain grouping (keeping grouped_df class associated attributes, present).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/decay_epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop any epi_df metadata and class on a data frame ‚Äî decay_epi_df","text":"","code":"decay_epi_df(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/decay_epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop any epi_df metadata and class on a data frame ‚Äî decay_epi_df","text":"x epi_df data frame","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/decay_epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop any epi_df metadata and class on a data frame ‚Äî decay_epi_df","text":"x metadata dropped \"epi_df\" class, previously present, dropped","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/deprecated_quo_is_present.html","id":null,"dir":"Reference","previous_headings":"","what":"lifecycle::is_present for enquosed deprecated NSE arg ‚Äî deprecated_quo_is_present","title":"lifecycle::is_present for enquosed deprecated NSE arg ‚Äî deprecated_quo_is_present","text":"lifecycle::is_present designed use args undergo standard evaluation, rather non-standard evaluation (NSE). function designed fulfill similar purpose, args enquosed preparation NSE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/deprecated_quo_is_present.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"lifecycle::is_present for enquosed deprecated NSE arg ‚Äî deprecated_quo_is_present","text":"","code":"deprecated_quo_is_present(quo)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/deprecated_quo_is_present.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"lifecycle::is_present for enquosed deprecated NSE arg ‚Äî deprecated_quo_is_present","text":"quo enquosed arg","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/deprecated_quo_is_present.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"lifecycle::is_present for enquosed deprecated NSE arg ‚Äî deprecated_quo_is_present","text":"bool; quo \"present\", look like missing quosure expr looked like deprecated() lifecycle::deprecated()?","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/deprecated_quo_is_present.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"lifecycle::is_present for enquosed deprecated NSE arg ‚Äî deprecated_quo_is_present","text":"","code":"fn <- function(x = deprecated()) {   deprecated_quo_is_present(rlang::enquo(x)) }  fn() # FALSE #> [1] FALSE fn(.data$something) # TRUE #> [1] TRUE  # Functions that wrap `fn` should forward the NSE arg to `fn` using # [`{{ arg }}`][rlang::embrace-operator] (or, if they are working from an # argument that has already been defused into a quosure, `!!quo`). (This is # already how NSE arguments that will be enquosed should be forwarded.)  wrapper1 <- function(x = deprecated()) fn({{ x }}) wrapper2 <- function(x = lifecycle::deprecated()) fn({{ x }}) wrapper3 <- function(x) fn({{ x }}) wrapper4 <- function(x) fn(!!rlang::enquo(x))  wrapper1() # FALSE #> [1] FALSE wrapper2() # FALSE #> [1] FALSE wrapper3() # FALSE #> [1] FALSE wrapper4() # FALSE #> [1] FALSE  # More advanced: wrapper that receives an already-enquosed arg:  inner_wrapper <- function(quo) fn(!!quo) outer_wrapper1 <- function(x = deprecated()) inner_wrapper(rlang::enquo(x))  outer_wrapper1() # FALSE #> [1] FALSE  # Improper argument forwarding from a wrapper function will cause this # function to produce incorrect results. bad_wrapper1 <- function(x) fn(x) bad_wrapper1() # TRUE, bad #> [1] TRUE"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/detect_outlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect outliers ‚Äî detect_outlr","title":"Detect outliers ‚Äî detect_outlr","text":"Applies one outlier detection methods given signal variable, optionally aggregates outputs create consensus result. See outliers vignette examples. detect_outlr_rm detects outliers based distance rolling median specified terms multiples rolling interquartile range (IQR). detect_outlr_stl detects outliers based seasonal-trend decomposition using LOESS (STL).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/detect_outlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect outliers ‚Äî detect_outlr","text":"","code":"detect_outlr(   x = seq_along(y),   y,   methods = tibble::tibble(method = \"rm\", args = list(list()), abbr = \"rm\"),   combiner = c(\"median\", \"mean\", \"none\") )  detect_outlr_rm(   x = seq_along(y),   y,   n = 21,   log_transform = FALSE,   detect_negatives = FALSE,   detection_multiplier = 2,   min_radius = 0,   replacement_multiplier = 0 )  detect_outlr_stl(   x = seq_along(y),   y,   n_trend = 21,   n_seasonal = 21,   n_threshold = 21,   seasonal_period,   seasonal_as_residual = FALSE,   log_transform = FALSE,   detect_negatives = FALSE,   detection_multiplier = 2,   min_radius = 0,   replacement_multiplier = 0 )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/detect_outlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect outliers ‚Äî detect_outlr","text":"x Design points corresponding signal values y. Default seq_along(y) (, equally-spaced points 1 length y). y Signal values. methods tibble specifying method(s) use outlier detection, one row per method, following columns: method: Either \"rm\" \"stl\", custom function outlier detection; see details explanation. args: Named list arguments passed detection method. abbr: Abbreviation use naming output columns results method. combiner String, one \"median\", \"mean\", \"none\", specifying combine results different outlier detection methods thresholds determining whether particular observation classified outlier, well replacement value outliers.  \"none\", summarized results calculated. Note number methods (number rows) odd, \"median\" equivalent majority vote purposes determining whether given observation outlier. n Number time steps use rolling window. Default 21. value centrally aligned. n odd number, rolling window extends (n-1)/2 time steps design point (n-1)/2 time steps . n even, rolling range extends n/2-1 time steps n/2 time steps . log_transform log transform applied running outlier detection? Default FALSE. TRUE, zeros present, log transform padded 1. detect_negatives negative values automatically count outliers? Default FALSE. detection_multiplier Value determining far outlier detection thresholds rolling median, calculated (rolling median) +/- (detection multiplier) * (rolling IQR). Default 2. min_radius Minimum distance rolling median threshold, transformed scale. Default 0. replacement_multiplier Value determining far replacement values rolling median. replacement original value within detection thresholds, otherwise rounded nearest (rolling median) +/- (replacement multiplier) * (rolling IQR). Default 0. n_trend Number time steps use rolling window trend. Default 21. n_seasonal Number time steps use rolling window seasonality. Default 21. Can also string \"periodic\". See s.window stats::stl. n_threshold Number time steps use rolling window IQR outlier thresholds. seasonal_period Integer specifying period \"seasonality\". example, daily data, period 7 means weekly seasonality. must strictly larger 1. Also impacts size low-pass filter window; see l.window stats::stl. seasonal_as_residual Boolean specifying whether seasonal(/weekly) component treated part residual component instead part predictions. default, FALSE, treats part predictions, large seasonal(/weekly) components lead flagging points outliers. TRUE may instead consider extrema large seasonal variations outliers; n_seasonal seasonal_period still impact result, though, impacting estimation trend component.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/detect_outlr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect outliers ‚Äî detect_outlr","text":"tibble number rows equal length(y) columns giving outlier detection thresholds (lower upper) replacement values detection method (replacement).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/detect_outlr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect outliers ‚Äî detect_outlr","text":"outlier detection method, one per row passed methods tibble, function must take first two arguments x y, number additional arguments. function must return tibble number rows equal length(y), columns lower, upper, replacement, representing lower upper bounds considered outlier, posited replacement value, respectively. convenience, outlier detection method can specified (method column methods) string \"rm\", shorthand detect_outlr_rm(), detects outliers via rolling median; \"stl\", shorthand detect_outlr_stl(), detects outliers via STL decomposition. STL decomposition computed using stats::stl(). computed, outlier detection method analogous rolling median method detect_outlr_rm(), except fitted values residuals STL decomposition taking place rolling median residuals rolling median, respectively. last set arguments, log_transform replacement_multiplier, exactly detect_outlr_rm().","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/detect_outlr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect outliers ‚Äî detect_outlr","text":"","code":"detection_methods <- dplyr::bind_rows(   dplyr::tibble(     method = \"rm\",     args = list(list(       detect_negatives = TRUE,       detection_multiplier = 2.5     )),     abbr = \"rm\"   ),   dplyr::tibble(     method = \"stl\",     args = list(list(       detect_negatives = TRUE,       detection_multiplier = 2.5,       seasonal_period = 7     )),     abbr = \"stl_seasonal\"   ),   dplyr::tibble(     method = \"stl\",     args = list(list(       detect_negatives = TRUE,       detection_multiplier = 2.5,       seasonal_period = 7,       seasonal_as_residual = TRUE     )),     abbr = \"stl_reseasonal\"   ) )  x <- covid_incidence_outliers %>%   dplyr::select(geo_value, time_value, cases) %>%   as_epi_df() %>%   group_by(geo_value) %>%   mutate(outlier_info = detect_outlr(     x = time_value, y = cases,     methods = detection_methods,     combiner = \"median\"   )) %>%   unnest(outlier_info) # Detect outliers based on a rolling median covid_incidence_outliers %>%   dplyr::select(geo_value, time_value, cases) %>%   as_epi_df() %>%   group_by(geo_value) %>%   mutate(outlier_info = detect_outlr_rm(     x = time_value, y = cases   )) #> An `epi_df` object, 730 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-10-28 #>  #> # A tibble: 730 √ó 4 #> # Groups:   geo_value [2] #>    geo_value time_value cases outlier_info$lower $upper $replacement #>  * <chr>     <date>     <dbl>              <dbl>  <dbl>        <dbl> #>  1 fl        2020-06-01   667               530   2010           667 #>  2 nj        2020-06-01   486               150.   840.          486 #>  3 fl        2020-06-02   617               582.  1992.          617 #>  4 nj        2020-06-02   658               210.   771.          658 #>  5 fl        2020-06-03  1317               635   1975          1317 #>  6 nj        2020-06-03   541               270    702           541 #>  7 fl        2020-06-04  1419               713   1909          1419 #>  8 nj        2020-06-04   478               174.   790.          478 #>  9 fl        2020-06-05  1305               553   2081          1305 #> 10 nj        2020-06-05   825               118.   838.          825 #> # ‚Ñπ 720 more rows # Detects outliers based on a seasonal-trend decomposition using LOESS covid_incidence_outliers %>%   dplyr::select(geo_value, time_value, cases) %>%   as_epi_df() %>%   group_by(geo_value) %>%   mutate(outlier_info = detect_outlr_stl(     x = time_value, y = cases,     seasonal_period = 7 # weekly seasonality for daily data   )) #> An `epi_df` object, 730 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-10-28 #>  #> # A tibble: 730 √ó 4 #> # Groups:   geo_value [2] #>    geo_value time_value cases outlier_info$lower $upper $replacement #>  * <chr>     <date>     <dbl>              <dbl>  <dbl>        <dbl> #>  1 fl        2020-06-01   667             -1193.  1233.          667 #>  2 nj        2020-06-01   486               281.   762.          486 #>  3 fl        2020-06-02   617              -691.  1890.          617 #>  4 nj        2020-06-02   658               317.   891.          658 #>  5 fl        2020-06-03  1317              -144.  2396.         1317 #>  6 nj        2020-06-03   541               292.   809.          541 #>  7 fl        2020-06-04  1419               260.  2696.         1419 #>  8 nj        2020-06-04   478               315.   792.          478 #>  9 fl        2020-06-05  1305               548.  2950.         1305 #> 10 nj        2020-06-05   825               382.   835.          825 #> # ‚Ñπ 720 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/difftime_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"summary doesn't work on difftimes ‚Äî difftime_summary","title":"summary doesn't work on difftimes ‚Äî difftime_summary","text":"summary work difftimes","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/difftime_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summary doesn't work on difftimes ‚Äî difftime_summary","text":"","code":"difftime_summary(diff_time_val)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/dplyr_reconstruct.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"dplyr_reconstruct ‚Äî dplyr_reconstruct.epi_df","title":"dplyr_reconstruct ‚Äî dplyr_reconstruct.epi_df","text":"dplyr_reconstruct","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/dplyr_reconstruct.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dplyr_reconstruct ‚Äî dplyr_reconstruct.epi_df","text":"","code":"# S3 method for class 'epi_df' dplyr_reconstruct(data, template)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/dplyr_reconstruct.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dplyr_reconstruct ‚Äî dplyr_reconstruct.epi_df","text":"data tibble epi_df (dplyr feeds former, may directly feed latter methods) template epi_df template use restore","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/dplyr_reconstruct.epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dplyr_reconstruct ‚Äî dplyr_reconstruct.epi_df","text":"epi_df degrade tbl_df","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"epi_archive object ‚Äî epi_archive","title":"epi_archive object ‚Äî epi_archive","text":"second main data structure storing time series epiprocess. similar epi_df fundamentally table required columns stores epidemiological time series data. epi_archive requires geo_value, time_value, version column (possibly key columns) along measurement values. brief, epi_archive history time series data, version column tracks time data available. allows version-aware forecasting. new_epi_archive constructor epi_archive objects assumes arguments validated. users use as_epi_archive.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object ‚Äî epi_archive","text":"","code":"new_epi_archive(   x,   geo_type,   time_type,   other_keys,   compactify,   clobberable_versions_start,   versions_end,   compactify_tol = .Machine$double.eps^0.5 )  validate_epi_archive(   x,   other_keys,   compactify,   clobberable_versions_start,   versions_end )  as_epi_archive(   x,   geo_type = deprecated(),   time_type = deprecated(),   other_keys = character(),   compactify = NULL,   clobberable_versions_start = NA,   .versions_end = max_version_with_row_in(x),   ...,   versions_end = .versions_end )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"epi_archive object ‚Äî epi_archive","text":"x data.frame, data.table, tibble, columns geo_value, time_value, version, additional number columns. geo_type DEPRECATED effect. Geo value type inferred location column set \"custom\" recognized. time_type DEPRECATED effect. Time value type inferred time column set \"custom\" recognized. Unpredictable behavior may result time type recognized. other_keys Character vector specifying names variables x considered key variables (language data.table) apart \"geo_value\", \"time_value\", \"version\". Typical examples \"age\" granular geographies. compactify Optional; Boolean. TRUE remove redundant rows, FALSE , missing NULL remove redundant rows, issue warning. See information compactify. clobberable_versions_start Optional; length-1; either value class typeof x$version, NA class typeof: specifically, either () earliest version subject \"clobbering\" (overwritten different update data, using version tag old update data), (b) NA, indicate versions clobberable. variety reasons versions clobberable routine circumstances, () today's version one/columns published initially filled NA LOCF, (b) buggy version today's data published fixed republished later day, (c) data pipeline delays (e.g., publisher uploading, periodic scraping, database syncing, periodic fetching, etc.) make events () (b) reflected later day (even different day) expected; potential causes vary different data pipelines. default value NA, consider versions clobberable. Another setting may appropriate pipelines max_version_with_row_in(x). versions_end Optional; length-1, class typeof x$version: last version observed? default max_version_with_row_in(x), values greater also valid, indicate observed additional versions data beyond max(x$version), contained empty updates. (default value clobberable_versions_start fully trust empty updates, assumes version >= max(x$version) clobbered.) nrow(x) == 0, argument mandatory. compactify_tol double. tolerance used detect approximate equality compactification .versions_end location based versions_end, used avoid prefix version = issue assigned versions_end instead used rename columns. ... used specifying column names, dplyr::rename. example version = release_date","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"epi_archive object ‚Äî epi_archive","text":"epi_archive object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"epi_archive object ‚Äî epi_archive","text":"epi_archive contains data.table object DT ({data.table} package), (least) following columns: geo_value: geographic value associated row measurements, time_value: time value associated row measurements, version: time value specifying version row measurements. example, given row version January 15, 2022 time_value January 14, 2022, row contains measurements data January 14, 2022 available one day later. variables geo_value, time_value, version serve key variables data table (addition keys specified metadata). can single row per unique combination key variables. keys epi_archive can viewed key(epi_archive$DT).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"compactification","dir":"Reference","previous_headings":"","what":"Compactification","title":"epi_archive object ‚Äî epi_archive","text":"default, epi_archive compactify data table remove redundant rows. done storing rows value, except version column (essentially last observation carried forward, along version index). done save space improve performance. want compactify data, can set compactify = FALSE as_epi_archive(). Note data scenarios, LOCF may appropriate. instance, expected data updated given day, data source update, reasonable code data NA day, instead assuming LOCF. NAs can introduced epi_archive methods reasons, e.g., epix_fill_through_version epix_merge, requested, represent potential update data yet access ; epix_merge represent \"value\" observation version first released, version observation appears archive data .","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"metadata","dir":"Reference","previous_headings":"","what":"Metadata","title":"epi_archive object ‚Äî epi_archive","text":"following pieces metadata included fields epi_archive object: geo_type: type geo values. time_type: type time values. other_keys: additional keys character vector. Typical examples \"age\" sub-geographies. metadata protected, generally recommended treat read-, use epi_archive methods interact data archive. Unexpected behavior may result modifying metadata directly.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"epi_archive object ‚Äî epi_archive","text":"","code":"# Simple ex. with necessary keys tib <- tibble::tibble(   geo_value = rep(c(\"ca\", \"hi\"), each = 5),   time_value = rep(seq(as.Date(\"2020-01-01\"),     by = 1, length.out = 5   ), times = 2),   version = rep(seq(as.Date(\"2020-01-02\"),     by = 1, length.out = 5   ), times = 2),   value = rnorm(10, mean = 2, sd = 1) )  toy_epi_archive <- tib %>% as_epi_archive() toy_epi_archive #> ‚Üí An `epi_archive` object, with metadata: #> ‚Ñπ Min/max time values: 2020-01-01 / 2020-01-05 #> ‚Ñπ First/last version with update: 2020-01-02 / 2020-01-06 #> ‚Ñπ Versions end: 2020-01-06 #> ‚Ñπ A preview of the table (10 rows x 4 columns): #> Key: <geo_value, time_value, version> #>     geo_value time_value    version      value #>        <char>     <Date>     <Date>      <num> #>  1:        ca 2020-01-01 2020-01-02  0.5999565 #>  2:        ca 2020-01-02 2020-01-03  2.2553171 #>  3:        ca 2020-01-03 2020-01-04 -0.4372636 #>  4:        ca 2020-01-04 2020-01-05  1.9944287 #>  5:        ca 2020-01-05 2020-01-06  2.6215527 #>  6:        hi 2020-01-01 2020-01-02  3.1484116 #>  7:        hi 2020-01-02 2020-01-03  0.1781823 #>  8:        hi 2020-01-03 2020-01-04  1.7526747 #>  9:        hi 2020-01-04 2020-01-05  1.7558004 #> 10:        hi 2020-01-05 2020-01-06  1.7172946  # Ex. with an additional key for county df <- data.frame(   geo_value = c(replicate(2, \"ca\"), replicate(2, \"fl\")),   county = c(1, 3, 2, 5),   time_value = c(     \"2020-06-01\",     \"2020-06-02\",     \"2020-06-01\",     \"2020-06-02\"   ),   version = c(     \"2020-06-02\",     \"2020-06-03\",     \"2020-06-02\",     \"2020-06-03\"   ),   cases = c(1, 2, 3, 4),   cases_rate = c(0.01, 0.02, 0.01, 0.05) )  x <- df %>% as_epi_archive(other_keys = \"county\") #> Warning: Unsupported time type in column `x$time_value`, with class `character`. #> Time-related functionality may have unexpected behavior."},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_cor.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute correlations between variables in an epi_df object ‚Äî epi_cor","title":"Compute correlations between variables in an epi_df object ‚Äî epi_cor","text":"Computes correlations variables epi_df object, allowing grouping geo value, time value, variables. See correlation vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_cor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute correlations between variables in an epi_df object ‚Äî epi_cor","text":"","code":"epi_cor(   x,   var1,   var2,   dt1 = 0,   dt2 = 0,   shift_by = geo_value,   cor_by = geo_value,   use = \"na.or.complete\",   method = c(\"pearson\", \"kendall\", \"spearman\") )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_cor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute correlations between variables in an epi_df object ‚Äî epi_cor","text":"x epi_df object consideration. var1, var2 variables x correlate. dt1, dt2 Time shifts consider two variables, respectively, computing correlations. Negative shifts translate lag value positive shifts lead value; example, dt = -1, new value June 2 original value June 1; dt = 1, new value June 2 original value June 3; dt = 0, values left . Default 0 dt1 dt2. shift_by variables(s) group , time shifts. default geo_value. However, also use, example, shift_by = c(geo_value, age_group), assuming x column age_group, perform time shifts per geo value age group. omit grouping entirely, use cor_by = NULL. Note grouping always undone correlation computations. cor_by variable(s) group , correlation computations. geo_value, default, correlations computed geo value, time; time_value, correlations computed time, geo values. grouping can also specified using number columns x; example, can use cor_by = c(geo_value, age_group), assuming x column age_group, order compute correlations pair geo value age group. omit grouping entirely, use cor_by = NULL. Note grouping always done time shifts. use, method Arguments pass cor(), \"na..complete\" default use (different cor()) \"pearson\" default method (cor()).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_cor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute correlations between variables in an epi_df object ‚Äî epi_cor","text":"tibble grouping columns first (geo_value, time_value, possibly others), column cor, gives correlation.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_cor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute correlations between variables in an epi_df object ‚Äî epi_cor","text":"","code":"# linear association of case and death rates on any given day epi_cor(   x = cases_deaths_subset,   var1 = case_rate_7d_av,   var2 = death_rate_7d_av,   cor_by = \"time_value\" ) #> Warning: There were 3 warnings in `dplyr::summarize()`. #> The first warning was: #> ‚Ñπ In argument: `cor = cor(x = .data$var1, y = .data$var2, use = use, method = #>   method)`. #> ‚Ñπ In group 1: `time_value = 2020-03-01`. #> Caused by warning in `cor()`: #> ! the standard deviation is zero #> ‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings. #> # A tibble: 671 √ó 2 #>    time_value    cor #>    <date>      <dbl> #>  1 2020-03-01 NA     #>  2 2020-03-02 NA     #>  3 2020-03-03 NA     #>  4 2020-03-04  0.746 #>  5 2020-03-05  0.549 #>  6 2020-03-06  0.692 #>  7 2020-03-07  0.277 #>  8 2020-03-08 -0.226 #>  9 2020-03-09 -0.195 #> 10 2020-03-10 -0.227 #> # ‚Ñπ 661 more rows  # correlation of death rates and lagged case rates epi_cor(   x = cases_deaths_subset,   var1 = case_rate_7d_av,   var2 = death_rate_7d_av,   cor_by = time_value,   dt1 = -2 ) #> Warning: There was 1 warning in `dplyr::summarize()`. #> ‚Ñπ In argument: `cor = cor(x = .data$var1, y = .data$var2, use = use, method = #>   method)`. #> ‚Ñπ In group 3: `time_value = 2020-03-03`. #> Caused by warning in `cor()`: #> ! the standard deviation is zero #> # A tibble: 671 √ó 2 #>    time_value    cor #>    <date>      <dbl> #>  1 2020-03-01 NA     #>  2 2020-03-02 NA     #>  3 2020-03-03 NA     #>  4 2020-03-04  0.989 #>  5 2020-03-05  0.907 #>  6 2020-03-06  0.746 #>  7 2020-03-07  0.549 #>  8 2020-03-08 -0.158 #>  9 2020-03-09 -0.126 #> 10 2020-03-10 -0.163 #> # ‚Ñπ 661 more rows  # correlation grouped by location epi_cor(   x = cases_deaths_subset,   var1 = case_rate_7d_av,   var2 = death_rate_7d_av,   cor_by = geo_value ) #> # A tibble: 6 √ó 2 #>   geo_value   cor #>   <chr>     <dbl> #> 1 ca        0.573 #> 2 fl        0.488 #> 3 ga        0.465 #> 4 ny        0.285 #> 5 pa        0.708 #> 6 tx        0.750  # correlation grouped by location and incorporates lagged cases rates epi_cor(   x = cases_deaths_subset,   var1 = case_rate_7d_av,   var2 = death_rate_7d_av,   cor_by = geo_value,   dt1 = -2 ) #> # A tibble: 6 √ó 2 #>   geo_value   cor #>   <chr>     <dbl> #> 1 ca        0.618 #> 2 fl        0.576 #> 3 ga        0.525 #> 4 ny        0.337 #> 5 pa        0.734 #> 6 tx        0.784"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for epi_df format ‚Äî as_epi_df","title":"Test for epi_df format ‚Äî as_epi_df","text":"One two main data structures storing time series epiprocess. simply tibble least two columns, geo_value time_value, provide keys time series. can columns, can seen measured variables key. brief, epi_df represents snapshot epidemiological data set point time.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for epi_df format ‚Äî as_epi_df","text":"","code":"as_epi_df(x, ...)  # S3 method for class 'epi_df' as_epi_df(x, ...)  # S3 method for class 'tbl_df' as_epi_df(   x,   geo_type = deprecated(),   time_type = deprecated(),   as_of,   other_keys = character(),   ... )  # S3 method for class 'grouped_df' as_epi_df(x, ...)  # S3 method for class 'data.frame' as_epi_df(x, as_of, other_keys = character(), ...)  # S3 method for class 'tbl_ts' as_epi_df(x, as_of, other_keys = character(), ...)  is_epi_df(x)  new_epi_df(   x = tibble::tibble(geo_value = character(), time_value = as.Date(integer())),   geo_type,   time_type,   as_of,   other_keys = character(),   ... )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for epi_df format ‚Äî as_epi_df","text":"x object. ... Additional arguments passed methods. geo_type as_epi_df(), effect; geo value type inferred location column set \"custom\" recognized. new_epi_df(), set value inferred. time_type as_epi_df(), effect: time value type inferred time column set \"custom\" recognized. Unpredictable behavior may result time type recognized. new_epi_df(), set value inferred. as_of Time value representing time given data available. example, as_of January 31, 2022, epi_df object created represent --date version data available January 31, 2022. as_of argument missing, current day-time used. other_keys tibble additional keys, sure specify character vector (typical examples \"age\" sub-geographies).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for epi_df format ‚Äî as_epi_df","text":"as_epi_df(): (ungrouped) epi_df is_epi_df: TRUE object inherits epi_df, otherwise FALSE. new_epi_df(): epi_df","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test for epi_df format ‚Äî as_epi_df","text":"epi_df tibble (least) following columns: geo_value: character vector representing geographical unit observation. country code, state name, county code, etc. time_value: date integer vector representing time observation. columns can considered measured variables, also refer signal variables. epi_df object also metadata (least) following fields: geo_type: type geo values. as_of: time value given data available. users use as_epi_df. input tibble x constructor must contain columns geo_value time_value. columns preserved , treated measured variables. as_of missing, function try guess as_of, issue, version column x (present), as_of field metadata (stored attributes); fails, current day-time used. new_epi_df constructor assumes arguments already validated, mainly used advanced users. Metadata epi_df object x can accessed (altered) via attributes(x)$metadata. first field list, geo_type, can usually inferred geo_value columns. currently used downstream functions epiprocess package, serve useful bits information convey data set hand. information coding given . last field list, as_of, one unique aspects epi_df object. brief, can think epi_df object single snapshot data set contains --date values signals variables, time specified as_of field. epi_df ever loses geo_value time_value columns, decay regular tibble. companion object epi_archive object, contains full version history given data set. Revisions common many types epidemiological data streams, paying attention data revisions can important sorts downstream data analysis modeling tasks. See documentation epi_archive details data versioning works epiprocess package (including generate epi_df objects, data snapshots, epi_archive object).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"geo-types","dir":"Reference","previous_headings":"","what":"Geo Types","title":"Test for epi_df format ‚Äî as_epi_df","text":"following geo types recognized epi_df. \"county\": observation corresponds U.S. county; coded 5-digit FIPS code. \"hrr\": observation corresponds U.S. hospital referral region (designed represent regional healthcare markets); 306 HRRs U.S; coded number (nonconsecutive, 1 457). \"state\": observation corresponds U.S. state; coded 2-digit postal abbreviation (lowercase); note Puerto Rico \"pr\" Washington D.C. \"dc\". \"hhs\": observation corresponds U.S. HHS region; coded number (consecutive, 1 10). \"nation\": observation corresponds country; coded ISO 31661- alpha-2 country codes (lowercase). unrecognizable geo type labeled \"custom\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"time-types","dir":"Reference","previous_headings":"","what":"Time Types","title":"Test for epi_df format ‚Äî as_epi_df","text":"following time types recognized epi_df. \"day\": observation corresponds day; coded Date object, .Date(\"2022-01-31\"). \"week\": observation corresponds week; alignment can arbitrary (whether week starts Monday, Tuesday); coded Date object, representing start date week. \"yearmonth\": observation corresponds month; coded tsibble::yearmonth object. \"integer\": generic integer index (e.g. years something else). unrecognizable time type labeled \"custom\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Test for epi_df format ‚Äî as_epi_df","text":"as_epi_df(): preferred way constructing epi_dfs new_epi_df(): Lower-level constructor epi_df object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for epi_df format ‚Äî as_epi_df","text":"","code":"# Convert a `tsibble` that has county code as an extra key # Notice that county code should be a character string to preserve any leading zeroes ex1_input <- tibble::tibble(   geo_value = c(     \"06059\", \"06061\", \"06067\",     \"12111\", \"12113\", \"12117\",     \"42101\", \"42103\", \"42105\"   ),   state_name = rep(c(\"ca\", \"fl\", \"pa\"), each = 3),   time_value = rep(seq(as.Date(\"2020-06-01\"), as.Date(\"2020-06-03\"),     by = \"day\"   ), length.out = length(geo_value)),   value = 1:length(geo_value) + 0.01 * rnorm(length(geo_value)) ) %>%   tsibble::as_tsibble(index = time_value, key = c(geo_value, state_name))  # The `other_keys` metadata (`\"state_name\"` in this case) is automatically # inferred from the `tsibble`'s `key`: ex1 <- as_epi_df(x = ex1_input, as_of = \"2020-06-03\") attr(ex1, \"metadata\")[[\"other_keys\"]] #> [1] \"state_name\"  # Dealing with misspecified column names: # Geographical and temporal information must be provided in columns named # `geo_value` and `time_value`; if we start from a data frame with a # different format, it must be converted to use `geo_value` and `time_value` # before calling `as_epi_df`. ex2_input <- tibble::tibble(   state = rep(c(\"ca\", \"fl\", \"pa\"), each = 3), # misnamed   pol = rep(c(\"blue\", \"swing\", \"swing\"), each = 3), # extra key   reported_date = rep(seq(as.Date(\"2020-06-01\"), as.Date(\"2020-06-03\"),     by = \"day\"   ), length.out = length(state)), # misnamed   value = 1:length(state) + 0.01 * rnorm(length(state)) ) print(ex2_input) #> # A tibble: 9 √ó 4 #>   state pol   reported_date value #>   <chr> <chr> <date>        <dbl> #> 1 ca    blue  2020-06-01    0.991 #> 2 ca    blue  2020-06-02    2.00  #> 3 ca    blue  2020-06-03    3.00  #> 4 fl    swing 2020-06-01    3.99  #> 5 fl    swing 2020-06-02    5.01  #> 6 fl    swing 2020-06-03    6.02  #> 7 pa    swing 2020-06-01    7.00  #> 8 pa    swing 2020-06-02    7.99  #> 9 pa    swing 2020-06-03    9.00   ex2 <- ex2_input %>%   dplyr::rename(geo_value = state, time_value = reported_date) %>%   as_epi_df(     as_of = \"2020-06-03\",     other_keys = \"pol\"   ) attr(ex2, \"metadata\") #> $geo_type #> [1] \"state\" #>  #> $time_type #> [1] \"day\" #>  #> $as_of #> [1] \"2020-06-03\" #>  #> $other_keys #> [1] \"pol\" #>   # Adding additional keys to an `epi_df` object ex3_input <- covid_incidence_county_subset %>%   dplyr::filter(time_value > \"2021-12-01\", state_name == \"Massachusetts\") %>%   dplyr::slice_tail(n = 6)  ex3 <- ex3_input %>%   tsibble::as_tsibble() %>% # needed to add the additional metadata   # add 2 extra keys   dplyr::mutate(     state = rep(\"MA\", 6),     pol = rep(c(\"blue\", \"swing\", \"swing\"), each = 2)   ) %>%   as_epi_df(other_keys = c(\"state\", \"pol\"))  attr(ex3, \"metadata\") #> $geo_type #> [1] \"county\" #>  #> $time_type #> [1] \"day\" #>  #> $as_of #> [1] \"2024-12-09 23:50:59 UTC\" #>  #> $other_keys #> [1] \"state\" \"pol\"   #>   # Decays to a tibble covid_incidence_county_subset %>%   dplyr::select(-geo_value) #> # A tibble: 16,212 √ó 4 #>    time_value cases county_name       state_name    #>  * <date>     <dbl> <chr>             <chr>         #>  1 2020-06-01     4 Barnstable County Massachusetts #>  2 2020-06-01     0 Berkshire County  Massachusetts #>  3 2020-06-01    78 Bristol County    Massachusetts #>  4 2020-06-01     0 Dukes County      Massachusetts #>  5 2020-06-01    92 Essex County      Massachusetts #>  6 2020-06-01     0 Franklin County   Massachusetts #>  7 2020-06-01    35 Hampden County    Massachusetts #>  8 2020-06-01     4 Hampshire County  Massachusetts #>  9 2020-06-01    98 Middlesex County  Massachusetts #> 10 2020-06-01     0 Nantucket County  Massachusetts #> # ‚Ñπ 16,202 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Slide a function over variables in an epi_df object ‚Äî epi_slide","title":"Slide a function over variables in an epi_df object ‚Äî epi_slide","text":"Slides given function variables epi_df object. useful computations like rolling averages. function supports many ways specify computation, far common use case follows:   two common use cases, provide optimized functions much faster epi_slide: epi_slide_mean() epi_slide_sum(). recommend using functions possible. See vignette(\"epi_df\") examples.","code":"# Create new column `cases_7dmed` that contains a 7-day trailing median of cases epi_slide(edf, cases_7dmed = median(cases), .window_size = 7)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slide a function over variables in an epi_df object ‚Äî epi_slide","text":"","code":"epi_slide(   .x,   .f,   ...,   .window_size = NULL,   .align = c(\"right\", \"center\", \"left\"),   .ref_time_values = NULL,   .new_col_name = NULL,   .all_rows = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slide a function over variables in an epi_df object ‚Äî epi_slide","text":".x epi_df object. ungrouped, temporarily group geo_value columns other_keys. grouped, make sure grouping geo_value other_keys. .f Function, formula, missing; together ... specifies computation slide. return computation either scalar 1-row data frame. Data frame returns tidyr::unpack()-ed, named, tidyr::pack-ed columns, named. See examples. .f missing, ... specify computation via tidy-evaluation. usually convenient way use epi_slide. See examples. .f formula, formula use .x (input epi_df) operate columns input epi_df, e.g. ~mean(.x$var) compute mean var. function, .f must form function(x, g, t, ...), : x data frame column names original object, minus grouping variables, windowed data one group-.ref_time_value combination g one-row tibble containing values grouping variables associated group t .ref_time_value current window ... additional arguments ... Additional arguments pass function formula specified via .f. Alternatively, .f missing, ... interpreted \"data-masking\" expression expressions tidy evaluation. .window_size size sliding window. accepted values depend type time_value column .x: time type Date cadence daily, .window_size can integer (interpreted units days) difftime units \"days\" time type Date cadence weekly, .window_size must difftime units \"weeks\" time type yearmonth integer, .window_size must integer .align alignment sliding window. \"right\" (default), window end reference time. likely common use case, e.g. .window_size=7 .align=\"right\" slides past week data. \"left\", window start reference time. \"center\", window centered reference time. window size odd, window floor(window_size/2) points reference time; window size even, window asymmetric one value reference time . .ref_time_values time values compute slides values. default, unique time values .x. .new_col_name Name new column contain computed values. default \"slide_value\" unless slide computations output data frames, case unpacked (tidyr::unpack()) constituent columns names used. New columns given names clash existing columns .x. .all_rows .all_rows = FALSE, default, output epi_df rows time_value .ref_time_values. Otherwise, rows .x included missing value marker (typically NA, technically result vctrs::vec_cast-ing NA type slide computation output).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Slide a function over variables in an epi_df object ‚Äî epi_slide","text":"epi_df object one new slide computation columns added. ungrouped .x ungrouped, groups .x .x grouped.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide.html","id":"advanced-uses-of-f-via-tidy-evaluation","dir":"Reference","previous_headings":"","what":"Advanced uses of .f via tidy evaluation","title":"Slide a function over variables in an epi_df object ‚Äî epi_slide","text":"specifying .f via tidy evaluation, addition standard .data .env, make additional \"pronoun\"-like bindings available: .x, like .x dplyr::group_modify; ordinary object like epi_df rather rlang pronoun like .data; allows use additional dplyr, tidyr, epiprocess operations. multiple expressions ..., let refer output earlier expressions, .data . .group_key, like .y dplyr::group_modify. .ref_time_value, element .ref_time_values determined time window current computation.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slide a function over variables in an epi_df object ‚Äî epi_slide","text":"","code":"library(dplyr) #>  #> Attaching package: ‚Äòdplyr‚Äô #> The following objects are masked from ‚Äòpackage:stats‚Äô: #>  #>     filter, lag #> The following objects are masked from ‚Äòpackage:base‚Äô: #>  #>     intersect, setdiff, setequal, union  # Get the 7-day trailing standard deviation of cases and the 7-day trailing mean of cases cases_deaths_subset %>%   epi_slide(     cases_7sd = sd(cases, na.rm = TRUE),     cases_7dav = mean(cases, na.rm = TRUE),     .window_size = 7   ) %>%   select(geo_value, time_value, cases, cases_7sd, cases_7dav) #> An `epi_df` object, 4,026 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 5 #>    geo_value time_value cases cases_7sd cases_7dav #>  * <chr>     <date>     <dbl>     <dbl>      <dbl> #>  1 ca        2020-03-01     6     NA          6    #>  2 ca        2020-03-02     4      1.41       5    #>  3 ca        2020-03-03     6      1.15       5.33 #>  4 ca        2020-03-04    11      2.99       6.75 #>  5 ca        2020-03-05    10      2.97       7.4  #>  6 ca        2020-03-06    18      5.08       9.17 #>  7 ca        2020-03-07    26      7.87      11.6  #>  8 ca        2020-03-08    19      7.87      13.4  #>  9 ca        2020-03-09    23      7.34      16.1  #> 10 ca        2020-03-10    22      6.02      18.4  #> # ‚Ñπ 4,016 more rows # Note that epi_slide_mean could be used to more quickly calculate cases_7dav.  # In addition to the [`dplyr::mutate`]-like syntax, you can feed in a function or # formula in a way similar to [`dplyr::group_modify`]: my_summarizer <- function(window_data) {   window_data %>%     summarize(       cases_7sd = sd(cases, na.rm = TRUE),       cases_7dav = mean(cases, na.rm = TRUE)     ) } cases_deaths_subset %>%   epi_slide(     ~ my_summarizer(.x),     .window_size = 7   ) %>%   select(geo_value, time_value, cases, cases_7sd, cases_7dav) #> An `epi_df` object, 4,026 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 5 #>    geo_value time_value cases cases_7sd cases_7dav #>  * <chr>     <date>     <dbl>     <dbl>      <dbl> #>  1 ca        2020-03-01     6     NA          6    #>  2 ca        2020-03-02     4      1.41       5    #>  3 ca        2020-03-03     6      1.15       5.33 #>  4 ca        2020-03-04    11      2.99       6.75 #>  5 ca        2020-03-05    10      2.97       7.4  #>  6 ca        2020-03-06    18      5.08       9.17 #>  7 ca        2020-03-07    26      7.87      11.6  #>  8 ca        2020-03-08    19      7.87      13.4  #>  9 ca        2020-03-09    23      7.34      16.1  #> 10 ca        2020-03-10    22      6.02      18.4  #> # ‚Ñπ 4,016 more rows      #### Advanced: ####  # The tidyverse supports [\"packing\"][tidyr::pack] multiple columns into a # single tibble-type column contained within some larger tibble. Like dplyr, # we normally don't pack output columns together. However, packing behavior can be turned on # by providing a name for a tibble-type output: cases_deaths_subset %>%   epi_slide(     slide_packed = tibble(       cases_7sd = sd(.x$cases, na.rm = TRUE),       cases_7dav = mean(.x$cases, na.rm = TRUE)     ),     .window_size = 7   ) %>%   select(geo_value, time_value, cases, slide_packed) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>    geo_value time_value cases slide_packed$cases_7sd $cases_7dav #>  * <chr>     <date>     <dbl>                  <dbl>       <dbl> #>  1 ca        2020-03-01     6                  NA           6    #>  2 ca        2020-03-02     4                   1.41        5    #>  3 ca        2020-03-03     6                   1.15        5.33 #>  4 ca        2020-03-04    11                   2.99        6.75 #>  5 ca        2020-03-05    10                   2.97        7.4  #>  6 ca        2020-03-06    18                   5.08        9.17 #>  7 ca        2020-03-07    26                   7.87       11.6  #>  8 ca        2020-03-08    19                   7.87       13.4  #>  9 ca        2020-03-09    23                   7.34       16.1  #> 10 ca        2020-03-10    22                   6.02       18.4  #> # ‚Ñπ 4,016 more rows cases_deaths_subset %>%   epi_slide(     ~ tibble(       cases_7sd = sd(.x$cases, na.rm = TRUE),       cases_7dav = mean(.x$cases, na.rm = TRUE)     ),     .new_col_name = \"slide_packed\",     .window_size = 7   ) %>%   select(geo_value, time_value, cases, slide_packed) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>    geo_value time_value cases slide_packed$cases_7sd $cases_7dav #>  * <chr>     <date>     <dbl>                  <dbl>       <dbl> #>  1 ca        2020-03-01     6                  NA           6    #>  2 ca        2020-03-02     4                   1.41        5    #>  3 ca        2020-03-03     6                   1.15        5.33 #>  4 ca        2020-03-04    11                   2.99        6.75 #>  5 ca        2020-03-05    10                   2.97        7.4  #>  6 ca        2020-03-06    18                   5.08        9.17 #>  7 ca        2020-03-07    26                   7.87       11.6  #>  8 ca        2020-03-08    19                   7.87       13.4  #>  9 ca        2020-03-09    23                   7.34       16.1  #> 10 ca        2020-03-10    22                   6.02       18.4  #> # ‚Ñπ 4,016 more rows  # You can also get [\"nested\"][tidyr::nest] format by wrapping your results in # a list: cases_deaths_subset %>%   group_by(geo_value) %>%   epi_slide(     function(x, g, t) {       list(tibble(         cases_7sd = sd(x$cases, na.rm = TRUE),         cases_7dav = mean(x$cases, na.rm = TRUE)       ))     },     .window_size = 7   ) %>%   ungroup() %>%   select(geo_value, time_value, slide_value) #> An `epi_df` object, 4,026 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 3 #>    geo_value time_value slide_value      #>  * <chr>     <date>     <list>           #>  1 ca        2020-03-01 <tibble [1 √ó 2]> #>  2 ca        2020-03-02 <tibble [1 √ó 2]> #>  3 ca        2020-03-03 <tibble [1 √ó 2]> #>  4 ca        2020-03-04 <tibble [1 √ó 2]> #>  5 ca        2020-03-05 <tibble [1 √ó 2]> #>  6 ca        2020-03-06 <tibble [1 √ó 2]> #>  7 ca        2020-03-07 <tibble [1 √ó 2]> #>  8 ca        2020-03-08 <tibble [1 √ó 2]> #>  9 ca        2020-03-09 <tibble [1 √ó 2]> #> 10 ca        2020-03-10 <tibble [1 √ó 2]> #> # ‚Ñπ 4,016 more rows    # Use the geo_value or the ref_time_value in the slide computation cases_deaths_subset %>%   epi_slide(~ .x$geo_value[[1]], .window_size = 7) #> An `epi_df` object, 4,026 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 7 #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # ‚Ñπ 4,016 more rows #> # ‚Ñπ 1 more variable: slide_value <chr>  cases_deaths_subset %>%   epi_slide(~ .x$time_value[[1]], .window_size = 7) #> An `epi_df` object, 4,026 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 7 #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # ‚Ñπ 4,016 more rows #> # ‚Ñπ 1 more variable: slide_value <date>"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide_opt.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized slide functions for common cases ‚Äî epi_slide_opt","title":"Optimized slide functions for common cases ‚Äî epi_slide_opt","text":"epi_slide_opt allows sliding n-timestep data.table::froll slider::summary-slide function variables epi_df object. functions tend much faster epi_slide(). See vignette(\"epi_df\") examples. epi_slide_mean wrapper around epi_slide_opt .f = datatable::frollmean. epi_slide_sum wrapper around epi_slide_opt .f = datatable::frollsum.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide_opt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized slide functions for common cases ‚Äî epi_slide_opt","text":"","code":"epi_slide_opt(   .x,   .col_names,   .f,   ...,   .window_size = NULL,   .align = c(\"right\", \"center\", \"left\"),   .prefix = NULL,   .suffix = NULL,   .new_col_names = NULL,   .ref_time_values = NULL,   .all_rows = FALSE )  epi_slide_mean(   .x,   .col_names,   ...,   .window_size = NULL,   .align = c(\"right\", \"center\", \"left\"),   .prefix = NULL,   .suffix = NULL,   .new_col_names = NULL,   .ref_time_values = NULL,   .all_rows = FALSE )  epi_slide_sum(   .x,   .col_names,   ...,   .window_size = NULL,   .align = c(\"right\", \"center\", \"left\"),   .prefix = NULL,   .suffix = NULL,   .new_col_names = NULL,   .ref_time_values = NULL,   .all_rows = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide_opt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized slide functions for common cases ‚Äî epi_slide_opt","text":".x epi_df object. ungrouped, temporarily group geo_value columns other_keys. grouped, make sure grouping geo_value other_keys. .col_names <tidy-select> unquoted column name (e.g., cases), multiple column names (e.g., c(cases, deaths)), tidy-select expression, vector characters (e.g. c(\"cases\", \"deaths\")). Variable names can used positions data frame, expressions like x:y can used select range variables. tidy-selection renaming interface supported, used provide output column names; want customize output column names, use dplyr::rename slide. .f Function; together ... specifies computation slide. .f must one data.table's rolling functions (frollmean, frollsum, frollapply. See data.table::roll) one slider's specialized sliding functions (slide_mean, slide_sum, etc. See slider::summary-slide). optimized data.table slider functions directly passed computation function epi_slide without careful handling make sure computation group made .window_size dates rather .window_size points. epi_slide_opt (wrapper functions epi_slide_mean epi_slide_sum) take care window completion automatically prevent associated errors. ... Additional arguments pass slide computation .f, example, algo na.rm data.table functions. need specify .x, .window_size, .align (/slider functions). .window_size size sliding window. accepted values depend type time_value column .x: time type Date cadence daily, .window_size can integer (interpreted units days) difftime units \"days\" time type Date cadence weekly, .window_size must difftime units \"weeks\" time type yearmonth integer, .window_size must integer .align alignment sliding window. \"right\" (default), window end reference time. likely common use case, e.g. .window_size=7 .align=\"right\" slides past week data. \"left\", window start reference time. \"center\", window centered reference time. window size odd, window floor(window_size/2) points reference time; window size even, window asymmetric one value reference time . .prefix Optional glue::glue format string; name slide result column(s) attaching prefix corresponding input column(s). shorthand supported basing output names .window_size arguments; see \"Prefix suffix shorthand\" . .suffix Optional glue::glue format string; like .prefix. default naming behavior equivalent .suffix = \"_{.n}{.time_unit_abbr}{.align_abbr}{.f_abbr}\". Can used combination .prefix. .new_col_names Optional character vector length matching number input columns .col_names; name slide result column(s) names. used combination .prefix /.suffix. .ref_time_values time values compute slides values. default, unique time values .x. .all_rows .all_rows = FALSE, default, output epi_df rows time_value .ref_time_values. Otherwise, rows .x included missing value marker (typically NA, technically result vctrs::vec_cast-ing NA type slide computation output).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide_opt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized slide functions for common cases ‚Äî epi_slide_opt","text":"epi_df object one new slide computation columns added. ungrouped .x ungrouped, groups .x .x grouped.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide_opt.html","id":"prefix-and-suffix-shorthand","dir":"Reference","previous_headings":"","what":"Prefix and suffix shorthand","title":"Optimized slide functions for common cases ‚Äî epi_slide_opt","text":"glue::glue format strings specially interpret content within curly braces. E.g., glue::glue(\"ABC{2 + 2}\") evaluates \"ABC4\". .prefix .suffix, provide glue additional variable bindings: {.n} number time steps computation corresponding .window_size. {.time_unit_abbr} lower-case letter corresponding time_type .x {.align_abbr} \"\" .align default \"right\"; otherwise, first letter .align {.f_abbr} character vector containing short abbreviation .f factoring input column type(s) .col_names","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epi_slide_opt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimized slide functions for common cases ‚Äî epi_slide_opt","text":"","code":"library(dplyr)  # Add a column (`cases_7dsum`) containing a 7-day trailing sum on `cases`: cases_deaths_subset %>%   select(geo_value, time_value, cases) %>%   epi_slide_sum(cases, .window_size = 7) #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>    geo_value time_value cases cases_7dsum #>  * <chr>     <date>     <dbl>       <dbl> #>  1 ca        2020-03-01     6          NA #>  2 ca        2020-03-02     4          NA #>  3 ca        2020-03-03     6          NA #>  4 ca        2020-03-04    11          NA #>  5 ca        2020-03-05    10          NA #>  6 ca        2020-03-06    18          NA #>  7 ca        2020-03-07    26          81 #>  8 ca        2020-03-08    19          94 #>  9 ca        2020-03-09    23         113 #> 10 ca        2020-03-10    22         129 #> # ‚Ñπ 4,016 more rows  # Add a column (`cases_rate_7dav`) containing a 7-day trailing average on `case_rate`: covid_case_death_rates_extended %>%   epi_slide_mean(case_rate, .window_size = 7) #> An `epi_df` object, 37,576 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 #>  #> # A tibble: 37,576 √ó 5 #>    geo_value time_value case_rate death_rate case_rate_7dav #>  * <chr>     <date>         <dbl>      <dbl>          <dbl> #>  1 ak        2020-03-01         0          0             NA #>  2 ak        2020-03-02         0          0             NA #>  3 ak        2020-03-03         0          0             NA #>  4 ak        2020-03-04         0          0             NA #>  5 ak        2020-03-05         0          0             NA #>  6 ak        2020-03-06         0          0             NA #>  7 ak        2020-03-07         0          0              0 #>  8 ak        2020-03-08         0          0              0 #>  9 ak        2020-03-09         0          0              0 #> 10 ak        2020-03-10         0          0              0 #> # ‚Ñπ 37,566 more rows  # Use a less common specialized slide function: cases_deaths_subset %>%   epi_slide_opt(cases, slider::slide_min, .window_size = 7) #> An `epi_df` object, 4,026 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 7 #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # ‚Ñπ 4,016 more rows #> # ‚Ñπ 1 more variable: cases_7dmin <dbl>  # Specify output column names and/or a naming scheme: cases_deaths_subset %>%   select(geo_value, time_value, cases) %>%   group_by(geo_value) %>%   epi_slide_sum(cases, .window_size = 7, .new_col_names = \"case_sum\") %>%   ungroup() #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>    geo_value time_value cases case_sum #>  * <chr>     <date>     <dbl>    <dbl> #>  1 ca        2020-03-01     6       NA #>  2 ca        2020-03-02     4       NA #>  3 ca        2020-03-03     6       NA #>  4 ca        2020-03-04    11       NA #>  5 ca        2020-03-05    10       NA #>  6 ca        2020-03-06    18       NA #>  7 ca        2020-03-07    26       81 #>  8 ca        2020-03-08    19       94 #>  9 ca        2020-03-09    23      113 #> 10 ca        2020-03-10    22      129 #> # ‚Ñπ 4,016 more rows cases_deaths_subset %>%   select(geo_value, time_value, cases) %>%   group_by(geo_value) %>%   epi_slide_sum(cases, .window_size = 7, .prefix = \"sum_\") %>%   ungroup() #> An `epi_df` object, 4,026 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 4 #>    geo_value time_value cases sum_cases #>  * <chr>     <date>     <dbl>     <dbl> #>  1 ca        2020-03-01     6        NA #>  2 ca        2020-03-02     4        NA #>  3 ca        2020-03-03     6        NA #>  4 ca        2020-03-04    11        NA #>  5 ca        2020-03-05    10        NA #>  6 ca        2020-03-06    18        NA #>  7 ca        2020-03-07    26        81 #>  8 ca        2020-03-08    19        94 #>  9 ca        2020-03-09    23       113 #> 10 ca        2020-03-10    22       129 #> # ‚Ñπ 4,016 more rows  # Additional settings can be sent to the {data.table} and {slider} functions # via `...`. This example passes some arguments to `frollmean` settings for # speed, accuracy, and to allow partially-missing windows: covid_case_death_rates_extended %>%   epi_slide_mean(     case_rate,     .window_size = 7,     na.rm = TRUE, algo = \"exact\", hasNA = TRUE   ) #> An `epi_df` object, 37,576 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 #>  #> # A tibble: 37,576 √ó 5 #>    geo_value time_value case_rate death_rate case_rate_7dav #>  * <chr>     <date>         <dbl>      <dbl>          <dbl> #>  1 ak        2020-03-01         0          0              0 #>  2 ak        2020-03-02         0          0              0 #>  3 ak        2020-03-03         0          0              0 #>  4 ak        2020-03-04         0          0              0 #>  5 ak        2020-03-05         0          0              0 #>  6 ak        2020-03-06         0          0              0 #>  7 ak        2020-03-07         0          0              0 #>  8 ak        2020-03-08         0          0              0 #>  9 ak        2020-03-09         0          0              0 #> 10 ak        2020-03-10         0          0              0 #> # ‚Ñπ 37,566 more rows  # If the more specialized possibilities for `.f` don't cover your needs, you # can use `epi_slide_opt` with `.f = data.table::frollapply` to apply a # custom function at the cost of more computation time. See also `epi_slide` # if you need something even more general. cases_deaths_subset %>%   select(geo_value, time_value, case_rate_7d_av, death_rate_7d_av) %>%   epi_slide_opt(c(case_rate_7d_av, death_rate_7d_av),     data.table::frollapply,     FUN = median, .window_size = 28,     .suffix = \"_{.n}{.time_unit_abbr}_median\"   ) %>%   print(n = 40) #> An `epi_df` object, 4,026 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 6 #>    geo_value time_value case_rate_7d_av death_rate_7d_av case_rate_7d_av_28d_m‚Ä¶¬π #>  * <chr>     <date>               <dbl>            <dbl>                   <dbl> #>  1 ca        2020-03-01         0.00327         0                        NA      #>  2 ca        2020-03-02         0.00435         0                        NA      #>  3 ca        2020-03-03         0.00617         0                        NA      #>  4 ca        2020-03-04         0.00980         0.000363                 NA      #>  5 ca        2020-03-05         0.0134          0.000363                 NA      #>  6 ca        2020-03-06         0.0200          0.000363                 NA      #>  7 ca        2020-03-07         0.0294          0.000363                 NA      #>  8 ca        2020-03-08         0.0341          0.000363                 NA      #>  9 ca        2020-03-09         0.0410          0.000726                 NA      #> 10 ca        2020-03-10         0.0468          0.000726                 NA      #> 11 ca        2020-03-11         0.0519          0.00109                  NA      #> 12 ca        2020-03-12         0.0639          0.00145                  NA      #> 13 ca        2020-03-13         0.0766          0.00109                  NA      #> 14 ca        2020-03-14         0.0875          0.00145                  NA      #> 15 ca        2020-03-15         0.0947          0.00181                  NA      #> 16 ca        2020-03-16         0.144           0.00145                  NA      #> 17 ca        2020-03-17         0.167           0.00218                  NA      #> 18 ca        2020-03-18         0.221           0.00435                  NA      #> 19 ca        2020-03-19         0.275           0.00544                  NA      #> 20 ca        2020-03-20         0.350           0.00689                  NA      #> 21 ca        2020-03-21         0.385           0.00762                  NA      #> 22 ca        2020-03-22         0.480           0.0109                   NA      #> 23 ca        2020-03-23         0.559           0.0123                   NA      #> 24 ca        2020-03-24         0.684           0.0156                   NA      #> 25 ca        2020-03-25         0.806           0.0181                   NA      #> 26 ca        2020-03-26         1.05            0.0218                   NA      #> 27 ca        2020-03-27         1.20            0.0279                   NA      #> 28 ca        2020-03-28         2.22            0.0588                    0.0911 #> 29 ca        2020-03-29         1.38            0.0352                    0.119  #> 30 ca        2020-03-30         1.74            0.0396                    0.155  #> 31 ca        2020-03-31         2.00            0.0432                    0.194  #> 32 ca        2020-04-01         2.27            0.0483                    0.248  #> 33 ca        2020-04-02         2.50            0.0566                    0.312  #> 34 ca        2020-04-03         2.74            0.0639                    0.368  #> 35 ca        2020-04-04         1.93            0.0381                    0.433  #> 36 ca        2020-04-05         3.26            0.0762                    0.519  #> 37 ca        2020-04-06         3.31            0.0806                    0.621  #> 38 ca        2020-04-07         3.30            0.0922                    0.745  #> 39 ca        2020-04-08         3.38            0.105                     0.928  #> 40 ca        2020-04-09         3.18            0.110                     1.13   #> # ‚Ñπ 3,986 more rows #> # ‚Ñπ abbreviated name: ¬π‚Äãcase_rate_7d_av_28d_median #> # ‚Ñπ 1 more variable: death_rate_7d_av_28d_median <dbl>"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epidatasets_reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Selected example data sets from epidatasets ‚Äî cases_deaths_subset","title":"Selected example data sets from epidatasets ‚Äî cases_deaths_subset","text":"Data sets re-exported epidatasets; please see documentation objects epidatasets. brief description format objects described matching order .","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epidatasets_reexports.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selected example data sets from epidatasets ‚Äî cases_deaths_subset","text":"","code":"cases_deaths_subset  covid_incidence_county_subset  covid_incidence_outliers  archive_cases_dv_subset  covid_case_death_rates_extended"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epidatasets_reexports.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Selected example data sets from epidatasets ‚Äî cases_deaths_subset","text":"object class epi_df (inherits tbl_df, tbl, data.frame) 4026 rows 6 columns. object class epi_df (inherits tbl_df, tbl, data.frame) 16212 rows 5 columns. object class epi_df (inherits tbl_df, tbl, data.frame) 730 rows 3 columns. object class epi_archive length 6. object class epi_df (inherits tbl_df, tbl, data.frame) 37576 rows 4 columns.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epiprocess-package.html","id":null,"dir":"Reference","previous_headings":"","what":"epiprocess: Tools for basic signal processing in epidemiology ‚Äî epiprocess-package","title":"epiprocess: Tools for basic signal processing in epidemiology ‚Äî epiprocess-package","text":"package introduces common data structures working epidemiological data reported location time offers associated utilities perform basic signal processing tasks. package designed used conjunction `epipredict` building evaluating epidemiological models.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epiprocess-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"epiprocess: Tools for basic signal processing in epidemiology ‚Äî epiprocess-package","text":"Maintainer: Logan Brooks lcbrooks@andrew.cmu.edu Authors: Daniel McDonald Evan Ray Ryan Tibshirani contributors: Jacob Bien [contributor] Rafael Catoia [contributor] Nat DeFries [contributor] Rachel Lobay [contributor] Ken Mawer [contributor] Chloe [contributor] Quang Nguyen [contributor] Dmitry Shemetov [contributor] Lionel Henry (Author included rlang fragments) [contributor] Hadley Wickham (Author included rlang fragments) [contributor] Posit (Copyright holder included rlang fragments) [copyright holder] Johns Hopkins University Center Systems Science Engineering (Owner COVID-19 cases deaths data COVID-19 Data Repository) [data contributor] Johns Hopkins University (Copyright holder COVID-19 cases deaths data COVID-19 Data Repository) [copyright holder] Carnegie Mellon University Delphi Group (Owner claims-based CLI data Delphi Epidata API) [data contributor]","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_as_of.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a snapshot from an epi_archive object ‚Äî epix_as_of","title":"Generate a snapshot from an epi_archive object ‚Äî epix_as_of","text":"Generates snapshot epi_df format epi_archive object, given version. See archive vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_as_of.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a snapshot from an epi_archive object ‚Äî epix_as_of","text":"","code":"epix_as_of(   x,   version,   min_time_value = -Inf,   all_versions = FALSE,   max_version = deprecated() )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_as_of.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a snapshot from an epi_archive object ‚Äî epix_as_of","text":"x epi_archive object version Time value specifying max version permit snapshot. , snapshot comprise unique rows current archive data represent --date signal values, specified version (whose time values least min_time_value.) min_time_value Time value specifying min time value permit snapshot. Default -Inf, effectively means minimum considered. all_versions all_versions = TRUE, output epi_archive format, contain rows specified time_value range version <= version. resulting object cover potentially narrower version time_value range x, depending user-provided arguments. Otherwise, one row output version time_value. Default FALSE. max_version please use version argument instead.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_as_of.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a snapshot from an epi_archive object ‚Äî epix_as_of","text":"epi_df object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_as_of.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a snapshot from an epi_archive object ‚Äî epix_as_of","text":"","code":"epix_as_of(   archive_cases_dv_subset,   version = max(archive_cases_dv_subset$DT$version) ) #> An `epi_df` object, 2,192 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-12-01 #>  #> # A tibble: 2,192 √ó 4 #>    geo_value time_value percent_cli case_rate_7d_av #>  * <chr>     <date>           <dbl>           <dbl> #>  1 ca        2020-06-01        2.75            6.84 #>  2 ca        2020-06-02        2.57            6.82 #>  3 ca        2020-06-03        2.48            6.66 #>  4 ca        2020-06-04        2.41            6.98 #>  5 ca        2020-06-05        2.57            6.97 #>  6 ca        2020-06-06        2.63            6.66 #>  7 ca        2020-06-07        2.73            6.74 #>  8 ca        2020-06-08        3.04            6.67 #>  9 ca        2020-06-09        2.97            6.81 #> 10 ca        2020-06-10        2.99            7.13 #> # ‚Ñπ 2,182 more rows  range(archive_cases_dv_subset$DT$version) # 2020-06-02 -- 2021-12-01 #> [1] \"2020-06-02\" \"2021-12-01\"  epix_as_of(archive_cases_dv_subset, as.Date(\"2020-06-12\")) #> An `epi_df` object, 44 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2020-06-12 #>  #> # A tibble: 44 √ó 4 #>    geo_value time_value percent_cli case_rate_7d_av #>  * <chr>     <date>           <dbl>           <dbl> #>  1 ca        2020-06-01        2.23            6.63 #>  2 ca        2020-06-02        2.06            6.45 #>  3 ca        2020-06-03        1.90            6.62 #>  4 ca        2020-06-04        1.79            6.64 #>  5 ca        2020-06-05        1.83            6.91 #>  6 ca        2020-06-06        1.86            6.76 #>  7 ca        2020-06-07        1.78            6.75 #>  8 ca        2020-06-08        1.90            6.90 #>  9 ca        2020-06-09       NA               7.02 #> 10 ca        2020-06-10       NA               7.36 #> # ‚Ñπ 34 more rows  # --- Advanced: ---  # When requesting recent versions of a data set, there can be some # reproducibility issues. For example, requesting data as of the current date # may return different values based on whether today's data is available yet # or not. Other factors include the time it takes between data becoming # available and when you download the data, and whether the data provider # will overwrite (\"clobber\") version data rather than just publishing new # versions. You can include information about these factors by setting the # `clobberable_versions_start` and `versions_end` of an `epi_archive`, in # which case you will get warnings about potential reproducibility issues:  archive_cases_dv_subset2 <- as_epi_archive(   archive_cases_dv_subset$DT,   # Suppose last version with an update could potentially be rewritten   # (a.k.a. \"hotfixed\", \"clobbered\", etc.):   clobberable_versions_start = max(archive_cases_dv_subset$DT$version),   # Suppose today is the following day, and there are no updates out yet:   versions_end = max(archive_cases_dv_subset$DT$version) + 1L,   compactify = TRUE )  epix_as_of(archive_cases_dv_subset2, max(archive_cases_dv_subset$DT$version)) #> Warning: Getting data as of some recent version which could still be overwritten (under #> routine circumstances) without assigning a new version number (a.k.a. #> \"clobbered\").  Thus, the snapshot that we produce here should not be expected #> to be reproducible later. See `?epi_archive` for more info and `?epix_as_of` on #> how to muffle. #> An `epi_df` object, 2,192 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-12-01 #>  #> # A tibble: 2,192 √ó 4 #>    geo_value time_value percent_cli case_rate_7d_av #>  * <chr>     <date>           <dbl>           <dbl> #>  1 ca        2020-06-01        2.75            6.84 #>  2 ca        2020-06-02        2.57            6.82 #>  3 ca        2020-06-03        2.48            6.66 #>  4 ca        2020-06-04        2.41            6.98 #>  5 ca        2020-06-05        2.57            6.97 #>  6 ca        2020-06-06        2.63            6.66 #>  7 ca        2020-06-07        2.73            6.74 #>  8 ca        2020-06-08        3.04            6.67 #>  9 ca        2020-06-09        2.97            6.81 #> 10 ca        2020-06-10        2.99            7.13 #> # ‚Ñπ 2,182 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_fill_through_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","title":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","text":"function fills missing version history epi_archive object specified version, updating versions_end field necessary. Note filling done compactified way, see details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_fill_through_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","text":"","code":"epix_fill_through_version(x, fill_versions_end, how = c(\"na\", \"locf\"))"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_fill_through_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","text":"x epi_archive fill_versions_end scalar class&type x$version: version fill missing version history; epi_archive's versions_end attribute set , unless already later $versions_end. Optional; \"na\" \"locf\": \"na\" fills missing version history NAs, \"locf\" fills missing version history last version observation carried forward (LOCF). Default \"na\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_fill_through_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","text":"epi_archive epi_archive","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_fill_through_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","text":"Note generally store epi_archive's compacted form, meaning , implciitly, version exist, version_end attribute greater, understood versions value last observed version. affects behavior function following ways: = \"na\", function fill one missing version NA rest implicit. = \"locf\", function fill values.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_fill_through_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill epi_archive unobserved history ‚Äî epix_fill_through_version","text":"","code":"test_date <- as.Date(\"2020-01-01\") ea_orig <- as_epi_archive(data.table::data.table(   geo_value = \"ak\",   time_value = test_date + c(rep(0L, 5L), 1L),   version = test_date + c(1:5, 2L),   value = 1:6 )) epix_fill_through_version(ea_orig, test_date + 8, \"na\") #> ‚Üí An `epi_archive` object, with metadata: #> ‚Ñπ Min/max time values: 2020-01-01 / 2020-01-02 #> ‚Ñπ First/last version with update: 2020-01-02 / 2020-01-07 #> ‚Ñπ Versions end: 2020-01-09 #> ‚Ñπ A preview of the table (8 rows x 4 columns): #> Key: <geo_value, time_value, version> #>    geo_value time_value    version value #>       <char>     <Date>     <Date> <int> #> 1:        ak 2020-01-01 2020-01-02     1 #> 2:        ak 2020-01-01 2020-01-03     2 #> 3:        ak 2020-01-01 2020-01-04     3 #> 4:        ak 2020-01-01 2020-01-05     4 #> 5:        ak 2020-01-01 2020-01-06     5 #> 6:        ak 2020-01-01 2020-01-07    NA #> 7:        ak 2020-01-02 2020-01-03     6 #> 8:        ak 2020-01-02 2020-01-07    NA epix_fill_through_version(ea_orig, test_date + 8, \"locf\") #> ‚Üí An `epi_archive` object, with metadata: #> ‚Ñπ Min/max time values: 2020-01-01 / 2020-01-02 #> ‚Ñπ First/last version with update: 2020-01-02 / 2020-01-06 #> ‚Ñπ Versions end: 2020-01-09 #> ‚Ñπ A preview of the table (6 rows x 4 columns): #> Key: <geo_value, time_value, version> #>    geo_value time_value    version value #>       <char>     <Date>     <Date> <int> #> 1:        ak 2020-01-01 2020-01-02     1 #> 2:        ak 2020-01-01 2020-01-03     2 #> 3:        ak 2020-01-01 2020-01-04     3 #> 4:        ak 2020-01-01 2020-01-05     4 #> 5:        ak 2020-01-01 2020-01-06     5 #> 6:        ak 2020-01-02 2020-01-03     6"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge two epi_archive objects ‚Äî epix_merge","title":"Merge two epi_archive objects ‚Äî epix_merge","text":"Merges two epi_archives share common geo_value, time_value, set key columns. also share common versions_end, using epix_as_of result using epix_as_of x y individually, performing full join DTs non-version key columns (potentially consolidating multiple warnings clobberable versions). versions_end values differ, sync parameter controls done.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge two epi_archive objects ‚Äî epix_merge","text":"","code":"epix_merge(   x,   y,   sync = c(\"forbid\", \"na\", \"locf\", \"truncate\"),   compactify = TRUE )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge two epi_archive objects ‚Äî epix_merge","text":"x, y Two epi_archive objects join together. sync Optional; character. argument decides handle situation one signal recent revision another signal key already observed. options : \"forbid\": default strictest option, throws error; likely want, strict make user aware issues, \"locf\": carry forward last observed version missing signal new version use max(x$versions_end, y$versions_end) result's versions_end, \"na\": fill unobserved values NA's (can handy know source data truly missing upstream want represent lack information accurately, instance) use max(x$versions_end, y$versions_end) result's versions_end, \"truncate\": discard rows containing update rows later versions use min(x$versions_end, y$versions_end) result's versions_end. compactify Optional; TRUE (default), FALSE, NULL; result compactified? See as_epi_archive() details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge two epi_archive objects ‚Äî epix_merge","text":"resulting epi_archive","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_merge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge two epi_archive objects ‚Äî epix_merge","text":"merging archives, unless archives identical data release patterns, often handle situation one signal recent observation key another signal. case, two options: signal never observed key, need introduce NAs non-key variables missing signal, signal observed key previously, ealier revision date, need decide handle missing value recent signal; sync argument controls behavior. cases, clobberable_versions_start set earliest version clobbered either input archive.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_merge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge two epi_archive objects ‚Äî epix_merge","text":"","code":"# Example 1 # The s1 signal at August 1st gets revised from 10 to 11 on August 2nd s1 <- tibble::tibble(   geo_value = c(\"ca\", \"ca\", \"ca\"),   time_value = as.Date(c(\"2024-08-01\", \"2024-08-01\", \"2024-08-02\")),   version = as.Date(c(\"2024-08-01\", \"2024-08-02\", \"2024-08-02\")),   signal1 = c(10, 11, 7) ) s2 <- tibble::tibble(   geo_value = c(\"ca\", \"ca\"),   time_value = as.Date(c(\"2024-08-01\", \"2024-08-02\")),   version = as.Date(c(\"2024-08-03\", \"2024-08-03\")),   signal2 = c(2, 3) ) s1 <- s1 %>% as_epi_archive() s2 <- s2 %>% as_epi_archive() merged <- epix_merge(s1, s2, sync = \"locf\") merged[[\"DT\"]] #> Key: <geo_value, time_value, version> #>    geo_value time_value    version signal1 signal2 #>       <char>     <Date>     <Date>   <num>   <num> #> 1:        ca 2024-08-01 2024-08-01      10      NA #> 2:        ca 2024-08-01 2024-08-02      11      NA #> 3:        ca 2024-08-01 2024-08-03      11       2 #> 4:        ca 2024-08-02 2024-08-02       7      NA #> 5:        ca 2024-08-02 2024-08-03       7       3  # Example 2 # The s1 signal at August 1st gets revised from 12 to 13 on August 3rd s1 <- tibble::tibble(   geo_value = c(\"ca\", \"ca\", \"ca\", \"ca\"),   time_value = as.Date(c(\"2024-08-01\", \"2024-08-01\", \"2024-08-02\", \"2024-08-03\")),   version = as.Date(c(\"2024-08-01\", \"2024-08-03\", \"2024-08-03\", \"2024-08-03\")),   signal1 = c(12, 13, 22, 19) ) s2 <- tibble::tibble(   geo_value = c(\"ca\", \"ca\"),   time_value = as.Date(c(\"2024-08-01\", \"2024-08-02\")),   version = as.Date(c(\"2024-08-02\", \"2024-08-02\")),   signal2 = c(4, 5), ) s1 <- s1 %>% as_epi_archive() s2 <- s2 %>% as_epi_archive() merged <- epix_merge(s1, s2, sync = \"locf\") merged[[\"DT\"]] #> Key: <geo_value, time_value, version> #>    geo_value time_value    version signal1 signal2 #>       <char>     <Date>     <Date>   <num>   <num> #> 1:        ca 2024-08-01 2024-08-01      12      NA #> 2:        ca 2024-08-01 2024-08-02      12       4 #> 3:        ca 2024-08-01 2024-08-03      13       4 #> 4:        ca 2024-08-02 2024-08-02      NA       5 #> 5:        ca 2024-08-02 2024-08-03      22       5 #> 6:        ca 2024-08-03 2024-08-03      19      NA   # Example 3: s1 <- tibble::tibble(   geo_value = c(\"ca\", \"ca\", \"ca\"),   time_value = as.Date(c(\"2024-08-01\", \"2024-08-02\", \"2024-08-03\")),   version = as.Date(c(\"2024-08-01\", \"2024-08-02\", \"2024-08-03\")),   signal1 = c(14, 11, 9) ) # The s2 signal at August 1st gets revised from 3 to 5 on August 3rd s2 <- tibble::tibble(   geo_value = c(\"ca\", \"ca\", \"ca\"),   time_value = as.Date(c(\"2024-08-01\", \"2024-08-01\", \"2024-08-02\")),   version = as.Date(c(\"2024-08-02\", \"2024-08-03\", \"2024-08-03\")),   signal2 = c(3, 5, 2), ) s1 <- s1 %>% as_epi_archive() s2 <- s2 %>% as_epi_archive() merged <- epix_merge(s1, s2, sync = \"locf\") merged[[\"DT\"]] #> Key: <geo_value, time_value, version> #>    geo_value time_value    version signal1 signal2 #>       <char>     <Date>     <Date>   <num>   <num> #> 1:        ca 2024-08-01 2024-08-01      14      NA #> 2:        ca 2024-08-01 2024-08-02      14       3 #> 3:        ca 2024-08-01 2024-08-03      14       5 #> 4:        ca 2024-08-02 2024-08-02      11      NA #> 5:        ca 2024-08-02 2024-08-03      11       2 #> 6:        ca 2024-08-03 2024-08-03       9      NA"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","title":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","text":"Slides given function variables epi_archive object. behaves similarly epi_slide(), key exception version-aware: sliding computation given reference time t performed data available t. function intended use accurate backtesting models; see vignette(\"backtesting\", package=\"epipredict\") walkthrough.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","text":"","code":"epix_slide(   .x,   .f,   ...,   .before = Inf,   .versions = NULL,   .new_col_name = NULL,   .all_versions = FALSE )  # S3 method for class 'epi_archive' epix_slide(   .x,   .f,   ...,   .before = Inf,   .versions = NULL,   .new_col_name = NULL,   .all_versions = FALSE )  # S3 method for class 'grouped_epi_archive' epix_slide(   .x,   .f,   ...,   .before = Inf,   .versions = NULL,   .new_col_name = NULL,   .all_versions = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","text":".x epi_archive grouped_epi_archive object. ungrouped, data x treated part single data group. .f Function, formula, missing; together ... specifies computation slide. \"slide\" means apply computation sliding (.k.. \"rolling\") time window data group. window determined .parameter (see details ). function, .f must form function(x, g, t, ...), \"x\" epi_df column names archive's DT, minus version column \"g\" one-row tibble containing values grouping variables associated group \"t\" ref_time_value current window \"...\" additional arguments formula, .f can operate directly columns accessed via .x$var .$var, ~ mean (.x$var) compute mean column var group-ref_time_value combination. group key can accessed via .y .group_key, reference time value can accessed via .z .ref_time_value. .f missing, ... specify computation. ... Additional arguments pass function formula specified via f. Alternatively, .f missing, ... interpreted \"data-masking\" expression expressions tidy evaluation; addition referring columns directly name, expressions access .data .env pronouns dplyr verbs, can also refer .x (input epi_archive), .group_key, .ref_time_value. See details . .many time values .ref_time_value snapshot handed function .f contain? provided, single value compatible time_type time_value column (), commonly integer. window endpoint inclusive. example, .= 7, time_type archive \"day\", .ref_time_value January 8, smallest time_value snapshot January 1. missing, default limit time values, full snapshot given. .versions Reference time values / versions sliding computations; element vector serves anchor point time_value window computation max_version epix_as_of fetch data window. missing, set regularly-spaced sequence values set cover range versions DT plus versions_end; spacing values guessed (using GCD skips values). .new_col_name Either NULL string indicating name new column contain derived values. default, NULL, use name \"slide_value\" unless slide computations output data frames, case unpacked constituent columns names used. resulting column name(s) overlap column names used labeling computations, group_vars(x) \"version\", values columns must identical labels assign. .all_versions (.all_rows parameter epi_slide.) .all_versions = TRUE, slide computation passed version history (version <= .version .version one requested .versions) rows time_value least `.version . Otherwise, slide computation passed   recent versionfor every uniquetime_value. Default FALSE`.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","text":"tibble whose columns : grouping variables (), time_value, containing reference time values slide computation, column named according .new_col_name argument, containing slide values. grouped grouping variables.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_slide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","text":"key distinctions current function epi_slide(): .f functions epix_slide, one assume input data contain rows time_value matching computation's .ref_time_value (accessible via attributes(<data>)$metadata$as_of); typical epidemiological surveillance data, observations pertaining particular time period (time_value) first reported as_of instant time period ended. input class columns similar different: epix_slide (default .all_versions=FALSE) keeps columns epi_df-ness first argument computation; epi_slide provides grouping variables second input, convert first input regular tibble grouping variables include essential geo_value column. (.all_versions=TRUE, epix_slidewill   provide anepi_archiverather anepi-df` computation.) output class columns similar different: epix_slide() returns tibble containing grouping variables, time_value, new column(s) slide computations, whereas epi_slide() returns epi_df original variables plus new columns slide computations. (mirror grouping ungroupedness input, one exception: epi_archives can trivial (zero-variable) groupings, dropped epix_slide results supported tibbles.) size stability checks element/row recycling maintain size stability epix_slide, unlike epi_slide. (epix_slide roughly analogous dplyr::group_modify, epi_slide roughly analogous dplyr::mutate followed dplyr::arrange) detailed \"advanced\" vignette. .all_rows supported epix_slide; since slide computations allowed flexibility outputs epi_slide, guess good representation missing computations excluded group-.ref_time_value pairs. .versions default epix_slide based making evenly-spaced sequence versions DT plus versions_end, rather time_values. Apart distinctions, interfaces epix_slide() epi_slide() . Furthermore, current function can considerably slower epi_slide(), two reasons: (1) must repeatedly fetch properly-versioned snapshots data archive (via epix_as_of()), (2) performs \"manual\" sliding sorts, benefit highly efficient slider package. reason, never used place epi_slide(), used version-aware sliding necessary (purpose).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slide a function over variables in an epi_archive or grouped_epi_archive ‚Äî epix_slide","text":"","code":"library(dplyr)  # Reference time points for which we want to compute slide values: versions <- seq(as.Date(\"2020-06-02\"),   as.Date(\"2020-06-15\"),   by = \"1 day\" )  # A simple (but not very useful) example (see the archive vignette for a more # realistic one): archive_cases_dv_subset %>%   group_by(geo_value) %>%   epix_slide(     .f = ~ mean(.x$case_rate_7d_av),     .before = 2,     .versions = versions,     .new_col_name = \"case_rate_7d_av_recent_av\"   ) %>%   ungroup() #> # A tibble: 56 √ó 3 #>    geo_value version    case_rate_7d_av_recent_av #>    <chr>     <date>                         <dbl> #>  1 ca        2020-06-02                      6.63 #>  2 fl        2020-06-02                      3.38 #>  3 ny        2020-06-02                      6.57 #>  4 tx        2020-06-02                      4.52 #>  5 ca        2020-06-03                      6.54 #>  6 fl        2020-06-03                      3.42 #>  7 ny        2020-06-03                      6.66 #>  8 tx        2020-06-03                      4.75 #>  9 ca        2020-06-04                      6.53 #> 10 fl        2020-06-04                      3.77 #> # ‚Ñπ 46 more rows # We requested time windows that started 2 days before the corresponding time # values. The actual number of `time_value`s in each computation depends on # the reporting latency of the signal and `time_value` range covered by the # archive (2020-06-01 -- 2021-11-30 in this example).  In this case, we have # * 0 `time_value`s, for ref time 2020-06-01 --> the result is automatically #                                                discarded # * 1 `time_value`, for ref time 2020-06-02 # * 2 `time_value`s, for the rest of the results # * never the 3 `time_value`s we would get from `epi_slide`, since, because #   of data latency, we'll never have an observation #   `time_value == .ref_time_value` as of `.ref_time_value`. # The example below shows this type of behavior in more detail.  # Examining characteristics of the data passed to each computation with # `all_versions=FALSE`. archive_cases_dv_subset %>%   group_by(geo_value) %>%   epix_slide(     function(x, gk, rtv) {       tibble(         time_range = if (nrow(x) == 0L) {           \"0 `time_value`s\"         } else {           sprintf(\"%s -- %s\", min(x$time_value), max(x$time_value))         },         n = nrow(x),         class1 = class(x)[[1L]]       )     },     .before = 5, .all_versions = FALSE,     .versions = versions   ) %>%   ungroup() %>%   arrange(geo_value, version) #> # A tibble: 56 √ó 5 #>    geo_value version    time_range                   n class1 #>    <chr>     <date>     <chr>                    <int> <chr>  #>  1 ca        2020-06-02 2020-06-01 -- 2020-06-01     1 epi_df #>  2 ca        2020-06-03 2020-06-01 -- 2020-06-02     2 epi_df #>  3 ca        2020-06-04 2020-06-01 -- 2020-06-03     3 epi_df #>  4 ca        2020-06-05 2020-06-01 -- 2020-06-04     4 epi_df #>  5 ca        2020-06-06 2020-06-01 -- 2020-06-05     5 epi_df #>  6 ca        2020-06-07 2020-06-02 -- 2020-06-06     5 epi_df #>  7 ca        2020-06-08 2020-06-03 -- 2020-06-07     5 epi_df #>  8 ca        2020-06-09 2020-06-04 -- 2020-06-08     5 epi_df #>  9 ca        2020-06-10 2020-06-05 -- 2020-06-09     5 epi_df #> 10 ca        2020-06-11 2020-06-06 -- 2020-06-10     5 epi_df #> # ‚Ñπ 46 more rows  # --- Advanced: ---  # `epix_slide` with `all_versions=FALSE` (the default) applies a # version-unaware computation to several versions of the data. We can also # use `.all_versions=TRUE` to apply a version-*aware* computation to several # versions of the data, again looking at characteristics of the data passed # to each computation. In this case, each computation should expect an # `epi_archive` containing the relevant version data:  archive_cases_dv_subset %>%   group_by(geo_value) %>%   epix_slide(     function(x, gk, rtv) {       tibble(         versions_start = if (nrow(x$DT) == 0L) {           \"NA (0 rows)\"         } else {           toString(min(x$DT$version))         },         versions_end = x$versions_end,         time_range = if (nrow(x$DT) == 0L) {           \"0 `time_value`s\"         } else {           sprintf(\"%s -- %s\", min(x$DT$time_value), max(x$DT$time_value))         },         n = nrow(x$DT),         class1 = class(x)[[1L]]       )     },     .before = 5, .all_versions = TRUE,     .versions = versions   ) %>%   ungroup() %>%   # Focus on one geo_value so we can better see the columns above:   filter(geo_value == \"ca\") %>%   select(-geo_value) #> # A tibble: 14 √ó 6 #>    version    versions_start versions_end time_range                   n class1  #>    <date>     <chr>          <date>       <chr>                    <int> <chr>   #>  1 2020-06-02 2020-06-02     2020-06-02   2020-06-01 -- 2020-06-01     1 epi_ar‚Ä¶ #>  2 2020-06-03 2020-06-02     2020-06-03   2020-06-01 -- 2020-06-02     2 epi_ar‚Ä¶ #>  3 2020-06-04 2020-06-02     2020-06-04   2020-06-01 -- 2020-06-03     3 epi_ar‚Ä¶ #>  4 2020-06-05 2020-06-02     2020-06-05   2020-06-01 -- 2020-06-04     4 epi_ar‚Ä¶ #>  5 2020-06-06 2020-06-02     2020-06-06   2020-06-01 -- 2020-06-05     8 epi_ar‚Ä¶ #>  6 2020-06-07 2020-06-03     2020-06-07   2020-06-02 -- 2020-06-06     9 epi_ar‚Ä¶ #>  7 2020-06-08 2020-06-04     2020-06-08   2020-06-03 -- 2020-06-07     9 epi_ar‚Ä¶ #>  8 2020-06-09 2020-06-05     2020-06-09   2020-06-04 -- 2020-06-08     8 epi_ar‚Ä¶ #>  9 2020-06-10 2020-06-06     2020-06-10   2020-06-05 -- 2020-06-09     8 epi_ar‚Ä¶ #> 10 2020-06-11 2020-06-07     2020-06-11   2020-06-06 -- 2020-06-10     8 epi_ar‚Ä¶ #> 11 2020-06-12 2020-06-08     2020-06-12   2020-06-07 -- 2020-06-11     8 epi_ar‚Ä¶ #> 12 2020-06-13 2020-06-09     2020-06-13   2020-06-08 -- 2020-06-12     8 epi_ar‚Ä¶ #> 13 2020-06-14 2020-06-10     2020-06-14   2020-06-09 -- 2020-06-13     8 epi_ar‚Ä¶ #> 14 2020-06-15 2020-06-11     2020-06-15   2020-06-10 -- 2020-06-14     8 epi_ar‚Ä¶"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_truncate_versions_after.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter an epi_archive object to keep only older versions ‚Äî epix_truncate_versions_after","title":"Filter an epi_archive object to keep only older versions ‚Äî epix_truncate_versions_after","text":"Generates filtered epi_archive epi_archive object, keeping rows version falling specified date.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_truncate_versions_after.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter an epi_archive object to keep only older versions ‚Äî epix_truncate_versions_after","text":"","code":"epix_truncate_versions_after(x, max_version)  # S3 method for class 'epi_archive' epix_truncate_versions_after(x, max_version)  # S3 method for class 'grouped_epi_archive' epix_truncate_versions_after(x, max_version)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_truncate_versions_after.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter an epi_archive object to keep only older versions ‚Äî epix_truncate_versions_after","text":"x epi_archive object. max_version latest version include archive.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/epix_truncate_versions_after.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter an epi_archive object to keep only older versions ‚Äî epix_truncate_versions_after","text":"epi_archive object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/f_no_na.html","id":null,"dir":"Reference","previous_headings":"","what":"use when the default behavior returns a warning on empty lists, which we do not want, and there is no super clean way of preventing this ‚Äî f_no_na","title":"use when the default behavior returns a warning on empty lists, which we do not want, and there is no super clean way of preventing this ‚Äî f_no_na","text":"use default behavior returns warning empty lists, want, super clean way preventing ","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/f_no_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"use when the default behavior returns a warning on empty lists, which we do not want, and there is no super clean way of preventing this ‚Äî f_no_na","text":"","code":"f_no_na(f, x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_chr_with_quotes.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a character vector as a string via deparsing/quoting each ‚Äî format_chr_with_quotes","title":"Format a character vector as a string via deparsing/quoting each ‚Äî format_chr_with_quotes","text":"Format character vector string via deparsing/quoting ","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_chr_with_quotes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a character vector as a string via deparsing/quoting each ‚Äî format_chr_with_quotes","text":"","code":"format_chr_with_quotes(x, empty = \"*none*\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_chr_with_quotes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a character vector as a string via deparsing/quoting each ‚Äî format_chr_with_quotes","text":"x chr; e.g., colnames data frame empty string; output x length 0?","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_chr_with_quotes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a character vector as a string via deparsing/quoting each ‚Äî format_chr_with_quotes","text":"string","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_class_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a class vector as a string via deparsing it ‚Äî format_class_vec","title":"Format a class vector as a string via deparsing it ‚Äî format_class_vec","text":"Format class vector string via deparsing ","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_class_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a class vector as a string via deparsing it ‚Äî format_class_vec","text":"","code":"format_class_vec(class_vec)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_class_vec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a class vector as a string via deparsing it ‚Äî format_class_vec","text":"class_vec chr; output class(object) object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_class_vec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a class vector as a string via deparsing it ‚Äî format_class_vec","text":"string","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_tibble_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a tibble row as chr ‚Äî format_tibble_row","title":"Format a tibble row as chr ‚Äî format_tibble_row","text":"Format tibble row chr","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_tibble_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a tibble row as chr ‚Äî format_tibble_row","text":"","code":"format_tibble_row(x, empty = \"*none*\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_tibble_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a tibble row as chr ‚Äî format_tibble_row","text":"x tibble single row","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_tibble_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a tibble row as chr ‚Äî format_tibble_row","text":"chr one entry per column, form \" = \"","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varname.html","id":null,"dir":"Reference","previous_headings":"","what":"","title":"","text":"Designed give good output interpolated cli. Main purpose add backticks around variable names necessary.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varname.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"","text":"","code":"format_varname(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varname.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"","text":"x string; e.g., colname","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varname.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"","text":"string","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varnames.html","id":null,"dir":"Reference","previous_headings":"","what":"","title":"","text":"Designed give good output interpolated cli. Main purpose add backticks around variable names necessary, something empty string length 0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"","text":"","code":"format_varnames(x, empty = \"*none*\")"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"","text":"x chr; e.g., colnames data frame empty string; output x length 0?","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/format_varnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"","text":"chr","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/full_date_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a complete date sequence between min(x$time_value) and max (x$time_value). Produce lists of dates before min(x$time_value) and after max(x$time_value) for padding initial and final windows to size n. ‚Äî full_date_seq","title":"Make a complete date sequence between min(x$time_value) and max (x$time_value). Produce lists of dates before min(x$time_value) and after max(x$time_value) for padding initial and final windows to size n. ‚Äî full_date_seq","text":"args assumed validated calling function (using validate_slide_window_arg).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/full_date_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a complete date sequence between min(x$time_value) and max (x$time_value). Produce lists of dates before min(x$time_value) and after max(x$time_value) for padding initial and final windows to size n. ‚Äî full_date_seq","text":"","code":"full_date_seq(x, before, after, time_type)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/geo_column_names.html","id":null,"dir":"Reference","previous_headings":"","what":"potential geo_value columns ‚Äî geo_column_names","title":"potential geo_value columns ‚Äî geo_column_names","text":"full list potential substitutions geo_value column name: geo_value, geo_values, geo_id, geos, location, jurisdiction, fips, zip, county, hrr, msa, state, province, nation, states, provinces, counties, geo_Value, Geo_Value, Geo_Values, Geo_Id, Geos, Location, Jurisdiction, Fips, Zip, County, Hrr, Msa, State, Province, Nation, States, Provinces, Counties, Geo_Value","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/geo_column_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"potential geo_value columns ‚Äî geo_column_names","text":"","code":"geo_column_names()"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/get_last_run.html","id":null,"dir":"Reference","previous_headings":"","what":"return the first value in values_from from the last string of trues in bool_vec ‚Äî get_last_run","title":"return the first value in values_from from the last string of trues in bool_vec ‚Äî get_last_run","text":"point operation get value values_from occurs index start last run true values bool_vec. example, c(1,1,0,1,1), want 4th entry, since 0 breaking run","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/get_last_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"return the first value in values_from from the last string of trues in bool_vec ‚Äî get_last_run","text":"","code":"get_last_run(bool_vec, values_from)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_by.epi_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"group_by and related methods for epi_archive, grouped_epi_archive ‚Äî group_by.epi_archive","title":"group_by and related methods for epi_archive, grouped_epi_archive ‚Äî group_by.epi_archive","text":"group_by related methods epi_archive, grouped_epi_archive","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_by.epi_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"group_by and related methods for epi_archive, grouped_epi_archive ‚Äî group_by.epi_archive","text":"","code":"# S3 method for class 'epi_archive' group_by(.data, ..., .add = FALSE, .drop = dplyr::group_by_drop_default(.data))  # S3 method for class 'grouped_epi_archive' group_by(.data, ..., .add = FALSE, .drop = dplyr::group_by_drop_default(.data))  # S3 method for class 'grouped_epi_archive' group_by_drop_default(.tbl)  # S3 method for class 'grouped_epi_archive' group_vars(x)  # S3 method for class 'grouped_epi_archive' groups(x)  # S3 method for class 'grouped_epi_archive' ungroup(x, ...)  is_grouped_epi_archive(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_by.epi_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"group_by and related methods for epi_archive, grouped_epi_archive ‚Äî group_by.epi_archive","text":".data epi_archive grouped_epi_archive ... Similar dplyr::group_by (see \"Details:\" edge cases); group_by: unquoted variable name(s) \"data masking\" expression(s). possible use dplyr::mutate-like syntax calculate new columns perform grouping, note , regrouping already-grouped .data object, calculations carried ignoring grouping (dplyr). ungroup: either empty, order remove grouping output epi_archive; variable name(s) \"tidy-select\" expression(s), order remove matching variables list grouping variables, output another grouped_epi_archive. .add Boolean. FALSE, default, output grouped variable selection ... ; TRUE, output grouped current grouping variables plus variable selection .... .drop described dplyr::group_by; determines treatment factor columns. .tbl grouped_epi_archive object. x groups, group_vars, ungroup: grouped_epi_archive; is_grouped_epi_archive: object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_by.epi_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"group_by and related methods for epi_archive, grouped_epi_archive ‚Äî group_by.epi_archive","text":"match dplyr, group_by allows \"data masking\" (also referred \"tidy evaluation\") expressions ..., just column names, way similar mutate. Note replacing removing key columns expressions disabled. archive %>% group_by() expressions group regroup zero columns (indicating rows treated part one large group) output grouped_epi_archive, order enable use grouped_epi_archive methods result. slight contrast operations tibbles grouped tibbles, output grouped_df circumstances. Using group_by .add=FALSE override existing grouping disabled; instead, ungroup first group_by. group_by_drop_default (ungrouped) epi_archives expected dispatch group_by_drop_default.default (dedicated method grouped_epi_archives).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_by.epi_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"group_by and related methods for epi_archive, grouped_epi_archive ‚Äî group_by.epi_archive","text":"","code":"grouped_archive <- archive_cases_dv_subset %>% group_by(geo_value)  # `print` for metadata and method listing: grouped_archive %>% print() #> A `grouped_epi_archive` object: #> * Groups: geo_value #> It wraps an ungrouped `epi_archive`, with metadata: #> ‚Ñπ Min/max time values: 2020-06-01 / 2021-11-30 #> ‚Ñπ First/last version with update: 2020-06-02 / 2021-12-01 #> ‚Ñπ Versions end: 2021-12-01 #> ‚Ñπ A preview of the table (129638 rows x 5 columns): #> Key: <geo_value, time_value, version> #>         geo_value time_value    version percent_cli case_rate_7d_av #>            <char>     <Date>     <Date>       <num>           <num> #>      1:        ca 2020-06-01 2020-06-02          NA        6.628329 #>      2:        ca 2020-06-01 2020-06-06    2.140116        6.628329 #>      3:        ca 2020-06-01 2020-06-07    2.140116        6.628329 #>      4:        ca 2020-06-01 2020-06-08    2.140379        6.628329 #>      5:        ca 2020-06-01 2020-06-09    2.114430        6.628329 #>     ---                                                             #> 129634:        tx 2021-11-26 2021-11-29    1.858596        7.957657 #> 129635:        tx 2021-11-27 2021-11-28          NA        7.174299 #> 129636:        tx 2021-11-28 2021-11-29          NA        6.834681 #> 129637:        tx 2021-11-29 2021-11-30          NA        8.841247 #> 129638:        tx 2021-11-30 2021-12-01          NA        9.566218  # The primary use for grouping is to perform a grouped `epix_slide`:  archive_cases_dv_subset %>%   group_by(geo_value) %>%   epix_slide(     .f = ~ mean(.x$case_rate_7d_av),     .before = 2,     .versions = as.Date(\"2020-06-11\") + 0:2,     .new_col_name = \"case_rate_3d_av\"   ) %>%   ungroup() #> # A tibble: 12 √ó 3 #>    geo_value version    case_rate_3d_av #>    <chr>     <date>               <dbl> #>  1 ca        2020-06-11            7.19 #>  2 fl        2020-06-11            5.71 #>  3 ny        2020-06-11            4.59 #>  4 tx        2020-06-11            5.62 #>  5 ca        2020-06-12            7.52 #>  6 fl        2020-06-12            5.82 #>  7 ny        2020-06-12            4.34 #>  8 tx        2020-06-12            5.91 #>  9 ca        2020-06-13            7.62 #> 10 fl        2020-06-13            6.11 #> 11 ny        2020-06-13            4.14 #> 12 tx        2020-06-13            6.03  # -----------------------------------------------------------------  # Advanced: some other features of dplyr grouping are implemented:  library(dplyr) toy_archive <-   tribble(     ~geo_value, ~age_group, ~time_value, ~version, ~value,     \"us\", \"adult\", \"2000-01-01\", \"2000-01-02\", 121,     \"us\", \"pediatric\", \"2000-01-02\", \"2000-01-03\", 5, # (addition)     \"us\", \"adult\", \"2000-01-01\", \"2000-01-03\", 125, # (revision)     \"us\", \"adult\", \"2000-01-02\", \"2000-01-03\", 130 # (addition)   ) %>%   mutate(     age_group = ordered(age_group, c(\"pediatric\", \"adult\")),     time_value = as.Date(time_value),     version = as.Date(version)   ) %>%   as_epi_archive(other_keys = \"age_group\")  # The following are equivalent: toy_archive %>% group_by(geo_value, age_group) #> A `grouped_epi_archive` object: #> * Groups: geo_value, age_group #> * Drops groups formed by factor levels that don't appear in the data #> It wraps an ungrouped `epi_archive`, with metadata: #> ‚Ñπ Other DT keys: age_group #> ‚Ñπ Min/max time values: 2000-01-01 / 2000-01-02 #> ‚Ñπ First/last version with update: 2000-01-02 / 2000-01-03 #> ‚Ñπ Versions end: 2000-01-03 #> ‚Ñπ A preview of the table (4 rows x 5 columns): #> Key: <geo_value, time_value, age_group, version> #>    geo_value age_group time_value    version value #>       <char>     <ord>     <Date>     <Date> <num> #> 1:        us     adult 2000-01-01 2000-01-02   121 #> 2:        us     adult 2000-01-01 2000-01-03   125 #> 3:        us pediatric 2000-01-02 2000-01-03     5 #> 4:        us     adult 2000-01-02 2000-01-03   130 toy_archive %>%   group_by(geo_value) %>%   group_by(age_group, .add = TRUE) #> A `grouped_epi_archive` object: #> * Groups: geo_value, age_group #> * Drops groups formed by factor levels that don't appear in the data #> It wraps an ungrouped `epi_archive`, with metadata: #> ‚Ñπ Other DT keys: age_group #> ‚Ñπ Min/max time values: 2000-01-01 / 2000-01-02 #> ‚Ñπ First/last version with update: 2000-01-02 / 2000-01-03 #> ‚Ñπ Versions end: 2000-01-03 #> ‚Ñπ A preview of the table (4 rows x 5 columns): #> Key: <geo_value, time_value, age_group, version> #>    geo_value age_group time_value    version value #>       <char>     <ord>     <Date>     <Date> <num> #> 1:        us     adult 2000-01-01 2000-01-02   121 #> 2:        us     adult 2000-01-01 2000-01-03   125 #> 3:        us pediatric 2000-01-02 2000-01-03     5 #> 4:        us     adult 2000-01-02 2000-01-03   130 grouping_cols <- c(\"geo_value\", \"age_group\") toy_archive %>% group_by(across(all_of(grouping_cols))) #> A `grouped_epi_archive` object: #> * Groups: geo_value, age_group #> * Drops groups formed by factor levels that don't appear in the data #> It wraps an ungrouped `epi_archive`, with metadata: #> ‚Ñπ Other DT keys: age_group #> ‚Ñπ Min/max time values: 2000-01-01 / 2000-01-02 #> ‚Ñπ First/last version with update: 2000-01-02 / 2000-01-03 #> ‚Ñπ Versions end: 2000-01-03 #> ‚Ñπ A preview of the table (4 rows x 5 columns): #> Key: <geo_value, time_value, age_group, version> #>    geo_value age_group time_value    version value #>       <char>     <ord>     <Date>     <Date> <num> #> 1:        us     adult 2000-01-01 2000-01-02   121 #> 2:        us     adult 2000-01-01 2000-01-03   125 #> 3:        us pediatric 2000-01-02 2000-01-03     5 #> 4:        us     adult 2000-01-02 2000-01-03   130  # And these are equivalent: toy_archive %>% group_by(geo_value) #> A `grouped_epi_archive` object: #> * Groups: geo_value #> It wraps an ungrouped `epi_archive`, with metadata: #> ‚Ñπ Other DT keys: age_group #> ‚Ñπ Min/max time values: 2000-01-01 / 2000-01-02 #> ‚Ñπ First/last version with update: 2000-01-02 / 2000-01-03 #> ‚Ñπ Versions end: 2000-01-03 #> ‚Ñπ A preview of the table (4 rows x 5 columns): #> Key: <geo_value, time_value, age_group, version> #>    geo_value age_group time_value    version value #>       <char>     <ord>     <Date>     <Date> <num> #> 1:        us     adult 2000-01-01 2000-01-02   121 #> 2:        us     adult 2000-01-01 2000-01-03   125 #> 3:        us pediatric 2000-01-02 2000-01-03     5 #> 4:        us     adult 2000-01-02 2000-01-03   130 toy_archive %>%   group_by(geo_value, age_group) %>%   ungroup(age_group) #> A `grouped_epi_archive` object: #> * Groups: geo_value #> It wraps an ungrouped `epi_archive`, with metadata: #> ‚Ñπ Other DT keys: age_group #> ‚Ñπ Min/max time values: 2000-01-01 / 2000-01-02 #> ‚Ñπ First/last version with update: 2000-01-02 / 2000-01-03 #> ‚Ñπ Versions end: 2000-01-03 #> ‚Ñπ A preview of the table (4 rows x 5 columns): #> Key: <geo_value, time_value, age_group, version> #>    geo_value age_group time_value    version value #>       <char>     <ord>     <Date>     <Date> <num> #> 1:        us     adult 2000-01-01 2000-01-02   121 #> 2:        us     adult 2000-01-01 2000-01-03   125 #> 3:        us pediatric 2000-01-02 2000-01-03     5 #> 4:        us     adult 2000-01-02 2000-01-03   130  # To get the grouping variable names as a character vector: toy_archive %>%   group_by(geo_value) %>%   group_vars() #> [1] \"geo_value\"  # To get the grouping variable names as a `list` of `name`s (a.k.a. symbols): toy_archive %>%   group_by(geo_value) %>%   groups() #> [[1]] #> geo_value #>   toy_archive %>%   group_by(geo_value, age_group, .drop = FALSE) %>%   epix_slide(.f = ~ sum(.x$value), .before = 20) %>%   ungroup() #> # A tibble: 4 √ó 4 #>   geo_value age_group version    slide_value #>   <chr>     <ord>     <date>           <dbl> #> 1 us        pediatric 2000-01-02           0 #> 2 us        adult     2000-01-02         121 #> 3 us        pediatric 2000-01-03           5 #> 4 us        adult     2000-01-03         255"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Group an epi_df object by default keys ‚Äî group_epi_df","title":"Group an epi_df object by default keys ‚Äî group_epi_df","text":"Group epi_df object default keys","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group an epi_df object by default keys ‚Äî group_epi_df","text":"","code":"group_epi_df(x, exclude = character())"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group an epi_df object by default keys ‚Äî group_epi_df","text":"x epi_df exclude character vector column names exclude grouping","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/group_epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group an epi_df object by default keys ‚Äî group_epi_df","text":"grouped epi_df","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate growth rate ‚Äî growth_rate","title":"Estimate growth rate ‚Äî growth_rate","text":"Estimates growth rate signal given points along underlying sequence. Several methodologies available; see growth rate vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate growth rate ‚Äî growth_rate","text":"","code":"growth_rate(   x = seq_along(y),   y,   x0 = x,   method = c(\"rel_change\", \"linear_reg\", \"smooth_spline\", \"trend_filter\"),   h = 7,   log_scale = FALSE,   dup_rm = FALSE,   na_rm = FALSE,   ... )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate growth rate ‚Äî growth_rate","text":"x Design points corresponding signal values y. Default seq_along(y) (, equally-spaced points 1 length y). y Signal values. x0 Points estimate growth rate. Must subset x (extrapolation allowed). Default x. method Either \"rel_change\", \"linear_reg\", \"smooth_spline\", \"trend_filter\", indicating method use growth rate calculation. first two local methods: run sliding fashion sequence (order estimate derivatives hence growth rates); latter two global methods: run entire sequence. See details explanation. h Bandwidth sliding window, method \"rel_change\" \"linear_reg\". See details explanation. log_scale growth rates estimated using parametrization log scale? See details explanation. Default FALSE. dup_rm check remove duplicates x (corresponding elements y) computation? methods might handle duplicate x values gracefully, whereas others might fail (either quietly loudly). Default FALSE. na_rm missing values removed computation? Default FALSE. ... Additional arguments pass method used estimate derivative.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate growth rate ‚Äî growth_rate","text":"Vector growth rate estimates specified points x0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate growth rate ‚Äî growth_rate","text":"growth rate function f defined continuously-valued parameter t defined f'(t) / f(t), f'(t) derivative f t. estimate growth rate signal discrete-time (can thought evaluations discretizations underlying function continuous-time), can therefore estimate derivative divide signal value (possibly smoothed version signal value). following methods available estimating growth rate: \"rel_change\": uses (B/- 1) / h, B average y second half sliding window bandwidth h centered reference point x0, average first half. can seen using first-difference approximation derivative. \"linear_reg\": uses slope linear regression y x sliding window centered reference point x0, divided fitted value linear regression x0. \"smooth_spline\": uses estimated derivative x0 smoothing spline fit x y, via stats::smooth.spline(), divided fitted value spline x0. \"trend_filter\": uses estimated derivative x0 polynomial trend filtering (discrete spline) fit x y, via genlasso::trendfilter(), divided fitted value discrete spline x0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"log-scale","dir":"Reference","previous_headings":"","what":"Log Scale","title":"Estimate growth rate ‚Äî growth_rate","text":"alternative view growth rate function f general given defining g(t) = log(f(t)), observing g'(t) = f'(t) / f(t). Therefore, method estimates derivative can simply applied log signal interest, light, method (\"rel_change\", \"linear_reg\", \"smooth_spline\", \"trend_filter\") log scale analog, can used setting log_scale = TRUE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"sliding-windows","dir":"Reference","previous_headings":"","what":"Sliding Windows","title":"Estimate growth rate ‚Äî growth_rate","text":"local methods, \"rel_change\" \"linear_reg\", use sliding window centered reference point bandiwidth h. words, sliding window consists points x whose distance reference point h. Note unit distance implicitly defined x variable; example, x vector Date objects, h = 7, reference point January 7, sliding window contains data January 1 14 (matching behavior epi_slide() = h - 1 = h).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"additional-arguments","dir":"Reference","previous_headings":"","what":"Additional Arguments","title":"Estimate growth rate ‚Äî growth_rate","text":"global methods, \"smooth_spline\" \"trend_filter\", additional arguments can specified via ... underlying estimation function. smoothing spline case, additional arguments passed directly stats::smooth.spline() (defaults exactly function). trend filtering case works bit differently: , custom set arguments allowed (distributed internally genlasso::trendfilter() genlasso::cv.trendfilter()): ord: order piecewise polynomial trend filtering fit. Default 3. maxsteps: maximum number steps take solution path terminating. Default 1000. cv: cross-validation used choose effective degrees freedom fit? Default TRUE. k: number folds cross-validation used. Default 3. df: desired effective degrees freedom trend filtering fit. cv = FALSE, df must positive integer; cv = TRUE, df must one \"min\" \"1se\" indicating selection rule use based cross-validation error curve: minimum 1-standard-error rule, respectively. Default \"min\" (going along default cv = TRUE). Note cv = FALSE, require df set user.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate growth rate ‚Äî growth_rate","text":"","code":"# COVID cases growth rate by state using default method relative change cases_deaths_subset %>%   group_by(geo_value) %>%   mutate(cases_gr = growth_rate(x = time_value, y = cases)) #> An `epi_df` object, 4,026 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 7 #> # Groups:   geo_value [6] #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # ‚Ñπ 4,016 more rows #> # ‚Ñπ 1 more variable: cases_gr <dbl>  # Log scale, degree 4 polynomial and 6-fold cross validation cases_deaths_subset %>%   group_by(geo_value) %>%   mutate(gr_poly = growth_rate(x = time_value, y = cases, log_scale = TRUE, ord = 4, k = 6)) #> Warning: There were 3 warnings in `mutate()`. #> The first warning was: #> ‚Ñπ In argument: `gr_poly = growth_rate(...)`. #> ‚Ñπ In group 1: `geo_value = \"ca\"`. #> Caused by warning in `log()`: #> ! NaNs produced #> ‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings. #> An `epi_df` object, 4,026 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-03-20 #>  #> # A tibble: 4,026 √ó 7 #> # Groups:   geo_value [6] #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # ‚Ñπ 4,016 more rows #> # ‚Ñπ 1 more variable: gr_poly <dbl>"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/guess_column_name.html","id":null,"dir":"Reference","previous_headings":"","what":"rename potential time_value columns ‚Äî guess_column_name","title":"rename potential time_value columns ‚Äî guess_column_name","text":"potentially renames","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/guess_column_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rename potential time_value columns ‚Äî guess_column_name","text":"","code":"guess_column_name(x, column_name, substitutions)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/guess_column_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"rename potential time_value columns ‚Äî guess_column_name","text":"x tibble potentially rename substitutions named vector. potential substitions, every name time_value","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/guess_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use max valid period as guess for period of time_values ‚Äî guess_period","text":"","code":"guess_period(   time_values,   time_values_arg = rlang::caller_arg(time_values),   ... )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/guess_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use max valid period as guess for period of time_values ‚Äî guess_period","text":"time_values Vector containing time-interval-like time-point-like data, least two distinct values. time_values_arg Optional, string; name give time_values error messages. Defaults quoting expression caller fed time_values argument. ... empty, satisfy S3 generic.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/guess_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use max valid period as guess for period of time_values ‚Äî guess_period","text":"length-1 vector;  class either class base::diff() time values, integer, double, time_values can exactly obtained adding k * result integer k, smaller result can achieve .","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/is_locf.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks to see if a value in a vector is LOCF ‚Äî is_locf","title":"Checks to see if a value in a vector is LOCF ‚Äî is_locf","text":"LOCF meaning last observation carried forward. lags vector 1, compares . doubles uses float comparison via dplyr::near, otherwise uses equality.  NA's NaN's considered equal .","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/is_locf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks to see if a value in a vector is LOCF ‚Äî is_locf","text":"","code":"is_locf(vec, tolerance)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/key_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Grab any keys associated to an epi_df ‚Äî key_colnames","title":"Grab any keys associated to an epi_df ‚Äî key_colnames","text":"Grab keys associated epi_df","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/key_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grab any keys associated to an epi_df ‚Äî key_colnames","text":"","code":"key_colnames(x, ...)  # Default S3 method key_colnames(x, ...)  # S3 method for class 'data.frame' key_colnames(x, other_keys = character(0L), exclude = character(0L), ...)  # S3 method for class 'epi_df' key_colnames(x, exclude = character(0L), ...)  # S3 method for class 'epi_archive' key_colnames(x, exclude = character(0L), ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/key_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grab any keys associated to an epi_df ‚Äî key_colnames","text":"x data.frame, tibble, epi_df ... additional arguments passed methods other_keys optional character vector keys include exclude optional character vector keys exclude","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/key_colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grab any keys associated to an epi_df ‚Äî key_colnames","text":"epi_df, returns \"keys\". Otherwise NULL.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/max_version_with_row_in.html","id":null,"dir":"Reference","previous_headings":"","what":"max(x$version), with error if x has 0 rows ‚Äî max_version_with_row_in","title":"max(x$version), with error if x has 0 rows ‚Äî max_version_with_row_in","text":"Exported make defaults easily copyable.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/max_version_with_row_in.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"max(x$version), with error if x has 0 rows ‚Äî max_version_with_row_in","text":"","code":"max_version_with_row_in(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/max_version_with_row_in.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"max(x$version), with error if x has 0 rows ‚Äî max_version_with_row_in","text":"x x argument as_epi_archive","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/max_version_with_row_in.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"max(x$version), with error if x has 0 rows ‚Äî max_version_with_row_in","text":"max(x$version) rows; raises error 0 rows NA version value","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/next_after.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the next possible value greater than x of the same type ‚Äî next_after","title":"Get the next possible value greater than x of the same type ‚Äî next_after","text":"Get next possible value greater x type","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/next_after.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the next possible value greater than x of the same type ‚Äî next_after","text":"","code":"next_after(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/next_after.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the next possible value greater than x of the same type ‚Äî next_after","text":"x starting \"value\"(s)","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/next_after.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the next possible value greater than x of the same type ‚Äî next_after","text":"class, typeof, length x","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/num_percent.html","id":null,"dir":"Reference","previous_headings":"","what":"simple util for printing a fraction and it's percent ‚Äî num_percent","title":"simple util for printing a fraction and it's percent ‚Äî num_percent","text":"simple util printing fraction percent","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/num_percent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simple util for printing a fraction and it's percent ‚Äî num_percent","text":"","code":"num_percent(a, b, b_description)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/paste_lines.html","id":null,"dir":"Reference","previous_headings":"","what":"Paste chr entries (lines) together with ","title":"Paste chr entries (lines) together with ","text":"Paste chr entries (lines) together \"\\n\" separators, trailing \"\\n\"","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/paste_lines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Paste chr entries (lines) together with ","text":"","code":"paste_lines(lines)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/paste_lines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Paste chr entries (lines) together with ","text":"lines chr","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/paste_lines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Paste chr entries (lines) together with ","text":"string","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator ‚Äî %>%","title":"Pipe operator ‚Äî %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator ‚Äî %>%","text":"","code":"lhs %>% rhs"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/print.epi_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Print information about an epi_archive object ‚Äî print.epi_archive","title":"Print information about an epi_archive object ‚Äî print.epi_archive","text":"Print information epi_archive object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/print.epi_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print information about an epi_archive object ‚Äî print.epi_archive","text":"","code":"# S3 method for class 'epi_archive' print(x, ..., class = TRUE, methods = TRUE)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/print.epi_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print information about an epi_archive object ‚Äî print.epi_archive","text":"x epi_archive object. ... empty, satisfy S3 generic. class Boolean; whether print class label header methods Boolean; whether print available methods archive","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/print.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Base S3 methods for an epi_df object ‚Äî print.epi_df","title":"Base S3 methods for an epi_df object ‚Äî print.epi_df","text":"Print summary functions epi_df object. Prints variety summary statistics epi_df object, time range included geographic coverage.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/print.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base S3 methods for an epi_df object ‚Äî print.epi_df","text":"","code":"# S3 method for class 'epi_df' print(x, ...)  # S3 method for class 'epi_df' summary(object, ...)  # S3 method for class 'epi_df' group_by(.data, ...)  # S3 method for class 'epi_df' ungroup(x, ...)  # S3 method for class 'epi_df' group_modify(.data, .f, ..., .keep = FALSE)  # S3 method for class 'epi_df' unnest(data, ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/print.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base S3 methods for an epi_df object ‚Äî print.epi_df","text":"x epi_df ... Additional arguments, compatibility summary(). Currently unused. object epi_df .data epi_df .f function formula; see dplyr::group_modify .keep Boolean; see dplyr::group_modify data epi_df","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages ‚Äî reexports","title":"Objects exported from other packages ‚Äî reexports","text":"objects imported packages. Follow links see documentation. dplyr arrange, filter, group_by, group_modify, mutate, relocate, rename, slice, ungroup ggplot2 autoplot tidyr complete, full_seq, unnest tsibble as_tsibble","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/removed_by_compactify.html","id":null,"dir":"Reference","previous_headings":"","what":"get the entries that compactify would remove ‚Äî removed_by_compactify","title":"get the entries that compactify would remove ‚Äî removed_by_compactify","text":"get entries compactify remove","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/removed_by_compactify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get the entries that compactify would remove ‚Äî removed_by_compactify","text":"","code":"removed_by_compactify(df, keys, tolerance)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/revision_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to describe revision behavior for an archive. ‚Äî revision_summary","title":"A function to describe revision behavior for an archive. ‚Äî revision_summary","text":"revision_summary removes missing values (requested), computes basic statistics revision behavior archive, returning tibble summarizing revisions per time_value+epi_key features. print_inform true, prints concise summary. columns returned : n_revisions: total number revisions entry min_lag: minimum time value (drop_nas=FALSE, includes NA's) max_lag: amount time final (new) version (caveat drop_nas=FALSE, though far less likely matter) min_value: minimum value across revisions max_value: maximum value across revisions median_value: median value across revisions spread: difference smallest largest values (always excludes NA values) rel_spread: spread divided largest value (always less 1). Note need final value. NA whenever spread 0. time_near_latest: time taken revisions settle within within_latest (default 20%) final value stay . example, consider series (0, 20, 99, 150, 102, 100); time_near_latest 5, since even though 99 within 20%, outside window afterwards 150.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/revision_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to describe revision behavior for an archive. ‚Äî revision_summary","text":"","code":"revision_summary(   epi_arch,   ...,   drop_nas = TRUE,   print_inform = TRUE,   min_waiting_period = as.difftime(60, units = \"days\"),   within_latest = 0.2,   quick_revision = as.difftime(3, units = \"days\"),   few_revisions = 3,   abs_spread_threshold = NULL,   rel_spread_threshold = 0.1,   compactify_tol = .Machine$double.eps^0.5,   should_compactify = TRUE )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/revision_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to describe revision behavior for an archive. ‚Äî revision_summary","text":"epi_arch epi_archive analyzed ... <tidyselect>, used choose column summarize. empty, chooses first. Currently implemented one column time. drop_nas bool, drop NA values archive? dropping NA's compactify run make sure duplicate values occasions signal revised NA, back immediately-preceding value. print_inform bool, determines whether print summary information, return full summary tibble min_waiting_period difftime, integer NULL. Sets cutoff: time_values earlier min_waiting_period versions_end removed. min_waiting_period characterize typical time revisions occur.  default 60 days corresponds typical final value case counts reported context insurance. avoid filtering, either set NULL 0. within_latest double 0 1. Determines threshold used time_to quick_revision difftime integer (integer treated days), printed summary, amount time final revision actual time_value consider revision quickly resolved. Default 3 days few_revisions integer, printed summary, upper bound number revisions consider \"\". Default 3. abs_spread_threshold numeric, printed summary, maximum spread used characterize revisions actually change much. Default 5% maximum value dataset, unit dependent values, likely needs chosen appropriate scale dataset. rel_spread_threshold float 0 1, printed summary, relative spread fraction used characterize revisions actually change much. Default .1, 10% final value compactify_tol float, used drop_nas=TRUE, determines threshold two floats considered identical. should_compactify bool. Compactify TRUE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/revision_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to describe revision behavior for an archive. ‚Äî revision_summary","text":"","code":"revision_example <- revision_summary(archive_cases_dv_subset, percent_cli) #> Min lag (time to first version): #>      min median     mean     max #>   3 days 3 days 3.5 days 12 days #> Fraction of epi_key+time_values with #> No revisions: #> ‚Ä¢ 0 out of 1,956 (0%) #> Quick revisions (last revision within 3 days of the `time_value`): #> ‚Ä¢ 0 out of 1,956 (0%) #> Few revisions (At most 3 revisions for that `time_value`): #> ‚Ä¢ 0 out of 1,956 (0%) #>  #> Fraction of revised epi_key+time_values which have: #> Less than 0.1 spread in relative value: #> ‚Ä¢ 91 out of 1,956 (4.65%) #> Spread of more than 2.22056495 in actual value (when revised): #> ‚Ä¢ 671 out of 1,956 (34.3%) #> days until within 20% of the latest value: #>      min median     mean     max #>   3 days 5 days 9.1 days 67 days revision_example %>% arrange(desc(spread)) #> # A tibble: 1,956 √ó 11 #>    time_value geo_value n_revisions min_lag max_lag time_near_latest spread #>    <date>     <chr>           <dbl> <drtn>  <drtn>  <drtn>            <dbl> #>  1 2020-12-26 ca                 62 3 days  73 days  6 days           14.1  #>  2 2020-12-25 ca                 62 3 days  73 days  7 days           13.2  #>  3 2020-11-27 fl                 66 3 days  73 days  4 days           12.0  #>  4 2021-09-27 fl                 43 3 days  63 days 59 days            9.79 #>  5 2020-12-25 fl                 62 3 days  73 days  4 days            9.75 #>  6 2021-09-26 fl                 43 4 days  64 days 60 days            9.48 #>  7 2021-09-27 ca                 43 3 days  63 days  8 days            9.31 #>  8 2021-09-25 fl                 43 5 days  65 days 61 days            8.83 #>  9 2020-11-05 ny                 66 3 days  73 days 11 days            8.64 #> 10 2020-11-27 tx                 66 3 days  73 days 10 days            8.56 #> # ‚Ñπ 1,946 more rows #> # ‚Ñπ 4 more variables: rel_spread <dbl>, min_value <dbl>, max_value <dbl>, #> #   median_value <dbl>"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/sum_groups_epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate an epi_df object ‚Äî sum_groups_epi_df","title":"Aggregate an epi_df object ‚Äî sum_groups_epi_df","text":"Aggregates epi_df object specified group columns, summing value column, returning epi_df. aggregating geo_value, resulting epi_df geo_value set \"total\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/sum_groups_epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate an epi_df object ‚Äî sum_groups_epi_df","text":"","code":"sum_groups_epi_df(.x, sum_cols = \"value\", group_cols = character())"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/sum_groups_epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate an epi_df object ‚Äî sum_groups_epi_df","text":".x epi_df sum_cols character vector columns aggregate group_cols character vector column names group . \"time_value\" included default.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/sum_groups_epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate an epi_df object ‚Äî sum_groups_epi_df","text":"epi_df object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/test_sensible_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Is x an ","title":"Is x an ","text":"Like checkmate::test_int disallowing non-sensible classes test_int accepts, difftimes. rely .numeric determine class appropriateness; note .numeric simply checking class \"numeric\" (else fail integer class).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/test_sensible_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is x an ","text":"","code":"test_sensible_int(   x,   na.ok = FALSE,   lower = -Inf,   upper = Inf,   tol = sqrt(.Machine$double.eps),   null.ok = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/test_sensible_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is x an ","text":"x object","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/test_sensible_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is x an ","text":"Boolean","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_column_names.html","id":null,"dir":"Reference","previous_headings":"","what":"potential time_value columns ‚Äî time_column_names","title":"potential time_value columns ‚Äî time_column_names","text":"full list potential substitutions time_value column name: time_value, date, time, datetime, dateTime, date_time, target_date, week, epiweek, month, mon, year, yearmon, yearmonth, yearMon, yearMonth, dates, time_values, target_dates, time_Value, Time_Value, Date, Time, Datetime, DateTime, Date_Time, Target_Date, Week, Epiweek, Month, Mon, Year, Yearmon, Yearmonth, YearMon, YearMonth, Dates, Time_Values, Target_Dates, Time_Value","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_column_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"potential time_value columns ‚Äî time_column_names","text":"","code":"time_column_names()"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_delta_to_n_steps.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a time delta to a integerish number of ","title":"Convert a time delta to a integerish number of ","text":"Convert time delta integerish number \"unit\" steps time values","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_delta_to_n_steps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a time delta to a integerish number of ","text":"","code":"time_delta_to_n_steps(time_delta, time_type)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_delta_to_n_steps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a time delta to a integerish number of ","text":"time_delta vector can added time values time type time_type arrive time values time type,  vector Inf/-Inf entries mixed , supported class time_delta, even time_type necessarily support Inf/-Inf entries. Basically slide window arg without sign length restrictions. time_type validate_slide_window_arg","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_delta_to_n_steps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a time delta to a integerish number of ","text":"bare integerish vector (possible infinite values) produces result time_delta multiplied natural unit_time_delta time type added time values time type time_type. given time type support infinite values, produce +Inf -Inf analogous entries time_delta, match addition result match addition result non-infinite entries.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_within_x_latest.html","id":null,"dir":"Reference","previous_headings":"","what":"pull the value from lags when values starts indefinitely being within prop of it's last value. ‚Äî time_within_x_latest","title":"pull the value from lags when values starts indefinitely being within prop of it's last value. ‚Äî time_within_x_latest","text":"pull value lags values starts indefinitely within prop last value.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_within_x_latest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pull the value from lags when values starts indefinitely being within prop of it's last value. ‚Äî time_within_x_latest","text":"","code":"time_within_x_latest(lags, values, prop = 0.2)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/time_within_x_latest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pull the value from lags when values starts indefinitely being within prop of it's last value. ‚Äî time_within_x_latest","text":"values 1 column tibble. errors may occur otherwise","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unit_time_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"Object that, added to time_values of time_type, advances by one time step/interval ‚Äî unit_time_delta","title":"Object that, added to time_values of time_type, advances by one time step/interval ‚Äî unit_time_delta","text":"Object , added time_values time_type, advances one time step/interval","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unit_time_delta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Object that, added to time_values of time_type, advances by one time step/interval ‚Äî unit_time_delta","text":"","code":"unit_time_delta(time_type)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unit_time_delta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Object that, added to time_values of time_type, advances by one time step/interval ‚Äî unit_time_delta","text":"time_type string; epi_df's epi_archive's time_type","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unit_time_delta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Object that, added to time_values of time_type, advances by one time step/interval ‚Äî unit_time_delta","text":"object u time_values + u represents advancing one time step / moving subsequent time interval time_values object time type time_type, time_values + k * u integerish vector k advances k steps (vectorization, recycling).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unwrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract singular element of a length-1 unnamed list (validated) ‚Äî unwrap","title":"Extract singular element of a length-1 unnamed list (validated) ‚Äî unwrap","text":"Inverse list(elt).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unwrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract singular element of a length-1 unnamed list (validated) ‚Äî unwrap","text":"","code":"unwrap(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unwrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract singular element of a length-1 unnamed list (validated) ‚Äî unwrap","text":"x length-1 list","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/unwrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract singular element of a length-1 unnamed list (validated) ‚Äî unwrap","text":"x[1L], x actually length-1 list; error otherwise","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/upcase_snake_case.html","id":null,"dir":"Reference","previous_headings":"","what":"given a vector of characters, add the same values, but upcased, e.g. ","title":"given a vector of characters, add the same values, but upcased, e.g. ","text":"given vector characters, add values, upcased, e.g. \"date\" -> c(\"date\", \"Date\") \"target_date\" -> c(\"target_date\", \"Target_Date\")","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/upcase_snake_case.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"given a vector of characters, add the same values, but upcased, e.g. ","text":"","code":"upcase_snake_case(vec)"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/validate_version_bound.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate a version bound arg ‚Äî validate_version_bound","title":"Validate a version bound arg ‚Äî validate_version_bound","text":"Expected used clobberable_versions_start, versions_end, similar arguments. additional context-specific checks may needed. Side effects: raises error version bound appears invalid.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/validate_version_bound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate a version bound arg ‚Äî validate_version_bound","text":"","code":"validate_version_bound(   version_bound,   x,   na_ok = FALSE,   version_bound_arg = rlang::caller_arg(version_bound),   x_arg = rlang::caller_arg(x) )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/validate_version_bound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate a version bound arg ‚Äî validate_version_bound","text":"version_bound version bound validate x data frame containing version column check compatibility na_ok Boolean; NA acceptable \"bound\"? (, NA special context-dependent meaning.) version_bound_arg optional string; call version bound error messages","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/version_column_names.html","id":null,"dir":"Reference","previous_headings":"","what":"potential version columns ‚Äî version_column_names","title":"potential version columns ‚Äî version_column_names","text":"full list potential substitutions version column name: version, issue, release, Version, Issue, Release","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/version_column_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"potential version columns ‚Äî version_column_names","text":"","code":"version_column_names()"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_symbolics.html","id":null,"dir":"Reference","previous_headings":"","what":"Line wrap list holding symbolic, with prefix&indent ‚Äî wrap_symbolics","title":"Line wrap list holding symbolic, with prefix&indent ‚Äî wrap_symbolics","text":"Helps pretty-print objects. Adds backticks, commas, prefixes, indentation. Wraps lines, insert line breaks middle name .","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_symbolics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Line wrap list holding symbolic, with prefix&indent ‚Äî wrap_symbolics","text":"","code":"wrap_symbolics(   symbolics,   initial = \"\",   common_prefix = \"\",   none_str = \"<none>\",   width = getOption(\"width\", 80L) )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_symbolics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Line wrap list holding symbolic, with prefix&indent ‚Äî wrap_symbolics","text":"symbolics List symbolic objects: variable names (potentially empty) initial Optional; single string: prefix initial line result; e.g., \"Variable names: \". Defaults \"\". non-initial lines indented whitespace matching (estimated) visual width initial. common_prefix Optional; single string: prefix every line (appear initial); e.g., \"# \". Defaults \"\". none_str Optional; single string: display given length-0 input. combined common_prefix initial. width Optional; single integer: desired maximum formatted line width. formatted output may obey setting common_prefix plus initial long printing width narrow.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_symbolics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Line wrap list holding symbolic, with prefix&indent ‚Äî wrap_symbolics","text":"chr; print, use base::writeLines.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_varnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Line wrap chr holding variable/column/other names, with prefix&indent ‚Äî wrap_varnames","title":"Line wrap chr holding variable/column/other names, with prefix&indent ‚Äî wrap_varnames","text":"Line wrap chr holding variable/column/names, prefix&indent","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_varnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Line wrap chr holding variable/column/other names, with prefix&indent ‚Äî wrap_varnames","text":"","code":"wrap_varnames(   nms,   initial = \"\",   common_prefix = \"\",   none_str = \"<none>\",   width = getOption(\"width\", 80L) )"},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_varnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Line wrap chr holding variable/column/other names, with prefix&indent ‚Äî wrap_varnames","text":"nms Character vector: variable names (potentially empty) initial Optional; single string: prefix initial line result; e.g., \"Variable names: \". Defaults \"\". non-initial lines indented whitespace matching (estimated) visual width initial. common_prefix Optional; single string: prefix every line (appear initial); e.g., \"# \". Defaults \"\". none_str Optional; single string: display given length-0 input. combined common_prefix initial. width Optional; single integer: desired maximum formatted line width. formatted output may obey setting common_prefix plus initial long printing width narrow.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/reference/wrap_varnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Line wrap chr holding variable/column/other names, with prefix&indent ‚Äî wrap_varnames","text":"chr; print, use base::writeLines.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-10","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.10","text":"Moved example datasets hosted package reexported epidatasets package. datasets can longer loaded data() can accessed epiprocess:: , loading package, just name dataset (#520). names starting jhu renamed uniform scheme now names starting covid. data set previously named jhu_confirmed_cumulative_num removed package, renamed version removed package, renamed version still available epidatasets. epi_slide_{sum,mean,opt} improved default output column names, additional arguments specifying names: .prefix, .suffix, .new_col_names. obtain old naming behavior, use .prefix =   \"slide_value_\". as_epi_df now removes grouping x applied.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-10","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.10","text":"epi_slide epix_slide now provide hints forget ~ using formula specify slide computation, bits forgotten syntax. Improved validation .window_size arguments. Rewrote lot package documentation consistent informative. Simplified streamlined vignettes. epi_slide_{sum,mean,opt} ungrouped epi_dfs now temporarily group geo_value other_keys slide operation rather raise error duplicated time values. epi_slide‚Äôs analogous automatic grouping made temporary order match. Improved speed key-uniqueness checks.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"bug-fixes-0-10","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"epiprocess 0.10","text":"Removed .window_size = 1 default epi_slide_{mean,sum,opt}; argument now mandatory, nearly always greater 1 except testing purposes. Fixed epi_slide_{sum,mean,opt} raising error certain tidyselect expressions.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-10","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.10","text":"Removed vignette dependency covidcast.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-9","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.9","text":"variables now dot-prefixed consistent tidyverse style functions allow tidyeval. /arguments replaced .window_size .align arguments. without name, unpacked separate columns without name prefixes name, become packed data.frame-class column (see tidyr::pack). as_list_col removed. can now directly return list slide computations instead. using as_list_col=TRUE, need wrap output list. Ungrouped slides longer allowed epi_slide. used geographic aggregation national, consider using sum_groups_epi_df. Added sum_groups_epi_df allow aggregation across key columns prior sliding. variables now dot-prefixed consistent tidyverse style functions allow tidyeval. without name, unpacked separate columns without name prefixes name, become packed data.frame-class column (see tidyr::pack). as_list_col removed. can now directly return list slide computations instead. using as_list_col=TRUE, need wrap output list. as_epi_df() now checks every group unique time values errors case. check performed beginning epi_slide(). check currently enforced dplyr operations (like joins, mutates, select), plan add future. as_epi_df() as_epi_archive() longer accept additional_metadata. Use new other_keys arg specify additional key columns, age group columns demographic breakdowns. Miscellaneous metadata longer handled epiprocess, can use R‚Äôs built-attr<- instead similar feature.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-9","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.9","text":"Added complete.epi_df, fills missing values epi_df NAs. Uses tidyr::complete underneath preserves epi_df metadata. Inclusion function revision_summary provide basic revision information epi_archives box. (#492)","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"bug-fixes-0-9","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"epiprocess 0.9","text":"Fix epi_slide_opt (related functions) correctly handle =Inf. Also allow multiple columns specified list strings. Disallow =Inf slide functions, since doesn‚Äôt seem like likely use case complicates code.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-8","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.8","text":"epi_df‚Äôs now strict types allow time column. Namely, explicit supporting Date daily weekly cadence generic integer types (yearly cadence). epi_slide arguments now require user specific time units certain cases. time_step argument removed. epix_slide argument now defaults Inf, requires user specify units cases. time_step argument removed. detect_outlr_stl(seasonal_period = NULL) longer accepted. Use detect_outlr_stl(seasonal_period = <value>, seasonal_as_residual = TRUE) instead. See ?detect_outlr_stl details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-8","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.8","text":"epi_slide computations now 2-4 times faster changing reference time values, made accessible within sliding functions, calculated (#397). Add new epi_slide_mean function allow much (~30x) faster rolling average computations cases (#400). Add new epi_slide_sum function allow much faster rolling sum computations cases (#433). Add new epi_slide_opt function allow much faster rolling computations cases, using data.table slider optimized rolling functions (#433). Add tidyselect interface epi_slide_opt derivatives (#452). regenerated jhu_csse_daily_subset dataset latest versions data API changed approach versioning, see DEVELOPMENT.md details select grouped epi_dfs now drops epi_dfness makes sense; PR #390 Minor documentation updates; PR #393 Improved epi_archive print method. Compactified metadata shows snippet underlying DT (#341). Added autoplot method epi_df objects, creates ggplot2 plot epi_df (#382). Refactored internals use cli warnings/errors checkmate argument checking (#413). Fix logic auto-assign epi_df time_type week (#416) year (#441). Clarified ‚ÄúGet started‚Äù example getting Ebola line list data epi_df format. Improved documentation web site landing page‚Äôs introduction. Fixed documentation referring old epi_slide() interface (#466, thanks @XuedaShen!). as_epi_df as_epi_archive now support arguments specify column names e.g.¬†as_epi_df(some_tibble, geo_value=state). addition, list default conversions, see time_column_names list columns automatically recognized converted time_value column (similar functions geo version). Fixed bug epix_slide_ref_time_values_default() datetimes output huge number ref_time_values spaced apart mere seconds. Multiple ‚Äúdata-masking‚Äù tidy evaluation expressions can passed via ..., rather just one. Additional tidy evaluation features dplyr::mutate supported: !! name_var := value, unnamed expressions evaluating data frames, = NULL; see ?epi_slide details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-8","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.8","text":"Resolved linting messages package checks (#468). Added optional decay_to_tibble attribute controlling as_tibble() behavior epi_dfs let {epipredict} work easily libraries (#471). Removed external package dependencies.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-7-0","dir":"Changelog","previous_headings":"","what":"Breaking changes:","title":"epiprocess 0.7.0","text":"Switched epi_df‚Äôs other_keys default NULL character(0); PR #390 Refactored epi_archive use S3 instead R6 object model. functionality stay , break member function interface. migration, can usually just convert epi_archive$merge(...) epi_archive <- epi_archive %>% epix_merge(...) (fill_through_version truncate_after_version) epi_archive$slide(...) epi_archive %>% epix_slide(...) (as_of, group_by, slide, etc.) (#340). limited situations, helper function calls epi_archive$merge etc. one arguments, may need carefully refactor .","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-7-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.7.0","text":"Updated vignettes compatibility epidatr 1.0.0 PR #377.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-7-0-1","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.7.0","text":"make existing slide computations work, add third argument f function accept new input: e.g., change f = function(x, g, <arguments>) { <body> } f = function(x, g, rt, <arguments>) { <body> }.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"New features","title":"epiprocess 0.7.0","text":"f formula, can now access reference time value via .z .ref_time_value. f missing, tidy evaluation expression ... can now refer window data epi_df tibble .x, group key .group_key, reference time value .ref_time_value. usual .data .env pronouns also work, butpick() cur_data() ; work .x instead. keep old behavior, manually perform row recycling within f computations, /left_join data frame representing desired output structure current epix_slide() result obtain desired repetitions completions expected all_rows = TRUE. keep old behavior, convert output epix_slide() epi_df desired set metadata appropriately.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-7-0-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.7.0","text":"epi_slide epix_slide now support as_list_col = TRUE slide computations output atomic vectors, output list column ‚Äúchopped‚Äù format (see tidyr::chop). epi_slide now works properly slide computations output just Date vector, rather converting slide_value numeric column. Fix ?archive_cases_dv_subset information regarding modifications upstream data @brookslogan (#299). Update use updated epidatr (fetch_tbl -> fetch) @brookslogan (#319).","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.6.0","text":"epi_slide‚Äôs time windows now extend time steps time steps corresponding ref_time_values. See ?epi_slide details matching old alignments. epix_slide‚Äôs time windows now extend time steps corresponding ref_time_values way latest data available corresponding ref_time_values. obtain old behavior, dplyr::ungroup slide results immediately. using as_list_col = TRUE together ref_time_values all_rows=TRUE, marker excluded computations now NULL entry list column, rather NA; using tidyr::unnest() afterward want keep missing data markers, need replace NULL entries NAs. Skipped computations now uniformly detectable using vctrs methods. x %>% epix_slide(<args>, group_by=c(col1, col2)) x %>% epix_slide(<args>, group_by=all_of(colname_vector)) x %>% group_by(col1, col2) %>% epix_slide(<args>) x %>% group_by(across(all_of(colname_vector))) %>% epix_slide(<args>) obtain old behavior, precede epix_slide call lacking group_by argument appropriate group_by call. epix_slide now guesses ref_time_values regularly spaced sequence covering DT$version values version_end, rather distinct DT$time_values. obtain old behavior, pass ref_time_values = unique(<ungrouped archive>$DT$time_value). epi_archive‚Äôs clobberable_versions_start‚Äôs default now NA, warnings default potential nonreproducibility. obtain old behavior, pass clobberable_versions_start = max_version_with_row_in(x).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"potentially-breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Potentially-breaking changes","title":"epiprocess 0.6.0","text":"Fixed [ grouped epi_dfs maintain grouping possible dropping epi_df class (e.g., removing time_value column). Fixed epi_df operations consistent decaying non-epi_dfs result operation doesn‚Äôt make sense epi_df (e.g., removing time_value column). Changed bind_rows grouped epi_dfs drop epi_df class. Like ungrouped epi_dfs, metadata result still simply taken first result, may inappropriate (#242). epi_slide epix_slide now raise error rather silently filtering ref_time_values don‚Äôt meet expectations.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"New features","title":"epiprocess 0.6.0","text":"epix_slide, <epi_archive>$slide new parameter all_versions. all_versions=TRUE, epix_slide pass filtered epi_archive computation rather epi_df snapshot. enables, e.g., performing pseudoprospective forecasts revision-aware forecaster using nested epix_slide operations.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-6-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.6.0","text":"Added dplyr::group_by dplyr::ungroup S3 methods epi_archive objects, plus corresponding $group_by $ungroup R6 methods. group_by implementation supports .add .drop arguments, ungroup supports partial ungrouping .... as_epi_archive, epi_archive$new now perform checks key uniqueness requirement (part #154).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-6-0","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.6.0","text":"Added NEWS.md file track changes package. Implemented ?dplyr::dplyr_extending epi_dfs (#223). Fixed various small documentation issues (#217).","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"potentially-breaking-changes-0-5-0","dir":"Changelog","previous_headings":"","what":"Potentially-breaking changes","title":"epiprocess 0.5.0","text":"epix_slide, <epi_archive>$slide now feed f epi_df rather converting tibble/tbl_df first, allowing use epi_df methods metadata, often yielding epi_dfs slide result. obtain old behavior, convert tibble within f.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-5-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.5.0","text":"Fixed epix_merge, <epi_archive>$merge always raising error sync=\"truncate\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-5-0","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.5.0","text":"Added Remotes: entry genlasso, removed CRAN. Added as_epi_archive tests. Added missing epix_merge test sync=\"truncate\".","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"potentially-breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Potentially-breaking changes","title":"epiprocess 0.4.0","text":"Fixed [.epi_df reorder columns, incompatible downstream packages. Changed [.epi_df decay--tibble logic coherent epi_dfs current tolerance nonunique keys: stopped decaying tibble cases unique key wouldn‚Äôt preserved, since don‚Äôt enforce unique key elsewhere. Fixed [.epi_df adjust \"other_keys\" metadata corresponding columns selected . Fixed [.epi_df raise error resulting column names nonunique. Fixed [.epi_df drop metadata decaying tibble (due removal essential columns).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-4-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.4.0","text":"Added check epi_df additional_metadata list. Fixed incorrect as_epi_df examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-4-0","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.4.0","text":"Applied rename upstream package examples: delphi.epidata -> epidatr. Rounded [.epi_df tests.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.3.0","text":"Compactification (see ) default may change results working directly epi_archive‚Äôs DT field; disable, pass compactify=FALSE. epix_<method> mutate input epi_archives, may alias alias fields (worry user sticks epix_* functions ‚Äúregular‚Äù R functions copy--write-like behavior, avoiding mutating functions [.data.table). x$<method> may mutate x; mutates x, return x invisibly (makes sense), , fields, may either mutate object refers reseat reference (); x$<method> mutate x, result may contain aliases x fields. Removed ..., locf, nan parameters. Changed default behavior, now corresponds using =key(x$DT) (demanding set column names key(y$DT)), =TRUE, locf=TRUE, nan=NaN (post-filling step fixed apply gaps, longer fill NAs originating x$DT y$DT). x y longer allowed share names non-columns. epix_merge longer mutates x argument ($merge continues ). Removed (undocumented) capability passing data.table y. Removed inappropriate/misleading n=7 default argument (due reporting latency, n=7 yield 7 days data typical daily-reporting surveillance data source, one might assumed).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"epiprocess 0.3.0","text":"New compactify parameter allows removal rows redundant purposes epi_archive‚Äôs methods, use last version observation carried forward. New clobberable_versions_start field allows marking range versions ‚Äúclobbered‚Äù (rewritten without assigning new version tags); previously, hard-coded max(<epi_archive>$DT$version). New versions_end field allows marking range versions beyond max(<epi_archive>$DT$version) observed, contained changes. New sync parameter controls x y aren‚Äôt equally date (.e., x$versions_end y$versions_end different). New function epix_fill_through_version, method <epi_archive>$fill_through_version: non-mutating & mutating way ensure archive contains versions least fill_versions_end, extrapolating according necessary. Example archive data object now constructed demand underlying data, based user‚Äôs version epi_archive rather outdated R6 implementation whenever data object generated.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"breaking-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"epiprocess 0.2.0","text":"Removed default n=7 argument epix_slide.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-2-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.2.0","text":"Ignore NAs printing time_value range epi_archive. Fixed misleading column naming epix_slide example. Trimmed epi_slide examples. Synced --date docs.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-2-0","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.2.0","text":"Removed dependency epi_archive tests example archive. object, made understandable reading without running. Fixed epi_df tests relying S3 method epi_df implemented externally epiprocess. Added tests epi_archive methods wrapper functions. Removed dead code. Made .{Rbuild,git}ignore files comprehensive.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"new-features-0-1-2","dir":"Changelog","previous_headings":"","what":"New features","title":"epiprocess 0.1.2","text":"treats x optional, constructing empty epi_df default.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-1-2","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.1.2","text":"Fixed geo_type guessing alphabetical strings 2 characters yield \"custom\", US \"nation\". Fixed time_type guessing actually detect Date-class time_values regularly spaced 7 days apart \"week\"-type intended. Improved printing epi_dfs, epi_archivess. Fixed as_of cut (forecast-like) data time_value > max_version. Expanded epi_df docs include conversion tsibble/tbl_ts objects, usage other_keys, pre-processing objects following geo_value, time_value naming scheme. Expanded epi_slide examples show use f argument named parameters. Updated examples print relevant columns given common 80-column terminal width. Added growth rate examples. Improved as_epi_archive epi_archive$new/$initialize documentation, including constructing toy archive.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-1-2","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.1.2","text":"Added tests epi_slide, epi_cor, internal utility functions. Fixed currently-unused internal utility functions MiddleL, MiddleR yield correct results odd-length vectors.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"new-features-0-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"epiprocess 0.1.1","text":"New example data objects allow one quickly experiment epi_dfs epi_archives without relying/waiting API fetch data.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"improvements-0-1-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"epiprocess 0.1.1","text":"Improved epi_slide error messaging. Fixed description appropriate parameters f argument epi_slide; previous description give incorrect behavior f named parameters receive values epi_slide‚Äôs .... Added examples throughout package. Using example data objects vignettes also speeds vignette compilation.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"cleanup-0-1-1","dir":"Changelog","previous_headings":"","what":"Cleanup","title":"epiprocess 0.1.1","text":"Set gh-actions CI. Added tests epi_dfs.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/dev/news/index.html","id":"implemented-core-functionality-vignettes-0-1-0","dir":"Changelog","previous_headings":"","what":"Implemented core functionality, vignettes","title":"epiprocess 0.1.0","text":"as_epi_df converts epi_df, guessing geo_type, time_type, other_keys, as_of specified. as_epi_df.tbl_ts as_tsibble.epi_df automatically set other_keys key&index, respectively. epi_slide applies user-supplied computation sliding/rolling time window user-specified groups, adding results new columns, recycling/broadcasting results keep result size stable. Allows computation provided function, purrr-style formula, tidyeval dots. Uses slider underneath efficiency. epi_cor calculates Pearson, Kendall, Spearman correlations two (optionally time-shifted) variables epi_df within user-specified groups. Convenience function: is_epi_df. as_epi_archive: prepares epi_archive object data frame containing snapshots /patch data every available version data set. as_of: extracts snapshot data set requested version, epi_df format. epix_slide, <epi_archive>$slide: similar epi_slide, epi_archives; requested ref_time_value group, applies time window user-specified computation snapshot data ref_time_value. epix_merge, <epi_archive>$merge: like merge epi_archives, allowing last version observation carried forward fill gaps x y. Convenience function: is_epi_archive. growth_rate: estimates growth rate time series using one built-methods based relative change, linear regression, smoothing splines, trend filtering. detect_outlr: applies one outlier detection methods given signal variable, optionally aggregates outputs create consensus result. detect_outlr_rm: outlier detection function based rolling-median-based outlier detection function; one methods included detect_outlr. detect_outlr_stl: outlier detection function based seasonal-trend decomposition using LOESS (STL); one methods included detect_outlr.","code":""}]
