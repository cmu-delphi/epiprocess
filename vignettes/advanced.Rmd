---
title: Advanced sliding with nonstandard outputs
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Advanced sliding with nonstandard outputs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

In this vignette, we discuss how to use the sliding functionality in the 
`epiprocess` package with computations that have advanced output structures.

In general, the functions `epi_slide()` and `epix_slide()` do what they can to
ensure the result of a slide operation is *size stable*, meaning, it will return 
something whose length is the same as the number of appearances of reference 
time values for the slide computation in the given data frame/table (this 
defaults to all time values, but can be some given subset when `ref_time_values` 
is specified).

The output of a slide computation should either be an atomic value/vector, or a 
data frame. This data frame can have multiple columns, multiple rows, or both. 
Below we demonstrate some advanced use cases of sliding with these output 
structures. We focus on `epi_slide()` for the most part, though the behavior we
demonstrate also carries over to `epix_slide()`.

## Recycling outputs

When a computation returns a single atomic value, `epi_slide()` will internally 
try to recycle the output so that it is size stable (in the sense described 
above). We can use this to our advantage, for example, in order to compute a
trailing average marginally over geo values, which we demonstrate below in a
simple synthetic example. 

```{r message = FALSE}
library(epiprocess)
library(dplyr)

df <- tibble(
  geo_value = rep(c("ca", "fl", "pa"), each = 3),
  time_value = rep(seq(as.Date("2020-06-01"), as.Date("2020-06-03"),
                       by = "day"), length.out = length(geo_value)),
  x = 1:length(geo_value) + 0.01 * rnorm(length(geo_value)),
) %>%
  as_epi_df()

# 2-day trailing average, per geo value
df %>% 
  group_by(geo_value) %>%
  epi_slide(x_2dav = mean(x), before = 1)

# 2-day trailing average, marginally 
df %>% 
  epi_slide(x_2dav = mean(x), before = 1)
```

```{r, include = FALSE}
# More checks (not included)
df %>% 
  epi_slide(x_2dav = mean(x), before = 1, ref_time_values = as.Date("2020-06-02"))

df %>% 
  mutate(version = time_value) %>% 
  as_epi_archive() %>%
  epix_slide(x_2dav = mean(x), n = 2, ref_time_values = as.Date("2020-06-02"))

df %>% 
  mutate(version = time_value) %>% 
  as_epi_archive() %>%
  epix_slide(~ mean(.x$x), n = 2, ref_time_values = as.Date("2020-06-02"))
```

When the slide computation returns an atomic vector (rather than a single value)
`epi_slide()` checks whether its return length ensures size stability, and if 
so, uses it to fill the new column. For example, this next computation gives the
same result as the last one.

```{r}
df %>% 
  epi_slide(y_2dav = rep(mean(x), 3), before = 1)
```

However, if the output is an atomic vector (rather than a single value) and it
is *not* size stable, then `epi_slide()` throws an error. For example, below we 
are trying to return 2 things for 3 states.

```{r, error = TRUE}
df %>% 
  epi_slide(x_2dav = rep(mean(x), 2), before = 1)
```

## Multi-column outputs

Now we move on to outputs that are data frames with a single row but multiple 
columns. Working with this type of output structure has in fact has already been 
demonstrated in the [slide
vignette](https://cmu-delphi.github.io/epiprocess/articles/slide.html). When
we set `as_list_col = TRUE` in the call to `epi_slide()`, the resulting `epi_df` 
object returned by `epi_slide()` has a list column containing the slide values.

```{r}
df2 <- df %>% 
  group_by(geo_value) %>%
  epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),
            before = 1, as_list_col = TRUE)

class(df2$a)
length(df2$a)
df2$a[[2]]
```

When we use `as_list_col = FALSE` (the default in `epi_slide()`), the function 
unnests (in the sense of `tidyr::unnest()`) the list column `a`, so that the 
resulting `epi_df` has multiple new columns containing the slide values. The
default is to name these unnested columns by prefixing the name assigned to the 
list column (here `a`) onto the column names of the output data frame from the
slide computation (here `x_2dav` and `x_2dma`) separated by "_".

```{r}
df %>% 
  group_by(geo_value) %>%
  epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),
            before = 1, as_list_col = FALSE)
```

We can use `names_sep = NULL` (which gets passed to `tidyr::unnest()`) to drop
the prefix associated with list column name, in naming the unnested columns.

```{r}
df %>% 
  group_by(geo_value) %>%
  epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),
            before = 1, as_list_col = FALSE, names_sep = NULL)
```

Furthermore, `epi_slide()` will recycle the single row data frame as needed in
order to make the result size stable, just like the case for atomic values.

```{r}
df %>% 
  epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),
            before = 1, as_list_col = FALSE, names_sep = NULL)
```

```{r, include = FALSE}
# More checks (not included)
df %>% 
  epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),
            ref_time_values = as.Date("2020-06-02"),
            before = 1, as_list_col = FALSE, names_sep = NULL)

df %>% 
  mutate(version = time_value) %>% 
  as_epi_archive() %>%
  epix_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),
             ref_time_values = as.Date("2020-06-02"),
             n = 2, as_list_col = FALSE, names_sep = NULL)
```

## Multi-row outputs

For a slide computation that outputs a data frame with more than one row, the 
behavior is analogous to a slide computation that outputs an atomic vector. 
Meaning, `epi_slide()` will check that the result is size stable, and if so,
will fill the new column(s) in the resulting `epi_df` object appropriately.

This can be convenient for modeling in the following sense: we can, for example,
fit a sliding forecasting model by pooling data from different locations, and
then return separate forecasts from this common model for each location. We use
our synthetic example to demonstrate this idea abstractly but simply.

```{r}
df$y <- 2 * df$x + 0.05 * rnorm(length(df$x))

df %>%
  epi_slide(function(d, ...) {
    obj <- lm(y ~ x, data = d)
    return(
      as.data.frame(
        predict(obj, newdata = d %>% 
                  group_by(geo_value) %>%
                  filter(time_value == max(time_value)), 
                interval = "prediction", level = 0.9)
      ))
  }, before = 1, new_col_name = "fc", names_sep = NULL)
```

## Version-aware forecasting, revisited

Finally, we revisit the COVID-19 forecasting example from the [archive 
vignette](https://cmu-delphi.github.io/epiprocess/articles/slide.html) in order
to demonstrate the last point in a more realistic setting. First, we fetch the
versioned data and build the archive.

```{r, message = FALSE, warning = FALSE, eval =FALSE}
library(delphi.epidata)
library(data.table)
library(ggplot2)
theme_set(theme_bw())

y1 <- covidcast(
  data_source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  geo_type = "state",
  time_value = epirange(20200601, 20211201),
  geo_values = "ca,fl",
  issues = epirange(20200601, 20211201)
) %>% fetch_tbl()

y2 <- covidcast(
  data_source = "jhu-csse",
  signal = "confirmed_7dav_incidence_prop",
  time_type = "day",
  geo_type = "state",
  time_value = epirange(20200601, 20211201),
  geo_values = "ca,fl",
  issues = epirange(20200601, 20211201)
) %>% fetch_tbl()

x <- y1 %>%
  select(geo_value, time_value,
    version = issue,
    percent_cli = value
  ) %>%
  as_epi_archive(compactify=FALSE)

# mutating merge operation:
x$merge(y2 %>%
  select(geo_value, time_value,
    version = issue,
    case_rate_7d_av = value
  ) %>%
  as_epi_archive(compactify=FALSE)
)
```

```{r, message = FALSE, warning = FALSE, echo =FALSE}
library(data.table)
library(ggplot2)
theme_set(theme_bw())

x <- archive_cases_dv_subset$DT %>%
  filter(geo_value %in% c("ca","fl")) %>%
  as_epi_archive()

```

Next, we extend the ARX function to handle multiple geo values, since in the 
present case, we will not be grouping by geo value and each slide computation
will be run on multiple geo values at once. Note that, because `epix_slide()` 
only returns the grouping variables, `time_value`, and the slide computations in
the eventual returned tibble, we need to include `geo_value` as a column in the 
output data frame from our ARX computation.

```{r}
library(tidyr)
library(purrr)

prob_arx_args <- function(lags = c(0, 7, 14), 
                          ahead = 7, 
                          min_train_window = 20,
                          lower_level = 0.05, 
                          upper_level = 0.95, 
                          symmetrize = TRUE, 
                          intercept = FALSE,
                          nonneg = TRUE) {
  return(list(lags = lags, 
              ahead = ahead, 
              min_train_window = min_train_window,
              lower_level = lower_level,
              upper_level = upper_level,
              symmetrize = symmetrize, 
              intercept = intercept,
              nonneg = nonneg))
}

prob_arx <- function(x, y, geo_value, time_value, args = prob_arx_args()) {  
  # Return NA if insufficient training data
  if (length(y) < args$min_train_window + max(args$lags) + args$ahead) {
    return(data.frame(geo_value = unique(geo_value), # Return geo value!
                      point = NA, lower = NA, upper = NA))
  }
  
  # Set up x, y, lags list
  if (!missing(x)) x <- data.frame(x, y)
  else x <- data.frame(y)
  if (!is.list(args$lags)) args$lags <- list(args$lags)
  args$lags = rep(args$lags, length.out = ncol(x))
  
  # Build features and response for the AR model, and then fit it
  dat <-
    tibble(i = 1:ncol(x), lag = args$lags) %>%
    unnest(lag) %>%
    mutate(name = paste0("x", 1:nrow(.))) %>%
    # One list element for each lagged feature
    pmap(function(i, lag, name) {
      tibble(geo_value = geo_value,
             time_value = time_value + lag, # Shift back 
             !!name := x[,i])
    }) %>% 
    # One list element for the response vector
    c(list(
      tibble(geo_value = geo_value,
             time_value = time_value - args$ahead, # Shift forward 
             y = y))) %>%
    # Combine them together into one data frame
    reduce(full_join, by = c("geo_value", "time_value")) %>%
    arrange(time_value)
  if (args$intercept) dat$x0 = rep(1, nrow(dat))
  obj <- lm(y ~ . + 0, data = select(dat, -geo_value, -time_value))
  
  # Use LOCF to fill NAs in the latest feature values (do this by geo value)
  setDT(dat) # Convert to a data.table object by reference
  cols <- setdiff(names(dat), c("geo_value", "time_value"))
  dat[, (cols) := nafill(.SD, type = "locf"), .SDcols = cols, by = "geo_value"]
  
  # Make predictions
  test_time_value = max(time_value)
  point <- predict(obj, newdata = dat %>% 
                     dplyr::group_by(geo_value) %>%
                     dplyr::filter(time_value == test_time_value))
  
  # Compute bands
  r <- residuals(obj)
  s <- ifelse(args$symmetrize, -1, NA) # Should the residuals be symmetrized?
  q <- quantile(c(r, s * r), probs = c(args$lower, args$upper), na.rm = TRUE)
  lower <- point + q[1]
  upper <- point + q[2]
  
  # Clip at zero if we need to, then return
  if (args$nonneg) { 
    point = pmax(point, 0) 
    lower = pmax(lower, 0) 
    upper = pmax(upper, 0) 
  }
  return(data.frame(geo_value = unique(geo_value), # Return geo value!
                    point = point, lower = lower, upper = upper))
}
```

We now make forecasts on the archive and compare to forecasts on the latest
data. 

```{r, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 6}
# Latest snapshot of data, and forecast dates
x_latest <- epix_as_of(x, max_version = max(x$DT$version))
fc_time_values <- seq(as.Date("2020-08-01"), 
                      as.Date("2021-12-01"), 
                      by = "1 month")

# Simple function to produce forecasts k weeks ahead
k_week_ahead <- function(x, ahead = 7, as_of = TRUE) {
  if (as_of) {
    x %>%
      epix_slide(fc = prob_arx(percent_cli, case_rate_7d_av, geo_value, time_value, 
                               args = prob_arx_args(ahead = ahead)), 
                 n = 120, ref_time_values = fc_time_values) %>%
      mutate(target_date = time_value + ahead, as_of = TRUE, 
             geo_value = fc_geo_value)
  }
  else {
    x_latest %>% 
      epi_slide(fc = prob_arx(percent_cli, case_rate_7d_av, geo_value, time_value, 
                              args = prob_arx_args(ahead = ahead)), 
                before = 119, ref_time_values = fc_time_values) %>%
      mutate(target_date = time_value + ahead, as_of = FALSE) 
  }
}

# Generate the forecasts, and bind them together
fc <- bind_rows(k_week_ahead(x, ahead = 7, as_of = TRUE),
                k_week_ahead(x, ahead = 14, as_of = TRUE),
                k_week_ahead(x, ahead = 21, as_of = TRUE),
                k_week_ahead(x, ahead = 28, as_of = TRUE),
                k_week_ahead(x, ahead = 7, as_of = FALSE),
                k_week_ahead(x, ahead = 14, as_of = FALSE),
                k_week_ahead(x, ahead = 21, as_of = FALSE),
                k_week_ahead(x, ahead = 28, as_of = FALSE))

# Plot them, on top of latest COVID-19 case rates 
ggplot(fc, aes(x = target_date, group = time_value, fill = as_of)) +
  geom_ribbon(aes(ymin = fc_lower, ymax = fc_upper), alpha = 0.4) +
  geom_line(data = x_latest, aes(x = time_value, y = case_rate_7d_av), 
               inherit.aes = FALSE, color = "gray50") +
  geom_line(aes(y = fc_point)) + geom_point(aes(y = fc_point), size = 0.5) + 
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_grid(vars(geo_value), vars(as_of), scales = "free") +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Reported COVID-19 case rates") + 
  theme(legend.position = "none") 
```

We can see that these forecasts, which come from training an ARX model jointly
over CA and FL, exhibit generally less variability and wider prediction bands
compared to the ones from the archive vignette, which come from training a 
separate ARX model on each state. As in the archive vignette, we can see a
difference between version-aware (right column) and -unaware (left column)
forecasting, as well.


## Attribution
The `case_rate_7d_av` data used in this document is a modified part of the [COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19) as [republished in the COVIDcast Epidata API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html). This data set is licensed under the terms of the [Creative Commons Attribution 4.0 International license](https://creativecommons.org/licenses/by/4.0/) by the Johns Hopkins University on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.

The `percent_cli` data is a modified part of the [COVIDcast Epidata API Doctor Visits data](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html). This dataset is licensed under the terms of the [Creative Commons Attribution 4.0 International license](https://creativecommons.org/licenses/by/4.0/). Copyright Delphi Research Group at Carnegie Mellon University 2020.


